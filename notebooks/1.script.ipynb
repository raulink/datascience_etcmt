{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script de migracion de datos\n",
    "\n",
    "Este programa está diseñado para procesar datos de, en el caso de los planes de mantenimiento, se tienen 2 planes de mantenimiento (Lineas de Alta Demanda LAD y Lineas de Baja Demanda LBD) descargándolos, transformándolos y guardándolos en un archivo Excel. La clase principal, GoogleSheetProcessor, maneja todo el flujo de trabajo, desde la obtención de datos hasta su procesamiento y almacenamiento. A continuación se describe el funcionamiento detallado del programa.\n",
    "\n",
    "## Funcionalidades Principales\n",
    "1. Inicialización (__init__)\n",
    "La clase se inicializa con la URL de una hoja de cálculo de Google Sheets. Durante la inicialización, se extraen los identificadores del archivo y de la hoja específica, y se construye la URL para exportar la hoja en formato CSV.\n",
    "\n",
    "### Atributos:\n",
    "\n",
    "sheet_url: URL de la hoja de cálculo de Google Sheets.\n",
    "spreadsheet_id: ID único de la hoja de cálculo.\n",
    "sheet_id: ID único de la hoja dentro de la hoja de cálculo.\n",
    "csv_export_url: URL para exportar la hoja en formato CSV.\n",
    "\n",
    "### Diccionarios predefinidos:\n",
    "\n",
    "valores: Diccionario que asocia códigos con valores numéricos. Este diccionario de valores es dependiendo las columnas de la hoja de calculo, especifico a las frecuencias \n",
    "regimen: Diccionario que asocia códigos con sus unidades de medida correspondientes.\n",
    "\n",
    "\n",
    "1. Extracción de Identificadores\n",
    "extract_spreadsheet_id(url): Extrae el ID de la hoja de cálculo desde la URL.\n",
    "extract_sheet_id(url): Extrae el ID de la hoja específica desde la URL.\n",
    "2. Construcción de la URL de Exportación\n",
    "construct_csv_export_url(): Construye la URL que permite descargar la hoja de cálculo en formato CSV.\n",
    "3. Descarga de la Hoja en CSV\n",
    "download_csv(output_filename='temp_sheet.csv'): Descarga la hoja de cálculo en formato CSV y la guarda con un nombre de archivo especificado (por defecto, temp_sheet.csv).\n",
    "4. Procesamiento de Datos\n",
    "process_data(filename=\"temp_sheet.csv\", valores=\"\", regimen=\"\"):\n",
    "Carga el archivo CSV y realiza una serie de transformaciones y filtrados en los datos, como la conversión de valores, la asignación de unidades, y la reestructuración del DataFrame.\n",
    "Comprueba que las claves de los diccionarios valores y regimen coinciden, lanzando un AssertionError si no es así.\n",
    "Filtra los datos para excluir planes y mantener solo las columnas relevantes.\n",
    "Realiza transformaciones en el DataFrame para preparar la información que se almacenará en Excel.\n",
    "Retorna los DataFrames df_plan, df_action, df_speciality y filtered_data.\n",
    "5. Guardar Resultados en Excel\n",
    "save_to_excel(output_path=\"Salida.xlsx\", filename=\"mix_plan.csv\", valores=\"\", regimen=\"\"):\n",
    "Llama al método process_data para obtener los DataFrames procesados.\n",
    "Guarda los DataFrames resultantes en un archivo Excel con hojas separadas para acciones, planes, especialidades y actividades filtradas.\n",
    "6. Funciones Auxiliares\n",
    "get_unique(df: pd.DataFrame, column: str): Genera un DataFrame con valores únicos de una columna específica, ajustando los índices.\n",
    "buscarIndice(df: pd.DataFrame, valor, columna='value'): Busca el índice de un valor específico en un DataFrame y lo retorna como un entero.\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Inicio] --> B[Inicializa GoogleSheetProcessor con lad.value]\n",
    "    B --> C[Lee CSV desde input/pad.csv]\n",
    "    C --> D[Inicializa GoogleSheetProcessor con lbd.value]\n",
    "    D --> E[Lee CSV desde input/pbd.csv]\n",
    "    E --> F[Concatena los DataFrames df1 y df2]\n",
    "    F --> G[Guarda el DataFrame combinado indicado en el campo salida]    \n",
    "    G --> H[Guarda el Dataframe directamente en la base de datos indicada]\n",
    "\n",
    "```\n",
    "\n",
    "Descripción del Flujograma\n",
    "* Inicio: El proceso comienza con la inicialización del primer GoogleSheetProcessor con la URL contenida en lad.value.\n",
    "* Lectura del primer CSV: Se lee el archivo CSV asociado al primer DataFrame desde la ruta input/pad.csv.\n",
    "* Inicialización del segundo GoogleSheetProcessor: Se inicializa el segundo objeto GoogleSheetProcessor con la URL contenida en lbd.value.\n",
    "* Lectura del segundo CSV: Se lee el archivo CSV asociado al segundo DataFrame desde la ruta input/pbd.csv.\n",
    "* Concatenación de DataFrames: Los dos DataFrames (df1 y df2) se combinan en uno solo mediante pd.concat.\n",
    "* Guardar el DataFrame combinado: El DataFrame combinado se guarda en un archivo CSV en la ruta input/mix_plan.csv.\n",
    "* Procesamiento y Almacenamiento de hoja de calculo procesada: Se puede almacenar en archivo excel o directamente en la base de datos, \n",
    "\n",
    "\n",
    "### Pantalla 1\n",
    "Al presionar el boton de _Generar Archivo Excel_ se realiza la generación del archivo excel en la carpeta output, colocando el nombre del archivo excel que se encuetnra en el campo de salida.\n",
    "\n",
    "![Pantalla 1](assets/pantalla1.png \"Pantalla 1\")\n",
    "\n",
    "### Pantalla 2\n",
    "\n",
    "En este apartado se colocan los datos de conexion de la base de datos. Al presionar el botón de _Cargar en Base de datos_ se procede a conectar y a volcar el dataframe en la base de datos indicada en los datos de usuario, password, host y base de datos de destino.\n",
    "\n",
    "![Pantalla 2](assets/pantalla2.png \"Pantalla 2\")\n",
    "\n",
    "\n",
    "\n",
    "> Nota. Exportar directamente en la base de datos aun no es posible, se requiere complementar el codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "class GoogleSheetProcessor:\n",
    "    def __init__(self, sheet_url:str):\n",
    "        self.sheet_url = sheet_url\n",
    "        self.spreadsheet_id = self.extract_spreadsheet_id(sheet_url)\n",
    "        self.sheet_id = self.extract_sheet_id(sheet_url)\n",
    "        self.csv_export_url = self.construct_csv_export_url()\n",
    "\n",
    "        # Diccionarios originales\n",
    "        self.valores = {\n",
    "            \"D\": 1, \"S\": 1, \"M\": 5, \"MC\": 1, \"2M\": 2, \"T\": 3, \"4M\": 4, \"SE\": 6,\n",
    "            \"8M\": 8, \"A\": 1, \"1.5A\": 18, \"2A\": 2, \"3A\": 3, \"4A\": 4, \"5A\": 5,\n",
    "            \"6A\": 6, \"8A\": 8, \"10A\": 10, \"1000\": 1000, \"6000\": 6000, \"22500\": 22500,\n",
    "            \"40000\": 40000, \"55000\": 55000\n",
    "        }\n",
    "\n",
    "        self.regimen = {\n",
    "            \"D\": 'dia', \"S\": 'semana', \"M\": 'semana', \"MC\": 'mes', \"2M\": 'mes', \"T\": 'mes',\n",
    "            \"4M\": 'mes', \"SE\": 'mes', \"8M\": 'mes', \"A\": 'año', \"1.5A\": 'mes', \"2A\": 'año',\n",
    "            \"3A\": 'año', \"4A\": 'año', \"5A\": 'año', \"6A\": 'año', \"8A\": 'año', \"10A\": 'año',\n",
    "            \"1000\": 'horas', \"6000\": 'horas', \"22500\": 'horas', \"40000\": 'horas', \"55000\": 'horas'\n",
    "        }\n",
    "\n",
    "    def extract_spreadsheet_id(self, url):\n",
    "        return url.split('/d/')[1].split('/')[0]\n",
    "\n",
    "    def extract_sheet_id(self, url):\n",
    "        return url.split('gid=')[1]\n",
    "\n",
    "    def construct_csv_export_url(self):\n",
    "        return f\"https://docs.google.com/spreadsheets/d/{self.spreadsheet_id}/export?format=csv&gid={self.sheet_id}\"\n",
    "\n",
    "    def download_csv(self, output_filename='temp_sheet.csv'):\n",
    "        # Descarga el archivo CSV y lo guarda temporalmente\n",
    "        response = requests.get(self.csv_export_url)\n",
    "        response.raise_for_status()  # Asegurarse de que la solicitud fue exitosa\n",
    "        with open(output_filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return output_filename\n",
    "    def get_unique(self, df: pd.DataFrame, column: str):\n",
    "        \"\"\"\n",
    "        Obtiene un DataFrame con valores únicos de la columna 'Column', con índices ajustados.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: Un DataFrame con valores únicos de la columna 'Column' y un índice ajustado.\n",
    "        \"\"\"\n",
    "        df[column] = df[column].str.strip()\n",
    "        df = df[df[column].notnull()]\n",
    "        df_unique = pd.DataFrame(df[column].unique(), columns=['value'])\n",
    "        df_unique.index = df_unique.index + 1\n",
    "        return df_unique\n",
    "\n",
    "\n",
    "    def buscarIndice(self, df: pd.DataFrame, valor, columna_id='value'):\n",
    "        # Verificar si el valor está en la columna_id especificada\n",
    "        resultado = df[df[columna_id].str.contains(valor, case=False, na=False)]    \n",
    "        # Si no encuentra el valor, retornar el mismo valor\n",
    "        if resultado.empty:\n",
    "            return valor\n",
    "        else:\n",
    "            return int(resultado.index[0])\n",
    "\n",
    "\n",
    "    def read_csv(self, filename=\"temp_sheet.csv\"):\n",
    "        # Lee el archivo CSV usando pandas\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.df.columns = self.df.loc[2, :].to_list()  # la fila 2 como fila\n",
    "        self.df = self.df.loc[4:, :]   # Obtener desde la fila 4 en adelante\n",
    "        return self.df\n",
    "    \n",
    "    def process_data_with_validation(self, df: pd.DataFrame, valores: dict):\n",
    "        # Iterar sobre las claves del diccionario valores\n",
    "        for col in valores.keys():\n",
    "            # Verificar si la columna existe en el DataFrame\n",
    "            if col in df.columns:\n",
    "                # Comprobar si la columna no es booleana\n",
    "                if not pd.api.types.is_bool_dtype(df[col]):\n",
    "                    # Si no es booleana, intentamos convertirla\n",
    "                    df[col] = df[col].apply(lambda x: True if str(x).upper() == 'TRUE' else False)\n",
    "                    # df[list(valores.keys())] = df[valores.keys()].applymap(lambda x: True if x == 'TRUE' else False)\n",
    "            else:\n",
    "                print(f\"La columna '{col}' no se encuentra en el DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    def process_data(self,filename = \"temp_sheet.csv\",valores=\"\", regimen=\"\"):        \n",
    "        df = pd.DataFrame()\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        if valores == \"\":valores = self.valores    \n",
    "        if regimen == \"\":regimen = self.regimen\n",
    "        \n",
    "        if valores.keys() != regimen.keys():\n",
    "            raise AssertionError(f\"Las claves no coinciden: {valores.keys()} != {regimen.keys()}\")\n",
    "\n",
    "        # Realiza el procesamiento necesario\n",
    "        # Este es un lugar para incluir toda la lógica de procesamiento\n",
    "        \n",
    "        # Suponiendo que el procesamiento produce 'filtered_data' y otros DataFrames\n",
    "        df_plan = pd.DataFrame()  # Placeholder\n",
    "        df_action = pd.DataFrame()  # Placeholder\n",
    "        df_speciality = pd.DataFrame()  # Placeholder\n",
    "        filtered_data = pd.DataFrame()  # Placeholder        \n",
    "        #print(valores)\n",
    "        ## convertir a booleano\n",
    "        # df[list(valores.keys())] = df[valores.keys()].applymap(lambda x: True if x == 'TRUE' else False)\n",
    "        ## convertir a booleano\n",
    "        df = self.process_data_with_validation(df,valores)\n",
    "        #print(df.dtypes)\n",
    "\n",
    "        # Quitar planes\n",
    "        df = df[df['Tipo_plan']!= 'Plan']   # Se cambio de Tipo a Tipo_plan el 5-9-24\n",
    "\n",
    "        # Obtener la unidades\n",
    "        parametros = regimen\n",
    "        df['unidad'] = df.apply(lambda row: next((parametros[key] for key in parametros.keys() if key in row and row[key] == True), None), axis=1)\n",
    "        # Obtener los valores\n",
    "        parametros = valores\n",
    "        df['valor'] = df.apply(lambda row: next((parametros[key] for key in parametros.keys() if key in row and row[key] == True), None), axis=1)\n",
    "        # Filtrar las columnas necesarias solamente\n",
    "        #print(\"Valores unicos en unidades: \")\n",
    "        #print(df['unidad'].unique())        \n",
    "        # Mantener solo las columnas necesarias\n",
    "        columns = ['Plan','Accion','Trabajo','Actividad','Tipo_plan','Parada','Relevancia','Especialidad','valor','unidad']\n",
    "        df = df[columns]\n",
    "        # Crear la nueva columna fk_activity que tendra relaciones con las actividades padre\n",
    "        df['fk_activity']= None\n",
    "        df['fkc_regime']= None\n",
    "\n",
    "        # renombrar los nombres de las columnas\n",
    "        nuevos_nombres = {\n",
    "            'Plan': 'fk_plan',\n",
    "            'Accion': 'fk_action',\n",
    "            'Actividad': 'name',\n",
    "            'Tipo_plan': 'fkc_activity_type',\n",
    "            'Relevancia': 'fkc_priority',\n",
    "            'Especialidad': 'fk_specialty',\n",
    "            'valor': 'time_interval_value',\n",
    "            'unidad': 'fk_periodicity_unit',\n",
    "            'Parada': 'stoppage',\n",
    "        }\n",
    "        df.rename(columns=nuevos_nombres, inplace=True)\n",
    "                # Mantener las columnas del excel en el orden indicado\n",
    "        columnas_excel = ['fk_activity','fk_plan','fk_action','name','fkc_activity_type','fkc_priority','fk_specialty','fkc_regime','stoppage','time_interval_value','fk_periodicity_unit'] \n",
    "\n",
    "        df = df[columnas_excel]\n",
    "        df_plan = self.get_unique(df,\"fk_plan\")\n",
    "        df_action = self.get_unique(df,\"fk_action\")\n",
    "        df_speciality = self.get_unique(df,\"fk_specialty\")\n",
    "        df_activity_type = self.get_unique(df,\"fkc_activity_type\")\n",
    "        df_regime = self.get_unique(df,\"fkc_regime\")\n",
    "\n",
    "        # Filter the data\n",
    "        #df = df_raw.copy(deep=True)\n",
    "        filtered_data = df[(df['fkc_activity_type'] == 'Actividad') | (df['fkc_activity_type'] == 'Tarea')]\n",
    "        \n",
    "        \n",
    "\n",
    "        # Add fk_activity column\n",
    "        filtered_data['fk_activity'] = None\n",
    "\n",
    "        # Buscar fk_activity para las Tareas que provienen de una Actividad\n",
    "        parent_index = None\n",
    "        for i, row in filtered_data.iterrows():\n",
    "            if row['fkc_activity_type'] == 'Actividad':\n",
    "                parent_index = i\n",
    "            elif row['fkc_activity_type'] == 'Tarea':\n",
    "                filtered_data.at[i, 'fk_activity'] = parent_index\n",
    "\n",
    "        # Obtener los ids de la relacion con los otros dataframes\n",
    "        filtered_data['fk_plan']= filtered_data['fk_plan'].apply(lambda x: self.buscarIndice(df_plan,x))\n",
    "        filtered_data['fk_action']= filtered_data['fk_action'].apply(lambda x: self.buscarIndice(df_action,x)) \n",
    "        filtered_data['fk_specialty']= filtered_data['fk_specialty'].apply(lambda x: self.buscarIndice(df_speciality,x)) \n",
    "        valores_lecturas=['horas','ciclos']\n",
    "        # Discriminar si las lecturas son horas o ciclos colocar FECHAS O LECTURAS\n",
    "        filtered_data['fkc_regime'] = filtered_data['fk_periodicity_unit'].apply(lambda x: 'LECTURAS' if x in valores_lecturas else 'FECHAS')\n",
    "        # Filtrar y aplicar los cambios correspondientes, mover los valores a las columnas de uso\n",
    "        filtered_data.loc[filtered_data['fk_periodicity_unit'].isin(valores_lecturas), 'usage_interval_value'] = filtered_data['time_interval_value']\n",
    "        filtered_data.loc[filtered_data['fk_periodicity_unit'].isin(valores_lecturas), 'fk_usage_unit'] = filtered_data['fk_periodicity_unit']\n",
    "\n",
    "        # Colocar los valores en las columnas timer_interva_value y fk_periodicity_unit en nulo\n",
    "        filtered_data.loc[filtered_data['fk_periodicity_unit'].isin(valores_lecturas), 'time_interval_value'] = pd.NA\n",
    "        filtered_data.loc[filtered_data['fk_periodicity_unit'].isin(valores_lecturas), 'fk_periodicity_unit'] = pd.NA\n",
    "       \n",
    "        return df_plan, df_action, df_speciality, filtered_data    \n",
    "\n",
    "\n",
    "    def save_to_excel(self, output_path=\"Salida.xlsx\",filename=\"mix_plan.csv\",valores=\"\",regimen=\"\"):\n",
    "        df_plan, df_action, df_speciality, filtered_data = self.process_data(filename=filename,valores=valores,regimen=regimen)  \n",
    "        with pd.ExcelWriter(output_path) as writer:\n",
    "            df_action.to_excel(writer, sheet_name='actions')\n",
    "            df_plan.to_excel(writer, sheet_name='plans')\n",
    "            df_speciality.to_excel(writer, sheet_name='specialties')\n",
    "            filtered_data.to_excel(writer, sheet_name='activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bloque de variables\n",
    "descargar = False\n",
    "url_alta_demanda =\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294\"\n",
    "archivo_ad = \"input/pad_actividades.csv\"\n",
    "url_baja_demanda = \"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294\"\n",
    "archivo_bd = \"input/pbd_actividades.csv\"\n",
    "filename_actividades = \"input/mix_plan_actividades.csv\"\n",
    "\n",
    "valores = {\"D\": 1,\"S\": 1,\"2S\": 2,\"M\": 5,\"MC\": 1,\"2M\": 2,\"T\": 3,\"SE\": 6,\"8M\": 8,\"A\": 1,\"1.5A\": 18,\"2A\": 2,\"3A\": 3,\"4A\": 4,\"5A\": 5,\"6A\": 6,\"8A\": 8,\"10A\": 10,\"1000\": 1000,\"1300\": 1300,\"1800\": 1800,\"6000\": 6000,\"22500\": 6000,\"40000\": 40000,\"55000\": 55000,\"55000C\": 55000}\n",
    "\n",
    "regimen = {\"D\": 'dia',\"S\": 'semana',\"2S\": 'semana',\"M\": 'semana',\"MC\": 'mes',\"2M\": 'mes',\"T\": 'mes',\"SE\": 'mes',\"8M\": 'mes',\"A\": 'año',\"1.5A\": 'mes',\"2A\": 'año',\"3A\": 'año',\"4A\": 'año',\"5A\": 'año',\"6A\": 'año',\"8A\": 'año',\"10A\": 'año',\"1000\": 'horas',\"1300\": 'horas',\"1800\": 'horas',\"6000\": 'horas',\"22500\": 'horas',\"40000\": 'horas',\"55000\": 'horas',\"55000C\": 'ciclos'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinacion de dataframes\n",
    "gs1 = GoogleSheetProcessor(url_alta_demanda)\n",
    "if descargar : gs1.download_csv(archivo_ad)\n",
    "df1 = gs1.read_csv(archivo_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GoogleSheetProcessor (url_baja_demanda)\n",
    "if descargar: gs2.download_csv(archivo_bd)\n",
    "df2 = gs2.read_csv(archivo_bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No son iguales las columnas, verificar la igualdad de columnas\n"
     ]
    }
   ],
   "source": [
    "if ((df1.columns == df2.columns).any) :\n",
    "    print(\"No son iguales las columnas, verificar la igualdad de columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el merge de ambos planes en un solo dataframe\n",
    "df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "df_merged.to_csv(filename_actividades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramamani\\AppData\\Local\\Temp\\ipykernel_8260\\4038540681.py:58: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  resultado = df[df[columna_id].str.contains(valor, case=False, na=False)]\n"
     ]
    }
   ],
   "source": [
    "df_plan, df_action, df_speciality, df_activities = gs1.process_data(filename=filename_actividades,valores=valores,regimen=regimen)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones principales\n",
    "1. **format_dataframe**:\n",
    "Descripción: Formatea un DataFrame antes de insertarlo en una base de datos, asegurándose de que tenga todas las columnas requeridas y ajustando algunas de sus propiedades (como agregar UUIDs, establecer columnas de seguimiento como created_at, updated_at, etc.).\n",
    "Uso: Asegura que las columnas entre el DataFrame y la tabla de la base de datos sean consistentes.\n",
    "2. **actualizar_tabla_postgres:**\n",
    "Descripción: Elimina los registros de una tabla PostgreSQL, inserta nuevos datos desde un DataFrame, y reinicia la secuencia de la columna id para evitar conflictos.\n",
    "Uso: Se utiliza para actualizar completamente una tabla en PostgreSQL con nuevos datos, manteniendo la consistencia de la columna id.\n",
    "3. **obtener_registros:**\n",
    "Descripción: Ejecuta una consulta SELECT * en una tabla PostgreSQL y devuelve los resultados en un DataFrame. Puede filtrar por columnas específicas si se le proporcionan.\n",
    "Uso: Sirve para obtener los registros de una tabla en formato DataFrame.\n",
    "4. **buscarIndice:**\n",
    "Descripción: Busca un valor en una columna específica de un DataFrame y devuelve el índice del primer resultado encontrado. Si no se encuentra el valor, devuelve el valor de búsqueda original.\n",
    "Uso: Para encontrar la posición de un valor en un DataFrame.\n",
    "5. **ejecutar_query:**\n",
    "Descripción: Ejecuta una consulta SQL (que puede o no devolver filas) y devuelve el resultado en un DataFrame si aplica.\n",
    "Uso: Ejecuta cualquier consulta SQL genérica, devolviendo resultados si es necesario.\n",
    "6. **eliminar_registros:**\n",
    "Descripción: Elimina todos los registros de una tabla PostgreSQL.\n",
    "Uso: Se utiliza para limpiar una tabla antes de insertar nuevos datos.\n",
    "7. **update_plans_table:**\n",
    "Descripción: Elimina registros de una tabla PostgreSQL, inserta nuevos datos desde un DataFrame y reinicia la secuencia de la columna id. Se enfoca en tablas relacionadas con planes.\n",
    "Uso: Función similar a actualizar_tabla_postgres, diseñada específicamente para actualizar tablas de planes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine.result import Result\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\"\"\" Para pasar a la base de datos\"\"\"\n",
    "\n",
    "def format_dataframe(df:pd.DataFrame,tabla:str,\n",
    "                     usuario='postgres', password='postgres',host='localhost', database='simyo3'):\n",
    "    \n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    # Leer la tabla original en un DataFrame de pandas\n",
    "    df_origen = pd.read_sql_query(f\"SELECT * FROM {tabla}\", con=engine)\n",
    "\n",
    "    # Renombrar la columna 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "\n",
    "    # Si existe la columna 'uuid' en la tabla original, crear esa columna\n",
    "    if 'uuid' in df_origen.columns:\n",
    "        df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "    if 'is_active' in df_origen.columns:\n",
    "        df['is_active'] = True        \n",
    "\n",
    "    # Identificar las columnas que están en df_origen pero no en df\n",
    "    missing_columns = [col for col in df_origen.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columnas faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir columnas comunes\n",
    "    df['id'] = df.index +1 if df.index[0] ==0 else df.index\n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()\n",
    "    # Validar que las columnas de df y df_origen sean iguales\n",
    "    columnas_df = set(df.columns)\n",
    "    columnas_df_origen = set(df_origen.columns)\n",
    "    \n",
    "    # Si las columnas no son iguales, lanzar un error\n",
    "    assert columnas_df == columnas_df_origen, f\"Las columnas no coinciden. Columnas faltantes: {columnas_df_origen - columnas_df} en df y {columnas_df - columnas_df_origen} en df_origen\"        \n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def actualizar_tabla_postgres(df: pd.DataFrame, tabla: str, columna_id: str,\n",
    "                              usuario='postgres', password='postgres', \n",
    "                              host='localhost', database='simyo3'):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "        \n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        #connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.execute(text(f\"DELETE FROM {tabla} CASCADE;\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # Insertar los nuevos datos en la tabla\n",
    "    df.to_sql(tabla, con=engine, if_exists='append', index=False)  # Solo append en tablas con relaciones    \n",
    "\n",
    "    # Obtener el valor máximo de la columna 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX({columna_id}) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    # Obtener el nombre de la secuencia asociada a la columna 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\"))\n",
    "        id_secuencia = result.scalar()\n",
    "\n",
    "    # Reiniciar el valor de la secuencia si se obtiene la secuencia asociada\n",
    "    with engine.connect() as connection:\n",
    "        if id_secuencia:\n",
    "            connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "            connection.commit()\n",
    "            print(f'Se reinició el índice {id_secuencia} en {max_id + 1}')\n",
    "\n",
    "# Ejemplo de uso:\n",
    "## actualizar_tabla_postgres(df_plan, 'plans', 'id')\n",
    "\n",
    "\n",
    "\n",
    "def obtener_registros( tabla,  usuario='postgres', password='postgres', host='localhost', database='simyo3',columna_ids=[]):\n",
    "    \"\"\"\n",
    "    Realiza un SELECT * en una tabla especificada de la base de datos y retorna un DataFrame con los resultados.\n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la sentencia SQL para obtener los registros\n",
    "        result = connection.execute(text(f'select * from {tabla}'))        \n",
    "        # Convertir los resultados en un DataFrame\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "        #df.index = df['index']\n",
    "        df.index = df['id']\n",
    "    return df if not columna_ids or len(columna_ids) == 0 else df[columna_ids]\n",
    "    \n",
    "def buscarIndice(df: pd.DataFrame, valor_busqueda:str, columna_busqueda='name'):\n",
    "    \"\"\"\n",
    "    Busca un valor en la columna especificada del DataFrame.\n",
    "    Si el valor de búsqueda es nulo o si no se encuentra, retorna el mismo valor de búsqueda.\n",
    "    \"\"\"\n",
    "    # Validar si el valor de búsqueda es nulo\n",
    "    if pd.isna(valor_busqueda):\n",
    "        return pd.NA    \n",
    "    # Verificar si el valor está en la columna_id especificada\n",
    "    resultado = df[df[columna_busqueda].str.contains(valor_busqueda, case=False, na=False)]    \n",
    "    # Si no encuentra el valor, retornar el mismo valor\n",
    "    if resultado.empty:\n",
    "        return valor_busqueda\n",
    "    else:\n",
    "        return int(resultado.index[0])\n",
    "\n",
    "def ejecutar_query(query, usuario='postgres', password='postgres', host='localhost', database='simyo3'):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta SQL y devuelve el resultado en un DataFrame si la consulta devuelve filas.\n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la consulta\n",
    "        result = connection.execute(text(query))\n",
    "        connection.commit()\n",
    "        \n",
    "        # Verificar si la consulta devuelve filas\n",
    "        if result.returns_rows:\n",
    "            # Obtener los resultados en un DataFrame\n",
    "            df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "            return df\n",
    "        else:\n",
    "            # Si no devuelve filas, solo confirmar la ejecución\n",
    "            return None\n",
    "\n",
    "    return result\n",
    "def eliminar_registros(tabla,usuario='postgres', password='postgres', host= 'localhost', database='simyo3'):\n",
    "    \"\"\"\n",
    "    Elimina todos los registros de una tabla especificada en la base de datos.    \n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la sentencia SQL para eliminar todos los registros\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.commit()  # Confirmar los cambios\n",
    "\n",
    "def __actualizar_tabla_postgres(df:pd.DataFrame , tabla:str, columna_id:str , usuario='postgres', password='postgres', host= 'localhost', database='simyo3'):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "\n",
    "    # Usar pd.read_sql_query con una conexión\n",
    "        # Leer la tabla en un DataFrame de pandas\n",
    "    df_origen = ejecutar_query(f\"SELECT * FROM {tabla}\")\n",
    "\n",
    "    \n",
    "    # Renombrar la columna_id 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "    \n",
    "    # Si existe la columna_id uuid en la tabla original, crear esa columna_id\n",
    "    if 'uuid' in df_origen.columns:\n",
    "        df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "    \n",
    "    if 'is_active' in df_origen.columns:\n",
    "        df['is_active'] = True\n",
    "\n",
    "\n",
    "    # Identificar las columna_ids que están en df pero no en df_origen\n",
    "    missing_columns = [col for col in df_origen.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columna_ids faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir las columna_ids comunes en las tablas\n",
    "    df['id'] = df.index\n",
    "    \n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()   \n",
    "\n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        #connection.commit()\n",
    "    \n",
    "    # Insertar nuevos datos con pandas to_sql\n",
    "    df.to_sql(tabla, con= engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Obtener el valor máximo de la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX({columna_id}) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    \n",
    "    # Obtener el nombre de la secuencia asociada a la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"\"\"\n",
    "            SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\n",
    "        \"\"\"))\n",
    "        id_secuencia = result.scalar()  # Obtener el nombre de la secuencia\n",
    "    \n",
    "        \n",
    "    # Reiniciar el valor de la secuencia\n",
    "    with engine.connect() as connection:\n",
    "        # Si se tienen \n",
    "        if id_secuencia : connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "\n",
    "\n",
    "def update_plans_table(df, usuario, password, host, database, tabla, columna_id, ):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "\n",
    "    # Leer la tabla en un DataFrame de pandas\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabla}\", engine)\n",
    "\n",
    "    # Renombrar columna_id 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "\n",
    "    # Identificar las columna_ids que están en df pero no en df\n",
    "    missing_columns = [col for col in df.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columna_ids faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir/actualizar las columna_ids necesarias en df\n",
    "    df['id'] = df.index\n",
    "    df['is_active'] = True\n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()\n",
    "\n",
    "    # Obtener el nombre de la secuencia asociada a la columna_id 'id' en la tabla 'plans_test'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\"))\n",
    "        id_secuencia = result.scalar()  # Obtener el nombre de la secuencia\n",
    "\n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # Insertar nuevos datos con pandas to_sql\n",
    "    df.to_sql(tabla, engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Obtener el valor máximo de la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX(id) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    # Reiniciar el valor de la secuencia\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "\n",
    "# Ejemplo de uso\n",
    "# Definir el DataFrame df con tus datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasos\n",
    "1. Eliminar registros de activities\n",
    "2. Eliminar de tabla base que este relacionado\n",
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Eliminar datos tabla actividades\n",
    "eliminar_registros(tabla='activities')\n",
    "# Eliminar registros de la tabla base que tenga items relacionados\n",
    "query = 'delete from base where fk_plan is not null '\n",
    "ejecutar_query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install SQLAlchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.actions_id_seq en 16\n"
     ]
    }
   ],
   "source": [
    "# Tabla actions, darle formato y actualizar en BBDD\n",
    "df_action =format_dataframe(df_action,'actions')\n",
    "actualizar_tabla_postgres(df_action,'actions','id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla Periodicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>is_active</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dia(s)</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>semana(s)</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       name  is_active  created_by  updated_by deleted_by  \\\n",
       "id                                                                \n",
       "1    1     dia(s)       True           1           1       None   \n",
       "2    2  semana(s)       True           1           1       None   \n",
       "\n",
       "                         created_at                       updated_at  \\\n",
       "id                                                                     \n",
       "1  2022-05-30 12:05:19.768000-04:00 2022-05-30 12:05:19.768000-04:00   \n",
       "2  2022-05-30 12:05:19.768000-04:00 2022-05-30 12:05:19.768000-04:00   \n",
       "\n",
       "   deleted_at  \n",
       "id             \n",
       "1        None  \n",
       "2        None  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_periodicities = obtener_registros(tabla='periodicities')\n",
    "df_periodicities.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specialties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.specialties_id_seq en 9\n"
     ]
    }
   ],
   "source": [
    "df_speciality = format_dataframe(df_speciality,'specialties')\n",
    "df_speciality['description'] = df_speciality['name'] # no se crea automaticamente\n",
    "actualizar_tabla_postgres(df=df_speciality,tabla='specialties',columna_id='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.plans_id_seq en 279\n"
     ]
    }
   ],
   "source": [
    "# Tabla actions, darle formato y actualizar en BBDD\n",
    "df_plan = format_dataframe(df_plan,'plans')\n",
    "actualizar_tabla_postgres(df_plan,'plans','id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.usage_units_id_seq en 3\n"
     ]
    }
   ],
   "source": [
    "df_usage_units = pd.DataFrame(df_activities['fk_usage_unit'].dropna().unique(),columns=['value'])\n",
    "df_usage_units = format_dataframe(df_usage_units,'usage_units')\n",
    "df_usage_units['unit']=df_usage_units['name']           #TODO: ???\n",
    "df_usage_units['description']=df_usage_units['name']    #TODO: ???\n",
    "actualizar_tabla_postgres(df_usage_units,'usage_units',columna_id='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usage_units.index = df_usage_units.id    # Se coloca el id correspondiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocar el fk de la tabla de unidades de periodicidad\n",
    "df_activities['fk_periodicity_unit'] = df_activities['fk_periodicity_unit'].apply(lambda x: buscarIndice(df_periodicities,x,columna_busqueda='name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla df_activities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fk_classifiers_type</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>grup_1</th>\n",
       "      <th>notEnabled</th>\n",
       "      <th>is_active</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ACORDE A LA DISPONIBILIDAD</td>\n",
       "      <td>ACORDE A LA DISPONIBILIDAD</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-05-30 12:05:18.891000-04:00</td>\n",
       "      <td>2022-05-30 12:05:18.891000-04:00</td>\n",
       "      <td>2022-07-18 10:05:18.891000-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-30 12:05:18.891000-04:00</td>\n",
       "      <td>2022-05-30 12:05:18.891000-04:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  fk_classifiers_type                        name  \\\n",
       "id                                                        \n",
       "5    5                    3  ACORDE A LA DISPONIBILIDAD   \n",
       "17  17                    5                   ELECTRICO   \n",
       "\n",
       "                   description  grup_1 notEnabled  is_active  created_by  \\\n",
       "id                                                                         \n",
       "5   ACORDE A LA DISPONIBILIDAD       1       None      False           1   \n",
       "17                   ELECTRICO       1       None       True           1   \n",
       "\n",
       "    updated_by  deleted_by                       created_at  \\\n",
       "id                                                            \n",
       "5          1.0         1.0 2022-05-30 12:05:18.891000-04:00   \n",
       "17         1.0         NaN 2022-05-30 12:05:18.891000-04:00   \n",
       "\n",
       "                         updated_at                       deleted_at  \n",
       "id                                                                    \n",
       "5  2022-05-30 12:05:18.891000-04:00 2022-07-18 10:05:18.891000-04:00  \n",
       "17 2022-05-30 12:05:18.891000-04:00                              NaT  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener registros de la tabla classifiers\n",
    "df_classifiers = obtener_registros(tabla='classifiers')\n",
    "df_classifiers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activities = format_dataframe(df_activities,'activities')\n",
    "# Convertir en sus indices todas las columnas que tengan que ver con classifiers\n",
    "df_activities['fkc_activity_type'] =df_activities['fkc_activity_type'].apply(lambda x: buscarIndice(valor_busqueda=str(x),df=df_classifiers,columna_busqueda='name')) \n",
    "df_activities['fkc_priority'] = df_activities['fkc_priority'].apply(lambda x: buscarIndice(df_classifiers,valor_busqueda=x,columna_busqueda='name'))\n",
    "df_activities['fkc_regime'] = df_activities['fkc_regime'].apply(lambda x: buscarIndice(df_classifiers,valor_busqueda=x,columna_busqueda='name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fk_activity</th>\n",
       "      <th>fk_plan</th>\n",
       "      <th>fk_action</th>\n",
       "      <th>name</th>\n",
       "      <th>fkc_activity_type</th>\n",
       "      <th>fkc_priority</th>\n",
       "      <th>fk_specialty</th>\n",
       "      <th>fkc_regime</th>\n",
       "      <th>stoppage</th>\n",
       "      <th>time_interval_value</th>\n",
       "      <th>...</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>earliest_reschedule_days</th>\n",
       "      <th>latest_reschedule_days</th>\n",
       "      <th>earliest_reschedule_usage</th>\n",
       "      <th>latest_reschedule_usage</th>\n",
       "      <th>skippable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verificar la ausencia de ruidos y vibraciones ...</td>\n",
       "      <td>166</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-07 23:15:41.185341</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verificación de marcas de tornillería del moto...</td>\n",
       "      <td>166</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-10-07 23:15:41.185341</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fk_activity fk_plan  fk_action  \\\n",
       "1        None       1          1   \n",
       "2        None       1          1   \n",
       "\n",
       "                                                name  fkc_activity_type  \\\n",
       "1  Verificar la ausencia de ruidos y vibraciones ...                166   \n",
       "2  Verificación de marcas de tornillería del moto...                166   \n",
       "\n",
       "  fkc_priority  fk_specialty  fkc_regime stoppage  time_interval_value  ...  \\\n",
       "1            8             1         163    False                  1.0  ...   \n",
       "2            8             1         163    False                  1.0  ...   \n",
       "\n",
       "  created_by                 updated_at updated_by deleted_at  deleted_by  \\\n",
       "1          1 2024-10-07 23:15:41.185341          1       <NA>        <NA>   \n",
       "2          1 2024-10-07 23:15:41.185341          1       <NA>        <NA>   \n",
       "\n",
       "   earliest_reschedule_days latest_reschedule_days  earliest_reschedule_usage  \\\n",
       "1                      <NA>                   <NA>                       <NA>   \n",
       "2                      <NA>                   <NA>                       <NA>   \n",
       "\n",
       "  latest_reschedule_usage  skippable  \n",
       "1                    <NA>       <NA>  \n",
       "2                    <NA>       <NA>  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtener periodiciadad unit\n",
    "df_activities['fk_periodicity_unit'] = df_activities['fk_periodicity_unit'].apply(lambda x: buscarIndice(valor_busqueda=str(x),df=df_periodicities,columna_busqueda='name'))\n",
    "# obtener usage_unit\n",
    "df_activities['fk_usage_unit'] = df_activities['fk_usage_unit'].apply(lambda x: buscarIndice(valor_busqueda=str(x),df=df_usage_units,columna_busqueda='name'))\n",
    "df_activities.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "(psycopg2.errors.InvalidTextRepresentation) la sintaxis de entrada no es válida para tipo integer: «nan»\nLINE 1: ...l motor.', 166, 8, 1, 163, false, 1.0, '1', NULL, 'nan', 'd3...\n                                                             ^\n\n[SQL: INSERT INTO activities (fk_activity, fk_plan, fk_action, name, fkc_activity_type, fkc_priority, fk_specialty, fkc_regime, stoppage, time_interval_value, fk_periodicity_unit, usage_interval_value, fk_usage_unit, uuid, is_active, id, created_at, create ... 635102 characters truncated ... ys__999)s, %(earliest_reschedule_usage__999)s, %(latest_reschedule_usage__999)s, %(skippable__999)s)]\n[parameters: {'time_interval_value__0': 1.0, 'latest_reschedule_usage__0': None, 'id__0': 1, 'fk_activity__0': None, 'fk_periodicity_unit__0': '1', 'created_by__0': 1, 'fk_usage_unit__0': 'nan', 'earliest_reschedule_usage__0': None, 'fkc_regime__0': 163, 'deleted_at__0': None, 'uuid__0': 'd3fe7473-1ca4-4c1e-8bd1-8eb72b23d69f', 'usage_interval_value__0': None, 'latest_reschedule_days__0': None, 'created_at__0': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fk_action__0': 1, 'fk_plan__0': 1, 'is_active__0': True, 'updated_at__0': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fkc_activity_type__0': 166, 'stoppage__0': False, 'fk_specialty__0': 1, 'fkc_priority__0': 8, 'updated_by__0': 1, 'earliest_reschedule_days__0': None, 'skippable__0': None, 'name__0': 'Verificar la ausencia de ruidos y vibraciones anormales, no tocar el motor.', 'deleted_by__0': None, 'time_interval_value__1': 1.0, 'latest_reschedule_usage__1': None, 'id__1': 2, 'fk_activity__1': None, 'fk_periodicity_unit__1': '1', 'created_by__1': 1, 'fk_usage_unit__1': 'nan', 'earliest_reschedule_usage__1': None, 'fkc_regime__1': 163, 'deleted_at__1': None, 'uuid__1': 'c6b26728-4e12-4aab-b4c8-447057681a9a', 'usage_interval_value__1': None, 'latest_reschedule_days__1': None, 'created_at__1': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fk_action__1': 1, 'fk_plan__1': 1, 'is_active__1': True, 'updated_at__1': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fkc_activity_type__1': 166, 'stoppage__1': False, 'fk_specialty__1': 1, 'fkc_priority__1': 8, 'updated_by__1': 1 ... 26900 parameters truncated ... 'fk_periodicity_unit__998': '<NA>', 'created_by__998': 1, 'fk_usage_unit__998': 1, 'earliest_reschedule_usage__998': None, 'fkc_regime__998': 164, 'deleted_at__998': None, 'uuid__998': '5b6f906d-bf32-4058-8735-5ca0288ca6dc', 'usage_interval_value__998': 1800.0, 'latest_reschedule_days__998': None, 'created_at__998': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fk_action__998': 1, 'fk_plan__998': 117, 'is_active__998': True, 'updated_at__998': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fkc_activity_type__998': 166, 'stoppage__998': True, 'fk_specialty__998': 2, 'fkc_priority__998': 8, 'updated_by__998': 1, 'earliest_reschedule_days__998': None, 'skippable__998': None, 'name__998': 'Verificar el estado del bandaje de la polea (visual)', 'deleted_by__998': None, 'time_interval_value__999': None, 'latest_reschedule_usage__999': None, 'id__999': 1116, 'fk_activity__999': None, 'fk_periodicity_unit__999': '<NA>', 'created_by__999': 1, 'fk_usage_unit__999': 1, 'earliest_reschedule_usage__999': None, 'fkc_regime__999': 164, 'deleted_at__999': None, 'uuid__999': '95f4a0c8-3a12-4dfc-9aeb-a88b57c0539e', 'usage_interval_value__999': 1800.0, 'latest_reschedule_days__999': None, 'created_at__999': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fk_action__999': 1, 'fk_plan__999': 117, 'is_active__999': True, 'updated_at__999': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fkc_activity_type__999': 166, 'stoppage__999': True, 'fk_specialty__999': 2, 'fkc_priority__999': 8, 'updated_by__999': 1, 'earliest_reschedule_days__999': None, 'skippable__999': None, 'name__999': 'Verificar el movimiento de las basculas (manualmente con el cable levantado) (solo las que se puedan mover)', 'deleted_by__999': None}]\n(Background on this error at: https://sqlalche.me/e/20/9h9h)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidTextRepresentation\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2118\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2118\u001b[0m         \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2120\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2121\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInvalidTextRepresentation\u001b[0m: la sintaxis de entrada no es válida para tipo integer: «nan»\nLINE 1: ...l motor.', 166, 8, 1, 163, false, 1.0, '1', NULL, 'nan', 'd3...\n                                                             ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mactualizar_tabla_postgres\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_activities\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcolumna_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[66], line 62\u001b[0m, in \u001b[0;36mactualizar_tabla_postgres\u001b[1;34m(df, tabla, columna_id, usuario, password, host, database)\u001b[0m\n\u001b[0;32m     59\u001b[0m     connection\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Insertar los nuevos datos en la tabla\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtabla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Solo append en tablas con relaciones    \u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Obtener el valor máximo de la columna 'id'\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m connection:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\pandas\\io\\sql.py:2018\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2006\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m   2008\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[0;32m   2009\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   2010\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2015\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2016\u001b[0m )\n\u001b[1;32m-> 2018\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m \u001b[43msql_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\pandas\\io\\sql.py:1567\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(msg, err_text):\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf cannot be used with MySQL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\pandas\\io\\sql.py:1558\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mStatementError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\pandas\\io\\sql.py:1119\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m-> 1119\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\pandas\\io\\sql.py:1010\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;124;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[1;32m-> 1010\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1630\u001b[0m )\n\u001b[0;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1639\u001b[0m )\n\u001b[1;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1655\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m         ret,\n\u001b[0;32m   1660\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1841\u001b[0m context\u001b[38;5;241m.\u001b[39mpre_exec()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecute_style \u001b[38;5;129;01mis\u001b[39;00m ExecuteStyle\u001b[38;5;241m.\u001b[39mINSERTMANYVALUES:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_insertmany_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_single_context(\n\u001b[0;32m   1847\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1848\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2126\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2118\u001b[0m         dialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[0;32m   2119\u001b[0m             cursor,\n\u001b[0;32m   2120\u001b[0m             sub_stmt,\n\u001b[0;32m   2121\u001b[0m             sub_params,\n\u001b[0;32m   2122\u001b[0m             context,\n\u001b[0;32m   2123\u001b[0m         )\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_long_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2129\u001b[0m \u001b[43m        \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_sub_exec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine_events:\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   2137\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2138\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2142\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   2143\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2118\u001b[0m, in \u001b[0;36mConnection._exec_insertmany_context\u001b[1;34m(self, dialect, context)\u001b[0m\n\u001b[0;32m   2116\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   2117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2118\u001b[0m         \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2120\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2121\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   2127\u001b[0m         e,\n\u001b[0;32m   2128\u001b[0m         sql_util\u001b[38;5;241m.\u001b[39m_long_statement(sub_stmt),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2132\u001b[0m         is_sub_exec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2133\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dash\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mDataError\u001b[0m: (psycopg2.errors.InvalidTextRepresentation) la sintaxis de entrada no es válida para tipo integer: «nan»\nLINE 1: ...l motor.', 166, 8, 1, 163, false, 1.0, '1', NULL, 'nan', 'd3...\n                                                             ^\n\n[SQL: INSERT INTO activities (fk_activity, fk_plan, fk_action, name, fkc_activity_type, fkc_priority, fk_specialty, fkc_regime, stoppage, time_interval_value, fk_periodicity_unit, usage_interval_value, fk_usage_unit, uuid, is_active, id, created_at, create ... 635102 characters truncated ... ys__999)s, %(earliest_reschedule_usage__999)s, %(latest_reschedule_usage__999)s, %(skippable__999)s)]\n[parameters: {'time_interval_value__0': 1.0, 'latest_reschedule_usage__0': None, 'id__0': 1, 'fk_activity__0': None, 'fk_periodicity_unit__0': '1', 'created_by__0': 1, 'fk_usage_unit__0': 'nan', 'earliest_reschedule_usage__0': None, 'fkc_regime__0': 163, 'deleted_at__0': None, 'uuid__0': 'd3fe7473-1ca4-4c1e-8bd1-8eb72b23d69f', 'usage_interval_value__0': None, 'latest_reschedule_days__0': None, 'created_at__0': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fk_action__0': 1, 'fk_plan__0': 1, 'is_active__0': True, 'updated_at__0': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fkc_activity_type__0': 166, 'stoppage__0': False, 'fk_specialty__0': 1, 'fkc_priority__0': 8, 'updated_by__0': 1, 'earliest_reschedule_days__0': None, 'skippable__0': None, 'name__0': 'Verificar la ausencia de ruidos y vibraciones anormales, no tocar el motor.', 'deleted_by__0': None, 'time_interval_value__1': 1.0, 'latest_reschedule_usage__1': None, 'id__1': 2, 'fk_activity__1': None, 'fk_periodicity_unit__1': '1', 'created_by__1': 1, 'fk_usage_unit__1': 'nan', 'earliest_reschedule_usage__1': None, 'fkc_regime__1': 163, 'deleted_at__1': None, 'uuid__1': 'c6b26728-4e12-4aab-b4c8-447057681a9a', 'usage_interval_value__1': None, 'latest_reschedule_days__1': None, 'created_at__1': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fk_action__1': 1, 'fk_plan__1': 1, 'is_active__1': True, 'updated_at__1': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fkc_activity_type__1': 166, 'stoppage__1': False, 'fk_specialty__1': 1, 'fkc_priority__1': 8, 'updated_by__1': 1 ... 26900 parameters truncated ... 'fk_periodicity_unit__998': '<NA>', 'created_by__998': 1, 'fk_usage_unit__998': 1, 'earliest_reschedule_usage__998': None, 'fkc_regime__998': 164, 'deleted_at__998': None, 'uuid__998': '5b6f906d-bf32-4058-8735-5ca0288ca6dc', 'usage_interval_value__998': 1800.0, 'latest_reschedule_days__998': None, 'created_at__998': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fk_action__998': 1, 'fk_plan__998': 117, 'is_active__998': True, 'updated_at__998': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fkc_activity_type__998': 166, 'stoppage__998': True, 'fk_specialty__998': 2, 'fkc_priority__998': 8, 'updated_by__998': 1, 'earliest_reschedule_days__998': None, 'skippable__998': None, 'name__998': 'Verificar el estado del bandaje de la polea (visual)', 'deleted_by__998': None, 'time_interval_value__999': None, 'latest_reschedule_usage__999': None, 'id__999': 1116, 'fk_activity__999': None, 'fk_periodicity_unit__999': '<NA>', 'created_by__999': 1, 'fk_usage_unit__999': 1, 'earliest_reschedule_usage__999': None, 'fkc_regime__999': 164, 'deleted_at__999': None, 'uuid__999': '95f4a0c8-3a12-4dfc-9aeb-a88b57c0539e', 'usage_interval_value__999': 1800.0, 'latest_reschedule_days__999': None, 'created_at__999': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fk_action__999': 1, 'fk_plan__999': 117, 'is_active__999': True, 'updated_at__999': datetime.datetime(2024, 10, 7, 23, 15, 41, 185341), 'fkc_activity_type__999': 166, 'stoppage__999': True, 'fk_specialty__999': 2, 'fkc_priority__999': 8, 'updated_by__999': 1, 'earliest_reschedule_days__999': None, 'skippable__999': None, 'name__999': 'Verificar el movimiento de las basculas (manualmente con el cable levantado) (solo las que se puedan mover)', 'deleted_by__999': None}]\n(Background on this error at: https://sqlalche.me/e/20/9h9h)"
     ]
    }
   ],
   "source": [
    "actualizar_tabla_postgres(df_activities,'activities',columna_id='id')\n",
    "\n",
    "#InvalidTextRepresentation: la sintaxis de entrada no es válida para tipo integer: «nan»\n",
    "#LINE 1: ...l motor.', 166, 8, 1, 163, false, 1.0, '1', NULL, 'nan', 'd3...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completar unidades medida y de uso\n",
    "\n",
    "De df_activities de la columna fk_periodicity_unit, si el valor de la columna es ['horas','ciclos'] mover el contenido de la columna time_interval_value a la columna usage_interval_value en la columna time_interval_value dejar con valor nulo, y mover el valor de la columna fk_peridicity_unit  a la columna fk_usage_unit y en la columna fk_periodicity_unit dejar en nulo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valores_a_mover = ['horas', 'ciclos']\n",
    "#df_activities.loc[df_activities['fk_periodicity_unit'].isin(valores_a_mover)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar las condiciones solicitadas en df_activities\n",
    "# Definir los valores de fk_periodicity_unit para los cuales se debe mover la información\n",
    "#valores_a_mover = ['horas', 'ciclos']\n",
    "\n",
    "# Filtrar y aplicar los cambios correspondientes, mover los valores a las columnas de uso\n",
    "#df_activities.loc[df_activities['fk_periodicity_unit'].isin(valores_a_mover), 'usage_interval_value'] = df_activities['time_interval_value']\n",
    "#df_activities.loc[df_activities['fk_periodicity_unit'].isin(valores_a_mover), 'fk_usage_unit'] = df_activities['fk_periodicity_unit']\n",
    "\n",
    "# Colocar los valores en las columnas timer_interva_value y fk_periodicity_unit en nulo\n",
    "#df_activities.loc[df_activities['fk_periodicity_unit'].isin(valores_a_mover), 'time_interval_value'] = pd.NA\n",
    "#df_activities.loc[df_activities['fk_periodicity_unit'].isin(valores_a_mover), 'fk_periodicity_unit'] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaciones con tabla classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sqlalchemy==1.4.23 psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Temporal\n",
    "# conexion a la base de datos en produccion\n",
    "usuario = 'postgres'\n",
    "contraseña = 'postgres'\n",
    "host ='localhost'\n",
    "db_produccion = 'simyo3'\n",
    "\n",
    "\n",
    "try:\n",
    "    # Intenta importar el paquete\n",
    "    from sqlalchemy import create_engine\n",
    "except ModuleNotFoundError:\n",
    "    # El paquete no está instalado\n",
    "    print(\"El paquete no está instalado\")\n",
    "    # Instala el paquete\n",
    "    !pip install sqlalchemy\n",
    "    from sqlalchemy import create_engine\n",
    "finally:\n",
    "    engine_produccion = create_engine(f'postgresql://{usuario}:{contraseña}@{host}/{db_produccion}')\n",
    "    connection = f\"postgresql+psycopg2://{usuario}:{contraseña}@{host}/{db_produccion}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalación\n",
    "Se colocaron todos los paquetes que se utilizan en el proyecto en el archivo paquetes.txt\n",
    "En caso que no funcione utilizar:\n",
    "\n",
    "<code> pip install SQLAlchemy psycopg2-binary </code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar a archivo excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)      \n",
    "######################    \n",
    "\n",
    "#####################\n",
    "with pd.ExcelWriter(\"output/\"+salida.value) as writer:\n",
    "    df_action.to_excel(writer, sheet_name='actions')\n",
    "    df_plan.to_excel(writer, sheet_name='plans')\n",
    "    df_speciality.to_excel(writer, sheet_name='specialties')\n",
    "    df_activities.to_excel(writer, sheet_name='activities')\n",
    "\n",
    "# gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\\nimport warnings\\nimport pandas as pd\\nimport ipywidgets as widgets\\nfrom ipywidgets import Button, Layout\\nfrom IPython.display import display\\n\\n#warnings.simplefilter(action=\\'ignore\\', category=FutureWarning)\\n\\nvalores = {\\n    \"D\": 1,\\n    \"S\": 1,\\n    \"2S\": 2,\\n    \"M\": 5,\\n    \"MC\": 1,\\n    \"2M\": 2,\\n    \"T\": 3,\\n    \"SE\": 6,\\n    \"8M\": 8,\\n    \"A\": 1,\\n    \"1.5A\": 18,\\n    \"2A\": 2,\\n    \"3A\": 3,\\n    \"4A\": 4,\\n    \"5A\": 5,\\n    \"6A\": 6,\\n    \"8A\": 8,\\n    \"10A\": 10,\\n    \"1000\": 1000,\\n    \"1300\": 1300,\\n    \"1800\": 1800,\\n    \"6000\": 6000,\\n    \"22500\": 6000,\\n    \"40000\": 40000,\\n    \"55000\": 55000,\\n    \"55000C\": 55000\\n}\\n\\nregimen = {\\n    \"D\": \\'dia\\',\\n    \"S\": \\'semana\\',\\n    \"2S\": \\'semana\\',\\n    \"M\": \\'semana\\',\\n    \"MC\": \\'mes\\',\\n    \"2M\": \\'mes\\',\\n    \"T\": \\'mes\\',\\n    \"SE\": \\'mes\\',\\n    \"8M\": \\'mes\\',\\n    \"A\": \\'Año\\',\\n    \"1.5A\": \\'mes\\',\\n    \"2A\": \\'Año\\',\\n    \"3A\": \\'Año\\',\\n    \"4A\": \\'Año\\',\\n    \"5A\": \\'Año\\',\\n    \"6A\": \\'Año\\',\\n    \"8A\": \\'Año\\',\\n    \"10A\": \\'Año\\',\\n    \"1000\": \\'horas\\',\\n    \"1300\": \\'horas\\',\\n    \"1800\": \\'horas\\',\\n    \"6000\": \\'horas\\',\\n    \"22500\": \\'horas\\',\\n    \"40000\": \\'horas\\',\\n    \"55000\": \\'horas\\',\\n    \"55000C\": \\'ciclos\\'\\n}\\n\\nlad = widgets.Textarea(value=\\'https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294\\',placeholder=\\'Plan Maestro LAD\\',description=\\'Lineas Alta Demanda:\\',disabled=False,layout=Layout(width=\\'70%\\',height=\"200px\"))\\nlbd = widgets.Textarea(value=\\'https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294\\',placeholder=\\'Plan Maestro LBD\\',description=\\'Lineas Baja Demanda:\\',disabled=False,layout=Layout(width=\\'70%\\',height=\"200px\"))\\nhost = widgets.Text(value=\\'192.168.100.50\\',placeholder=\\'Host\\',description=\\'Host:\\',disabled=False)\\nbasedatos = widgets.Text(value=\\'simyo2\\',placeholder=\\'BaseDatos\\',description=\\'BaseDatos\\',disabled=False)\\nusuario = widgets.Text(value=\\'mantto\\',description=\\'Usuario\\')\\npassword = widgets.Password(value=\\'Sistemas0\\',description=\\'Password\\')\\nbutton1 = widgets.Button(description=\"Generar Archivo Excel\",button_style=\\'success\\',layout=Layout(width=\\'20%\\'))\\nbutton2 = widgets.Button(description=\"Cargar en Base de datos\",button_style=\\'danger\\',layout=Layout(width=\\'20%\\'))\\noutput = widgets.Output()\\nsalida = widgets.Text(value=\"Salida.xlsx\",description=\"Nombre:\",disabled=False)\\naccordion = widgets.Accordion(children=[ salida], titles=([\\'Archivo Salida\\']))\\naccordion1 = widgets.Accordion(children=[ usuario,password,host,basedatos], titles=(\\'Usuario\\',\\'Password\\',\\'Host\\',\\'Base de Datos\\'))\\n\\ndisplay(lad,lbd,host,usuario,password,accordion,button1, accordion1,button2,output)\\n\\ndef on_button_clicked(b):    \\n    # Combinacion de dataframes\\n    gs1 = GoogleSheetProcessor(lad.value) #(\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294\")\\n    archivo = \"input/pad.csv\"\\n    #gs.download_csv(archivo)\\n    df1 = gs1.read_csv(archivo)\\n\\n    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294\")\\n    archivo = \"input/pbd.csv\"\\n    #gs.download_csv(archivo)\\n    df2 = gs2.read_csv(archivo)\\n    # Realizar el merge de ambos planes en un solo dataframe\\n    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\\n\\n    filename = \"input/mix_plan.csv\"\\n    df_merged.to_csv(filename)\\n    \\n    #df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)      \\n######################    \\n\\n#####################\\n\\n    df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)  \\n    with pd.ExcelWriter(\"output/\"+salida.value) as writer:\\n        df_action.to_excel(writer, sheet_name=\\'actions\\')\\n        df_plan.to_excel(writer, sheet_name=\\'plans\\')\\n        df_speciality.to_excel(writer, sheet_name=\\'specialties\\')\\n        filtered_data.to_excel(writer, sheet_name=\\'activities\\')\\n    \\n    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \\n    with output:\\n        print(\"Se Genera archivo excel Salida.xlsx\")\\n\\nbutton1.on_click(on_button_clicked)\\nbutton2.on_click(lambda _: print(\"Boton 2 accionado\"))\\n#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import display\n",
    "\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "valores = {\n",
    "    \"D\": 1,\n",
    "    \"S\": 1,\n",
    "    \"2S\": 2,\n",
    "    \"M\": 5,\n",
    "    \"MC\": 1,\n",
    "    \"2M\": 2,\n",
    "    \"T\": 3,\n",
    "    \"SE\": 6,\n",
    "    \"8M\": 8,\n",
    "    \"A\": 1,\n",
    "    \"1.5A\": 18,\n",
    "    \"2A\": 2,\n",
    "    \"3A\": 3,\n",
    "    \"4A\": 4,\n",
    "    \"5A\": 5,\n",
    "    \"6A\": 6,\n",
    "    \"8A\": 8,\n",
    "    \"10A\": 10,\n",
    "    \"1000\": 1000,\n",
    "    \"1300\": 1300,\n",
    "    \"1800\": 1800,\n",
    "    \"6000\": 6000,\n",
    "    \"22500\": 6000,\n",
    "    \"40000\": 40000,\n",
    "    \"55000\": 55000,\n",
    "    \"55000C\": 55000\n",
    "}\n",
    "\n",
    "regimen = {\n",
    "    \"D\": 'dia',\n",
    "    \"S\": 'semana',\n",
    "    \"2S\": 'semana',\n",
    "    \"M\": 'semana',\n",
    "    \"MC\": 'mes',\n",
    "    \"2M\": 'mes',\n",
    "    \"T\": 'mes',\n",
    "    \"SE\": 'mes',\n",
    "    \"8M\": 'mes',\n",
    "    \"A\": 'Año',\n",
    "    \"1.5A\": 'mes',\n",
    "    \"2A\": 'Año',\n",
    "    \"3A\": 'Año',\n",
    "    \"4A\": 'Año',\n",
    "    \"5A\": 'Año',\n",
    "    \"6A\": 'Año',\n",
    "    \"8A\": 'Año',\n",
    "    \"10A\": 'Año',\n",
    "    \"1000\": 'horas',\n",
    "    \"1300\": 'horas',\n",
    "    \"1800\": 'horas',\n",
    "    \"6000\": 'horas',\n",
    "    \"22500\": 'horas',\n",
    "    \"40000\": 'horas',\n",
    "    \"55000\": 'horas',\n",
    "    \"55000C\": 'ciclos'\n",
    "}\n",
    "\n",
    "lad = widgets.Textarea(value='https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294',placeholder='Plan Maestro LAD',description='Lineas Alta Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "lbd = widgets.Textarea(value='https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294',placeholder='Plan Maestro LBD',description='Lineas Baja Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "host = widgets.Text(value='192.168.100.50',placeholder='Host',description='Host:',disabled=False)\n",
    "basedatos = widgets.Text(value='simyo2',placeholder='BaseDatos',description='BaseDatos',disabled=False)\n",
    "usuario = widgets.Text(value='mantto',description='Usuario')\n",
    "password = widgets.Password(value='Sistemas0',description='Password')\n",
    "button1 = widgets.Button(description=\"Generar Archivo Excel\",button_style='success',layout=Layout(width='20%'))\n",
    "button2 = widgets.Button(description=\"Cargar en Base de datos\",button_style='danger',layout=Layout(width='20%'))\n",
    "output = widgets.Output()\n",
    "salida = widgets.Text(value=\"Salida.xlsx\",description=\"Nombre:\",disabled=False)\n",
    "accordion = widgets.Accordion(children=[ salida], titles=(['Archivo Salida']))\n",
    "accordion1 = widgets.Accordion(children=[ usuario,password,host,basedatos], titles=('Usuario','Password','Host','Base de Datos'))\n",
    "\n",
    "display(lad,lbd,host,usuario,password,accordion,button1, accordion1,button2,output)\n",
    "\n",
    "def on_button_clicked(b):    \n",
    "    # Combinacion de dataframes\n",
    "    gs1 = GoogleSheetProcessor(lad.value) #(\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294\")\n",
    "    archivo = \"input/pad.csv\"\n",
    "    #gs.download_csv(archivo)\n",
    "    df1 = gs1.read_csv(archivo)\n",
    "\n",
    "    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294\")\n",
    "    archivo = \"input/pbd.csv\"\n",
    "    #gs.download_csv(archivo)\n",
    "    df2 = gs2.read_csv(archivo)\n",
    "    # Realizar el merge de ambos planes en un solo dataframe\n",
    "    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    filename = \"input/mix_plan.csv\"\n",
    "    df_merged.to_csv(filename)\n",
    "    \n",
    "    #df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)      \n",
    "######################    \n",
    "\n",
    "#####################\n",
    "\n",
    "    df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)  \n",
    "    with pd.ExcelWriter(\"output/\"+salida.value) as writer:\n",
    "        df_action.to_excel(writer, sheet_name='actions')\n",
    "        df_plan.to_excel(writer, sheet_name='plans')\n",
    "        df_speciality.to_excel(writer, sheet_name='specialties')\n",
    "        filtered_data.to_excel(writer, sheet_name='activities')\n",
    "    \n",
    "    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \n",
    "    with output:\n",
    "        print(\"Se Genera archivo excel Salida.xlsx\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(lambda _: print(\"Boton 2 accionado\"))\n",
    "#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las columnas y sus tipos de datos de la columna activities\n",
    "query = \"\"\"\n",
    "SELECT column_name\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = 'activities' order by ordinal_position asc;\n",
    "\"\"\"\n",
    "df_columnas_activities = ejecutar_query(query)\n",
    "df_columnas_activities['column_name']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
