{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "class GoogleSheetProcessor:\n",
    "    def __init__(self, sheet_url1: str):\n",
    "        self.sheet_url1 = sheet_url1\n",
    "        self.spreadsheet_id = self.extract_spreadsheet_id(sheet_url1)\n",
    "        self.sheet_id = self.extract_sheet_id(sheet_url1)\n",
    "        self.csv_export_url = self.construct_csv_export_url()\n",
    "\n",
    "    def extract_spreadsheet_id(self, url: str):\n",
    "        return url.split('/d/')[1].split('/')[0]\n",
    "\n",
    "    def extract_sheet_id(self, url: str):\n",
    "        return url.split('gid=')[1]\n",
    "\n",
    "    def construct_csv_export_url(self):\n",
    "        return f\"https://docs.google.com/spreadsheets/d/{self.spreadsheet_id}/export?format=csv&gid={self.sheet_id}\"\n",
    "\n",
    "    def download_csv(self, output_filename: str = 'temp_sheet.csv'):\n",
    "        # Descarga el archivo CSV y lo guarda temporalmente\n",
    "        response = requests.get(self.csv_export_url)\n",
    "        response.raise_for_status()  # Asegurarse de que la solicitud fue exitosa\n",
    "        with open(output_filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return pd.read_csv(output_filename)\n",
    "\n",
    "    def validate_no_duplicate_columns(self, df: pd.DataFrame):\n",
    "        # Validar si existen columnas duplicadas en el DataFrame\n",
    "        duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "        if not duplicate_columns.empty:\n",
    "            raise ValueError(\n",
    "                f\"Columnas duplicadas encontradas: {duplicate_columns.tolist()}\")\n",
    "\n",
    "    def convertir_booleano_amef(self, df: pd.DataFrame, ini: int, end: int):\n",
    "        \"\"\"\n",
    "        Convierte a tipo booleano las columnas en el rango dado, si no son ya booleanas.\n",
    "\n",
    "        Parámetros:\n",
    "        - df: DataFrame en el que se realizará la conversión.\n",
    "        - ini: Índice de la columna inicial.\n",
    "        - end: Índice de la columna final.\n",
    "\n",
    "        Retorna:\n",
    "        - DataFrame con las columnas convertidas a booleano.\n",
    "        \"\"\"\n",
    "        # Iterar sobre las columnas en el rango especificado\n",
    "        for col in df.columns[ini + 1:end]:\n",
    "            # Verificar si la columna no es de tipo booleano\n",
    "            if df[col].dtype != bool:\n",
    "                # Convertir la columna a booleano\n",
    "                df[col] = df[col].map(lambda x: True if str(\n",
    "                    x).upper() == 'TRUE' else False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def load_data_from_postgres(\n",
    "            self,\n",
    "            db_url: str = 'postgresql://postgres:postgres@localhost/simyo',\n",
    "            query: str = \"\"\"\n",
    "                SELECT\n",
    "                    base.\"id\",\n",
    "                    \"structure\".tag,\n",
    "                    locations.location_code,\n",
    "                    \"plans\".\"name\",\n",
    "                    base.fk_plan\n",
    "                FROM\n",
    "                    base\n",
    "                    INNER JOIN\n",
    "                    locations\n",
    "                    ON\n",
    "                        base.fk_location = locations.\"id\"\n",
    "                    INNER JOIN\n",
    "                    \"structure\"\n",
    "                    ON\n",
    "                        base.fk_structure = \"structure\".\"id\"\n",
    "                    LEFT JOIN\n",
    "                    \"plans\"\n",
    "                    ON\n",
    "                        base.fk_plan = \"plans\".\"id\"\n",
    "                \"\"\"):\n",
    "        \"\"\"\n",
    "        Conecta a la base de datos PostgreSQL, ejecuta la consulta SQL y devuelve un DataFrame.\n",
    "\n",
    "        Parámetros:\n",
    "        - db_url (str): URL de la base de datos PostgreSQL.\n",
    "        - query (str): Consulta SQL a ejecutar.\n",
    "\n",
    "        Retorna:\n",
    "        - DataFrame con los datos obtenidos de la consulta.\n",
    "        \"\"\"\n",
    "        # Crear un engine de SQLAlchemy para conectarse a la base de datos\n",
    "        engine = sqlalchemy.create_engine(db_url)\n",
    "\n",
    "        # Ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "\n",
    "        # Establecer la columna 'id' como índice del DataFrame\n",
    "        df.index = df['id'].values\n",
    "\n",
    "        return df\n",
    "\n",
    "    def process_dataframe(self, df: pd.DataFrame, columns_to_remove: list):\n",
    "\n",
    "        # Si existen columnas con nombres duplicados, arrojar un error de columnas duplicadas\n",
    "        if df.columns.duplicated().any():\n",
    "            assert False, \"Hay columnas duplicadas en el DataFrame df1\"\n",
    "        # Eliminar columnas innecesarias\n",
    "        df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "        # Eliminar filas donde 'TIPO' tenga valores 'Sistema' o 'Subsistema'\n",
    "        df = df[~df['Tipo_equipo'].isin(['Sistema', 'Subsistema'])] # \n",
    "\n",
    "        # Filtrar filas donde la columna 'Plan' no sea nula\n",
    "        df = df[df['Plan'].notna()]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_output_dataframe(self, df: pd.DataFrame):\n",
    "        # Crear un DataFrame de salida con columnas específicas\n",
    "        # Iterar sobre las filas del dataframe\n",
    "        df_salida = pd.DataFrame()\n",
    "        for index, row in df.iterrows():\n",
    "            # Buscar el índice de la columna 'AMEF'\n",
    "            try:\n",
    "                amef_index = df.columns.get_loc('AMEF')\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            # Iterar a partir de la columna siguiente a 'AMEF'\n",
    "            for col in df.columns[amef_index + 1:]:\n",
    "                # print(col)\n",
    "                if row[col] == True:  # Si el valor es True\n",
    "                    # Adicionar una nueva fila al dataframe de salida\n",
    "                    new_row = pd.DataFrame({\n",
    "                        'tag': [row['Tag']],\n",
    "                        'location_code': [col],\n",
    "                        'plan': [row['Plan']]\n",
    "                    })\n",
    "                    df_salida = pd.concat(\n",
    "                        [df_salida, new_row], ignore_index=True)\n",
    "        return df_salida\n",
    "\n",
    "    def load_data_from_db(self, query: str, db_path: str):\n",
    "        # Cargar datos desde una base de datos SQLite\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        df_db = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return df_db\n",
    "\n",
    "    def read_csv(self, filename=\"temp_sheet.csv\", column_row=None, row_ini=None):\n",
    "        # Lee el archivo CSV usando pandas\n",
    "        # df = pd.DataFrame()\n",
    "        df = pd.read_csv(filename, header=column_row,\n",
    "                         skiprows=None, skipfooter=0)\n",
    "        if column_row and row_ini is None:\n",
    "            return df\n",
    "        else:\n",
    "            df.columns = df.loc[column_row, :].to_list()  # la fila 2 como fila\n",
    "            df = df.loc[row_ini:, :]   # Obtener desde la fila 4 en adelante\n",
    "            return df\n",
    "\n",
    "    def merge_dataframes(self, df1: pd.DataFrame, df2: pd.DataFrame, on_columns: list):\n",
    "        # Realizar el merge de dos DataFrames\n",
    "        return pd.merge(df1, df2, on=on_columns, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "    def process(\n",
    "            self,\n",
    "            df_input,\n",
    "            columns_to_remove: list = ['RO', 'AM', 'AZ', 'MO', 'VE', 'BL', 'NA', 'CE', 'CA', 'PL']):\n",
    "        # Método principal que engloba toda la lógica\n",
    "        # df = self.download_csv()  # Descarga y carga del CSV\n",
    "        # df = self.read_csv(filename=filename_input,column_row=2,row_ini=4)\n",
    "        # print(filename_input)\n",
    "        # df = pd.read_csv(filename_input)\n",
    "\n",
    "        # self.validate_no_duplicate_columns(df)  # Validar columnas duplicadas\n",
    "        # Método principal que engloba toda la lógica\n",
    "        df = self.process_dataframe(\n",
    "            df_input, columns_to_remove)  # Procesar el DataFrame\n",
    "        amef_index = df.columns.get_loc('AMEF')\n",
    "        end = len(df.columns)\n",
    "        df = self.convertir_booleano_amef(df, amef_index, end)\n",
    "        # Crear DataFrame de salida\n",
    "        df_output = self.create_output_dataframe(df)\n",
    "\n",
    "        cantidad_activos = df.iloc[:, amef_index + 1:].sum().sum()\n",
    "        print(f\"Existen {cantidad_activos} activos en la hoja de datos\")\n",
    "        if len(df_output) != cantidad_activos:\n",
    "            assert False, \"La cantidad de activos no corresponde con la salida\"\n",
    "        \n",
    "        # Cargar datos desde la base de datos\n",
    "        df_db = self.load_data_from_postgres()  \n",
    "        # Merge de DataFrames\n",
    "        df_result = self.merge_dataframes(df_output, df_db, ['tag', 'location_code'])  \n",
    "\n",
    "        return df_output, df_db, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ## Script 2\\n# https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\\nimport warnings\\nimport pandas as pd\\nimport ipywidgets as widgets\\nfrom ipywidgets import Button, Layout\\nfrom IPython.display import display\\n\\n#warnings.simplefilter(action=\\'ignore\\', category=FutureWarning)\\n\\nlad = widgets.Textarea(value=\\'https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\\',placeholder=\\'Plan Maestro LAD\\',description=\\'Lineas Alta Demanda:\\',disabled=False,layout=Layout(width=\\'70%\\',height=\"200px\"))\\nlbd = widgets.Textarea(value=\\'https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\\',placeholder=\\'Plan Maestro LBD\\',description=\\'Lineas Baja Demanda:\\',disabled=False,layout=Layout(width=\\'70%\\',height=\"200px\"))\\nhost = widgets.Text(value=\\'192.168.100.50\\',placeholder=\\'Host\\',description=\\'Host:\\',disabled=False)\\nbasedatos = widgets.Text(value=\\'simyo2\\',placeholder=\\'BaseDatos\\',description=\\'BaseDatos\\',disabled=False)\\nusuario = widgets.Text(value=\\'mantto\\',description=\\'Usuario\\')\\npassword = widgets.Password(value=\\'Sistemas0\\',description=\\'Password\\')\\nbutton1 = widgets.Button(description=\"Generar Archivo Excel\",button_style=\\'success\\',layout=Layout(width=\\'20%\\'))\\nbutton2 = widgets.Button(description=\"Cargar en Base de datos\",button_style=\\'danger\\',layout=Layout(width=\\'20%\\'))\\noutput = widgets.Output()\\nsalida = widgets.Text(value=\"output/Salida_Planes.xlsx\",description=\"Nombre:\",disabled=False)\\naccordion = widgets.Accordion(children=[ salida], titles=([\\'Archivo Salida\\']))\\naccordion1 = widgets.Accordion(children=[ usuario,password,host,basedatos], titles=(\\'Usuario\\',\\'Password\\',\\'Host\\',\\'Base de Datos\\'))\\n\\ndisplay(lad,lbd,host,usuario,password,accordion,button1, accordion1,button2,output)\\n\\ndef on_button_clicked(b):    \\n    # Combinacion de dataframes\\n    gs1 = GoogleSheetProcessor(lad.value) # (\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\")\\n    archivo = \"input/pad_planes.csv\"\\n    #gs1.download_csv(archivo)\\n    df1 = pd.read_csv(archivo,header=3,true_values=[\\'True\\',\\'TRUE\\'],false_values=[\\'False\\',\"FALSE\",\"\"])\\n\\n\\n    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\")\\n    archivo = \"input/pbd_planes.csv\"\\n    #gs2.download_csv(archivo)\\n    df2 = pd.read_csv(archivo,header=3,true_values=[\\'True\\',\\'TRUE\\'],false_values=[\\'False\\',\"FALSE\",\"\"])\\n\\n    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\\n    filename = \"input/mix_planes.csv\"\\n    df_merged.to_csv(filename,sep=\\';\\')\\n\\n    df_output, df_db, df_result=gs1.process(df_merged)\\n    df_result.to_excel(salida.value)\\n    \\n    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \\n    with output:\\n        print(f\"Se Genera archivo excel {salida.value}\")\\n\\nbutton1.on_click(on_button_clicked)\\nbutton2.on_click(lambda _: print(\"Boton 2 accionado\"))\\n#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html\\n## Script 2 '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ## Script 2\n",
    "# https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import display\n",
    "\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "lad = widgets.Textarea(value='https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678',placeholder='Plan Maestro LAD',description='Lineas Alta Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "lbd = widgets.Textarea(value='https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678',placeholder='Plan Maestro LBD',description='Lineas Baja Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "host = widgets.Text(value='192.168.100.50',placeholder='Host',description='Host:',disabled=False)\n",
    "basedatos = widgets.Text(value='simyo2',placeholder='BaseDatos',description='BaseDatos',disabled=False)\n",
    "usuario = widgets.Text(value='mantto',description='Usuario')\n",
    "password = widgets.Password(value='Sistemas0',description='Password')\n",
    "button1 = widgets.Button(description=\"Generar Archivo Excel\",button_style='success',layout=Layout(width='20%'))\n",
    "button2 = widgets.Button(description=\"Cargar en Base de datos\",button_style='danger',layout=Layout(width='20%'))\n",
    "output = widgets.Output()\n",
    "salida = widgets.Text(value=\"output/Salida_Planes.xlsx\",description=\"Nombre:\",disabled=False)\n",
    "accordion = widgets.Accordion(children=[ salida], titles=(['Archivo Salida']))\n",
    "accordion1 = widgets.Accordion(children=[ usuario,password,host,basedatos], titles=('Usuario','Password','Host','Base de Datos'))\n",
    "\n",
    "display(lad,lbd,host,usuario,password,accordion,button1, accordion1,button2,output)\n",
    "\n",
    "def on_button_clicked(b):    \n",
    "    # Combinacion de dataframes\n",
    "    gs1 = GoogleSheetProcessor(lad.value) # (\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\")\n",
    "    archivo = \"input/pad_planes.csv\"\n",
    "    #gs1.download_csv(archivo)\n",
    "    df1 = pd.read_csv(archivo,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n",
    "\n",
    "\n",
    "    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\")\n",
    "    archivo = \"input/pbd_planes.csv\"\n",
    "    #gs2.download_csv(archivo)\n",
    "    df2 = pd.read_csv(archivo,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n",
    "\n",
    "    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "    filename = \"input/mix_planes.csv\"\n",
    "    df_merged.to_csv(filename,sep=';')\n",
    "\n",
    "    df_output, df_db, df_result=gs1.process(df_merged)\n",
    "    df_result.to_excel(salida.value)\n",
    "    \n",
    "    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \n",
    "    with output:\n",
    "        print(f\"Se Genera archivo excel {salida.value}\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(lambda _: print(\"Boton 2 accionado\"))\n",
    "#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html\n",
    "## Script 2 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "descargar = False\n",
    "url_alta_demanda =\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\"\n",
    "archivo_ad = \"input/pad.csv\"\n",
    "url_baja_demanda = \"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\"\n",
    "archivo_bd = \"input/pbd.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinacion de dataframes\n",
    "gs1 = GoogleSheetProcessor(url_baja_demanda)\n",
    "if descargar : gs1.download_csv(archivo_ad)\n",
    "df1 = pd.read_csv(archivo_ad,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GoogleSheetProcessor (url_baja_demanda)\n",
    "\n",
    "if descargar: gs2.download_csv(archivo_bd)\n",
    "df2 = pd.read_csv(archivo_bd,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "filename = \"input/mix_planes.csv\"\n",
    "df_merged.to_csv(filename,sep=';')  # Exportar archivo mezclado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existen 12815 activos en la hoja de datos\n"
     ]
    }
   ],
   "source": [
    "df_output, df_db, df_result=gs1.process(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>location_code</th>\n",
       "      <th>name</th>\n",
       "      <th>fk_plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ACC-PRI-MEPA</td>\n",
       "      <td>RO-S2-M1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ACC-PRI-MEPA</td>\n",
       "      <td>RO-S1-M1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ACC-PRI-MEPA</td>\n",
       "      <td>AM-S1-M1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACC-PRI-MEPA</td>\n",
       "      <td>AM-S2-M1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ACC-PRI-MEPA</td>\n",
       "      <td>VE-S2-M1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20307</th>\n",
       "      <td>20307</td>\n",
       "      <td>LIN-VEH-V176-CELF2</td>\n",
       "      <td>BL-LIN-VH-V176</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20135</th>\n",
       "      <td>20135</td>\n",
       "      <td>LIN-VEH-V148-CBN</td>\n",
       "      <td>BL-LIN-VH-V148</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20133</th>\n",
       "      <td>20133</td>\n",
       "      <td>LIN-VEH-V148-SUS</td>\n",
       "      <td>BL-LIN-VH-V148</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20308</th>\n",
       "      <td>20308</td>\n",
       "      <td>SUM-GEED-GEE-GENE</td>\n",
       "      <td>BL-S1-M1-GSA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20024</th>\n",
       "      <td>20024</td>\n",
       "      <td>REE-REEL-HIDRE-PIH</td>\n",
       "      <td>NA-S1-R1-TMC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20307 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                 tag   location_code  name fk_plan\n",
       "1          1        ACC-PRI-MEPA        RO-S2-M1  None    None\n",
       "2          2        ACC-PRI-MEPA        RO-S1-M1  None    None\n",
       "3          3        ACC-PRI-MEPA        AM-S1-M1  None    None\n",
       "4          4        ACC-PRI-MEPA        AM-S2-M1  None    None\n",
       "5          5        ACC-PRI-MEPA        VE-S2-M1  None    None\n",
       "...      ...                 ...             ...   ...     ...\n",
       "20307  20307  LIN-VEH-V176-CELF2  BL-LIN-VH-V176  None    None\n",
       "20135  20135    LIN-VEH-V148-CBN  BL-LIN-VH-V148  None    None\n",
       "20133  20133    LIN-VEH-V148-SUS  BL-LIN-VH-V148  None    None\n",
       "20308  20308   SUM-GEED-GEE-GENE    BL-S1-M1-GSA  None    None\n",
       "20024  20024  REE-REEL-HIDRE-PIH    NA-S1-R1-TMC  None    None\n",
       "\n",
       "[20307 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fk_classifiers_type</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>grup_1</th>\n",
       "      <th>notEnabled</th>\n",
       "      <th>is_active</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ACORDE A LA DISPONIBILIDAD</td>\n",
       "      <td>ACORDE A LA DISPONIBILIDAD</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>2022-07-18 14:05:18.891000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>MECANICO</td>\n",
       "      <td>MECANICO</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>HIDRAULICO</td>\n",
       "      <td>HIDRAULICO</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>Nivel 1 - Industria</td>\n",
       "      <td>INDUSTRIA. (Empresa de transporte por cable Mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>2022-05-30 16:05:18.891000+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>30</td>\n",
       "      <td>LECTURAS</td>\n",
       "      <td>REGIMEN POR LECTURAS</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-18 22:29:51.035370+00:00</td>\n",
       "      <td>2023-10-18 22:29:51.035370+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>30</td>\n",
       "      <td>FECHAS/LECTURAS</td>\n",
       "      <td>REGIMEN POR FECHAS Y LECTURAS</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-18 22:29:51.035370+00:00</td>\n",
       "      <td>2023-10-18 22:29:51.035370+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>31</td>\n",
       "      <td>ACTIVIDAD</td>\n",
       "      <td>ACTIVIDAD</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-19 14:01:31.707049+00:00</td>\n",
       "      <td>2023-10-19 14:01:31.707049+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>31</td>\n",
       "      <td>TAREA</td>\n",
       "      <td>TAREA</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-19 14:01:31.707049+00:00</td>\n",
       "      <td>2023-10-19 14:01:31.707049+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>Planificado</td>\n",
       "      <td>MANTENIMIENTO DE TIPO PLANIFICADO</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-07 15:23:03.723058+00:00</td>\n",
       "      <td>2023-11-07 15:23:03.723058+00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  fk_classifiers_type                        name  \\\n",
       "5      5                    3  ACORDE A LA DISPONIBILIDAD   \n",
       "17    17                    5                   ELECTRICO   \n",
       "18    18                    5                    MECANICO   \n",
       "19    19                    5                  HIDRAULICO   \n",
       "20    20                    6         Nivel 1 - Industria   \n",
       "..   ...                  ...                         ...   \n",
       "164  164                   30                    LECTURAS   \n",
       "165  165                   30             FECHAS/LECTURAS   \n",
       "166  166                   31                   ACTIVIDAD   \n",
       "167  167                   31                       TAREA   \n",
       "168  168                    2                 Planificado   \n",
       "\n",
       "                                           description  grup_1 notEnabled  \\\n",
       "5                           ACORDE A LA DISPONIBILIDAD       1       None   \n",
       "17                                           ELECTRICO       1       None   \n",
       "18                                            MECANICO       1       None   \n",
       "19                                          HIDRAULICO       1       None   \n",
       "20   INDUSTRIA. (Empresa de transporte por cable Mi...       1       True   \n",
       "..                                                 ...     ...        ...   \n",
       "164                               REGIMEN POR LECTURAS       1       None   \n",
       "165                      REGIMEN POR FECHAS Y LECTURAS       1       None   \n",
       "166                                          ACTIVIDAD       1       None   \n",
       "167                                              TAREA       1       None   \n",
       "168                  MANTENIMIENTO DE TIPO PLANIFICADO       1       None   \n",
       "\n",
       "     is_active  created_by  updated_by  deleted_by  \\\n",
       "5        False           1         1.0         1.0   \n",
       "17        True           1         1.0         NaN   \n",
       "18        True           1         1.0         NaN   \n",
       "19        True           1         1.0         NaN   \n",
       "20        True           1         1.0         NaN   \n",
       "..         ...         ...         ...         ...   \n",
       "164       True           1         1.0         NaN   \n",
       "165       True           1         1.0         NaN   \n",
       "166       True           1         1.0         NaN   \n",
       "167       True           1         1.0         NaN   \n",
       "168       True           1         1.0         NaN   \n",
       "\n",
       "                          created_at                       updated_at  \\\n",
       "5   2022-05-30 16:05:18.891000+00:00 2022-05-30 16:05:18.891000+00:00   \n",
       "17  2022-05-30 16:05:18.891000+00:00 2022-05-30 16:05:18.891000+00:00   \n",
       "18  2022-05-30 16:05:18.891000+00:00 2022-05-30 16:05:18.891000+00:00   \n",
       "19  2022-05-30 16:05:18.891000+00:00 2022-05-30 16:05:18.891000+00:00   \n",
       "20  2022-05-30 16:05:18.891000+00:00 2022-05-30 16:05:18.891000+00:00   \n",
       "..                               ...                              ...   \n",
       "164 2023-10-18 22:29:51.035370+00:00 2023-10-18 22:29:51.035370+00:00   \n",
       "165 2023-10-18 22:29:51.035370+00:00 2023-10-18 22:29:51.035370+00:00   \n",
       "166 2023-10-19 14:01:31.707049+00:00 2023-10-19 14:01:31.707049+00:00   \n",
       "167 2023-10-19 14:01:31.707049+00:00 2023-10-19 14:01:31.707049+00:00   \n",
       "168 2023-11-07 15:23:03.723058+00:00 2023-11-07 15:23:03.723058+00:00   \n",
       "\n",
       "                          deleted_at  \n",
       "5   2022-07-18 14:05:18.891000+00:00  \n",
       "17                               NaT  \n",
       "18                               NaT  \n",
       "19                               NaT  \n",
       "20                               NaT  \n",
       "..                               ...  \n",
       "164                              NaT  \n",
       "165                              NaT  \n",
       "166                              NaT  \n",
       "167                              NaT  \n",
       "168                              NaT  \n",
       "\n",
       "[168 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "def get_data_from_dataframe(            \n",
    "            query = \"select * from classifiers\",\n",
    "            db_url: str = 'postgresql://postgres:postgres@localhost/simyo3',\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Conecta a la base de datos PostgreSQL, ejecuta la consulta SQL y devuelve un DataFrame.\n",
    "\n",
    "        Parámetros:\n",
    "        - db_url (str): URL de la base de datos PostgreSQL.\n",
    "        - query (str): Consulta SQL a ejecutar.\n",
    "\n",
    "        Retorna:\n",
    "        - DataFrame con los datos obtenidos de la consulta.\n",
    "        \"\"\"\n",
    "        # Crear un engine de SQLAlchemy para conectarse a la base de datos\n",
    "        engine = sqlalchemy.create_engine(db_url)\n",
    "\n",
    "        # Ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "\n",
    "        # Establecer la columna 'id' como índice del DataFrame\n",
    "        df.index = df['id'].values\n",
    "\n",
    "        return df\n",
    "df = get_data_from_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# Crear la conexión con la base de datos usando SQLAlchemy\n",
    "engine = create_engine('postgresql+psycopg2://tu_usuario:tu_password@tu_host:tu_puerto/tu_db')\n",
    "\n",
    "# Nombre de la tabla y secuencia\n",
    "table_name = 'nombre_de_tu_tabla'\n",
    "sequence_name = f'{table_name}_id_seq'\n",
    "\n",
    "# Paso 1: Conectar a la base de datos\n",
    "with engine.connect() as connection:\n",
    "\n",
    "    # Paso 2: Eliminar los datos existentes en la tabla (truncate)\n",
    "    connection.execute(text(f\"TRUNCATE TABLE {table_name} RESTART IDENTITY\"))\n",
    "\n",
    "    # Nota: RESTART IDENTITY elimina los datos y reinicia automáticamente la secuencia para los campos seriales,\n",
    "    # lo cual es más sencillo que manejar el 'ALTER SEQUENCE' manualmente.\n",
    "\n",
    "    # Paso 3: Crear un DataFrame con los datos a insertar\n",
    "    df = pd.DataFrame({\n",
    "        'columna1': ['valor1', 'valor2'],\n",
    "        'columna2': ['valor3', 'valor4']\n",
    "    })\n",
    "\n",
    "    # Paso 4: Insertar los nuevos datos en la tabla\n",
    "    df.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "\n",
    "# Cerramos la conexión y terminamos la operación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir df_plan\n",
    "\n",
    "id = 'plans_id_seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import psycopg2\n",
    "\n",
    "# Paso 1: Conectar a la base de datos PostgreSQL\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname='db_name',       # Reemplaza con el nombre de tu base de datos\n",
    "        user='user',            # Reemplaza con el usuario de la base de datos\n",
    "        password='password',    # Reemplaza con la contraseña del usuario\n",
    "        host='localhost',       # Reemplaza si tu base de datos está en otro servidor\n",
    "        port='5432'             # Reemplaza si usas otro puerto, el puerto por defecto es 5432\n",
    "    )\n",
    "    \n",
    "    import psycopg2\n",
    "\n",
    "    # Conexión a la base de datos\n",
    "    conn = psycopg2.connect(\"dbname='db_name' user='user' password='password' host='localhost' port='5432'\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Ejecución de la consulta para reiniciar la secuencia\n",
    "    cursor.execute(\"ALTER SEQUENCE table_name_id_seq RESTART WITH new_value;\")\n",
    "\n",
    "    # Confirmar los cambios\n",
    "    conn.commit()\n",
    "\n",
    "    # Cerrar conexión\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"Conexión a la base de datos establecida con éxito\")    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al conectar a la base de datos: {e}\")\n",
    "\n",
    "# Paso 2: Crear un cursor para ejecutar consultas\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Especificar el nombre de la secuencia y el nuevo valor\n",
    "sequence_name = 'table_name_id_seq'  # Reemplaza con el nombre de tu secuencia\n",
    "new_value = 100  # El valor desde el que quieres que se reinicie la secuencia\n",
    "\n",
    "# Ejecutar la consulta SQL\n",
    "try:\n",
    "    cursor.execute(f\"ALTER SEQUENCE {sequence_name} RESTART WITH {new_value};\")\n",
    "    print(f\"La secuencia {sequence_name} fue reiniciada con éxito a {new_value}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al ejecutar la consulta SQL: {e}\")\n",
    "\n",
    "\n",
    "# Insertar el DataFrame en la tabla, asegurando que si existen conflictos de columnas, las reemplace\n",
    "df.to_sql('table_name', con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
