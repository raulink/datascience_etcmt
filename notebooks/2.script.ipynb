{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543cd6a1b950436b9a3c1e4c72d3b9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0fde255cb4470fa3917083c01cc2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01629923ba0c41859f6a87d5607a2843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='localhost', description='Host:', placeholder='Host')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da007fe2f9584165b5202b60d55ddc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='postgres', description='Usuario')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363fc5ac8d474da98ef4714633e58472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Password(description='Password')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae8f9e40eeb496c948124eb1b6bd335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Text(value='output/Salida_Planes.xlsx', description='Nombre:'),), titles=('Archivo Salida'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11da4552c5a46ba9b0a9f302a0c6428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Generar Archivo Excel', layout=Layout(width='20%'), style=ButtonSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f45d5afabf34847bea520fde06ba4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Text(value='postgres', description='Usuario'), Password(description='Password'), Text(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48f0953f750476cb905d08f5cbdd780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Cargar en Base de datos', layout=Layout(width='20%'), style=ButtonS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce46522a1de04e7bb4696be4709fcc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import display\n",
    "\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Variables\n",
    "\n",
    "url_alta_demanda =\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\"\n",
    "archivo_ad = \"input/pad_equipos.csv\"\n",
    "url_baja_demanda = \"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\"\n",
    "archivo_bd = \"input/pbd_equipos.csv\"\n",
    "\n",
    "descargar = False\n",
    "lbd = url_baja_demanda\n",
    "lad = url_alta_demanda\n",
    "host = 'localhost'# '192.168.100.50'\n",
    "basedatos = 'db_mantenimiento' #'simyo2'\n",
    "usuario = 'postgres' #'mantto'\n",
    "password = ''# 'Sistemas0'\n",
    "salida = \"output/Salida_Planes.xlsx\"\n",
    "\n",
    "wlad = widgets.Textarea(value=lad,placeholder='Plan Maestro LAD',description='Lineas Alta Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "wlbd = widgets.Textarea(value=lbd,placeholder='Plan Maestro LBD',description='Lineas Baja Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "whost = widgets.Text(value=host,placeholder='Host',description='Host:',disabled=False)\n",
    "wbasedatos = widgets.Text(value=basedatos,placeholder='BaseDatos',description='BaseDatos',disabled=False)\n",
    "wusuario = widgets.Text(value=usuario,description='Usuario')\n",
    "wpassword = widgets.Password(value=password,description='Password')\n",
    "wbutton1 = widgets.Button(description=\"Generar Archivo Excel\",button_style='success',layout=Layout(width='20%'))\n",
    "wbutton2 = widgets.Button(description=\"Cargar en Base de datos\",button_style='danger',layout=Layout(width='20%'))\n",
    "woutput = widgets.Output()\n",
    "wsalida = widgets.Text(value=salida,description=\"Nombre:\",disabled=False)\n",
    "waccordion = widgets.Accordion(children=[ wsalida], titles=(['Archivo Salida']))\n",
    "waccordion1 = widgets.Accordion(children=[ wusuario,wpassword,whost,wbasedatos], titles=('Usuario','Password','Host','Base de Datos'))\n",
    "\n",
    "display(wlad,wlbd,whost,wusuario,wpassword,waccordion,wbutton1, waccordion1,wbutton2,woutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ## Script 2\\n# https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\\n\\n\\ndef on_button_clicked(b):    \\n    # Combinacion de dataframes\\n    gs1 = GoogleSheetProcessor(lad.value) # (\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\")\\n    archivo = \"input/pad_planes.csv\"\\n    #gs1.download_csv(archivo)\\n    df1 = pd.read_csv(archivo,header=3,true_values=[\\'True\\',\\'TRUE\\'],false_values=[\\'False\\',\"FALSE\",\"\"])\\n\\n\\n    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\")\\n    archivo = \"input/pbd_planes.csv\"\\n    #gs2.download_csv(archivo)\\n    df2 = pd.read_csv(archivo,header=3,true_values=[\\'True\\',\\'TRUE\\'],false_values=[\\'False\\',\"FALSE\",\"\"])\\n\\n    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\\n    filename = \"input/mix_planes.csv\"\\n    df_merged.to_csv(filename,sep=\\';\\')\\n\\n    df_output, df_db, df_result=gs1.process(df_merged)\\n    df_result.to_excel(salida.value)\\n    \\n    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \\n    with output:\\n        print(f\"Se Genera archivo excel {salida.value}\")\\n\\nbutton1.on_click(on_button_clicked)\\nbutton2.on_click(lambda _: print(\"Boton 2 accionado\"))\\n#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html\\n## Script 2 '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ## Script 2\n",
    "# https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\n",
    "\n",
    "\n",
    "def on_button_clicked(b):    \n",
    "    # Combinacion de dataframes\n",
    "    gs1 = GoogleSheetProcessor(lad.value) # (\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\")\n",
    "    archivo = \"input/pad_planes.csv\"\n",
    "    #gs1.download_csv(archivo)\n",
    "    df1 = pd.read_csv(archivo,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n",
    "\n",
    "\n",
    "    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\")\n",
    "    archivo = \"input/pbd_planes.csv\"\n",
    "    #gs2.download_csv(archivo)\n",
    "    df2 = pd.read_csv(archivo,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n",
    "\n",
    "    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "    filename = \"input/mix_planes.csv\"\n",
    "    df_merged.to_csv(filename,sep=';')\n",
    "\n",
    "    df_output, df_db, df_result=gs1.process(df_merged)\n",
    "    df_result.to_excel(salida.value)\n",
    "    \n",
    "    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \n",
    "    with output:\n",
    "        print(f\"Se Genera archivo excel {salida.value}\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(lambda _: print(\"Boton 2 accionado\"))\n",
    "#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html\n",
    "## Script 2 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import sqlite3\n",
    "\n",
    "class GoogleSheetProcessor2:\n",
    "    def __init__(self, sheet_url1: str):\n",
    "        self.sheet_url1 = sheet_url1\n",
    "        self.spreadsheet_id = self.extract_spreadsheet_id(sheet_url1)\n",
    "        self.sheet_id = self.extract_sheet_id(sheet_url1)\n",
    "        self.csv_export_url = self.construct_csv_export_url()\n",
    "\n",
    "    def extract_spreadsheet_id(self, url: str):\n",
    "        return url.split('/d/')[1].split('/')[0]\n",
    "\n",
    "    def extract_sheet_id(self, url: str):\n",
    "        return url.split('gid=')[1]\n",
    "\n",
    "    def construct_csv_export_url(self):\n",
    "        return f\"https://docs.google.com/spreadsheets/d/{self.spreadsheet_id}/export?format=csv&gid={self.sheet_id}\"\n",
    "\n",
    "    def download_csv(self, output_filename: str = 'temp_sheet.csv'):\n",
    "        # Descarga el archivo CSV y lo guarda temporalmente\n",
    "        response = requests.get(self.csv_export_url)\n",
    "        response.raise_for_status()  # Asegurarse de que la solicitud fue exitosa\n",
    "        with open(output_filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return pd.read_csv(output_filename)\n",
    "\n",
    "    def validate_no_duplicate_columns(self, df: pd.DataFrame):\n",
    "        # Validar si existen columnas duplicadas en el DataFrame\n",
    "        duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "        if not duplicate_columns.empty:\n",
    "            raise ValueError(\n",
    "                f\"Columnas duplicadas encontradas: {duplicate_columns.tolist()}\")\n",
    "\n",
    "    def convertir_booleano_amef(self, df: pd.DataFrame, ini: int, end: int):\n",
    "        \"\"\"\n",
    "        Convierte a tipo booleano las columnas en el rango dado, si no son ya booleanas.\n",
    "\n",
    "        Parámetros:\n",
    "        - df: DataFrame en el que se realizará la conversión.\n",
    "        - ini: Índice de la columna inicial.\n",
    "        - end: Índice de la columna final.\n",
    "\n",
    "        Retorna:\n",
    "        - DataFrame con las columnas convertidas a booleano.\n",
    "        \"\"\"\n",
    "        # Iterar sobre las columnas en el rango especificado\n",
    "        for col in df.columns[ini + 1:end]:\n",
    "            # Verificar si la columna no es de tipo booleano\n",
    "            if df[col].dtype != bool:\n",
    "                # Convertir la columna a booleano\n",
    "                df[col] = df[col].map(lambda x: True if str(\n",
    "                    x).upper() == 'TRUE' else False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def load_data_from_postgres(\n",
    "            self,\n",
    "            user=usuario,\n",
    "            password=password, \n",
    "            host=host,\n",
    "            database=basedatos,\n",
    "            #db_url: str = 'postgresql://postgres:postgres@localhost/simyo',\n",
    "            query: str = \"\"\"\n",
    "                SELECT\n",
    "                    base.\"id\",\n",
    "                    \"structure\".tag,\n",
    "                    locations.location_code,\n",
    "                    \"plans\".\"name\",\n",
    "                    base.fk_plan\n",
    "                FROM\n",
    "                    base\n",
    "                    INNER JOIN\n",
    "                    locations\n",
    "                    ON\n",
    "                        base.fk_location = locations.\"id\"\n",
    "                    INNER JOIN\n",
    "                    \"structure\"\n",
    "                    ON\n",
    "                        base.fk_structure = \"structure\".\"id\"\n",
    "                    LEFT JOIN\n",
    "                    \"plans\"\n",
    "                    ON\n",
    "                        base.fk_plan = \"plans\".\"id\"\n",
    "                \"\"\"):\n",
    "        \"\"\"\n",
    "        Conecta a la base de datos PostgreSQL, ejecuta la consulta SQL y devuelve un DataFrame.\n",
    "\n",
    "        Parámetros:\n",
    "        - db_url (str): URL de la base de datos PostgreSQL.\n",
    "        - query (str): Consulta SQL a ejecutar.\n",
    "\n",
    "        Retorna:\n",
    "        - DataFrame con los datos obtenidos de la consulta.\n",
    "        \"\"\"\n",
    "        # Crear un engine de SQLAlchemy para conectarse a la base de datos\n",
    "        db_url = f'postgresql://{user}:{password}@{host}/{database}'\n",
    "        engine = sqlalchemy.create_engine(db_url)\n",
    "\n",
    "        # Ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "\n",
    "        # Establecer la columna 'id' como índice del DataFrame\n",
    "        df.index = df['id'].values\n",
    "\n",
    "        return df\n",
    "\n",
    "    def process_dataframe(self, df: pd.DataFrame, columns_to_remove: list):\n",
    "        # Si existen columnas con nombres duplicados, arrojar un error de columnas duplicadas\n",
    "        if df.columns.duplicated().any():\n",
    "            assert False, \"Hay columnas duplicadas en el DataFrame df1\"\n",
    "        # Eliminar columnas innecesarias\n",
    "        df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "        # Eliminar filas donde 'TIPO' tenga valores 'Sistema' o 'Subsistema'\n",
    "        df = df[~df['Tipo_equipo'].isin(['Sistema', 'Subsistema'])] # \n",
    "\n",
    "        # Filtrar filas donde la columna 'Plan' no sea nula\n",
    "        df = df[df['Plan'].notna()]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_output_dataframe(self, df: pd.DataFrame):\n",
    "        # Crear un DataFrame de salida con columnas específicas\n",
    "        # Iterar sobre las filas del dataframe\n",
    "        df_salida = pd.DataFrame()\n",
    "        for index, row in df.iterrows():\n",
    "            # Buscar el índice de la columna 'AMEF'\n",
    "            try:\n",
    "                amef_index = df.columns.get_loc('AMEF')\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            # Iterar a partir de la columna siguiente a 'AMEF'\n",
    "            for col in df.columns[amef_index + 1:]:\n",
    "                # print(col)\n",
    "                if row[col] == True:  # Si el valor es True\n",
    "                    # Adicionar una nueva fila al dataframe de salida\n",
    "                    new_row = pd.DataFrame({\n",
    "                        'tag': [row['Tag']],\n",
    "                        'location_code': [col],\n",
    "                        'plan': [row['Plan']]\n",
    "                    })\n",
    "                    df_salida = pd.concat(\n",
    "                        [df_salida, new_row], ignore_index=True)\n",
    "        return df_salida\n",
    "\n",
    "    def load_data_from_db(self, query: str, db_path: str):\n",
    "        # Cargar datos desde una base de datos SQLite\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        df_db = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return df_db\n",
    "\n",
    "    def read_csv(self, filename=\"temp_sheet.csv\", column_row=None, row_ini=None):\n",
    "        # Lee el archivo CSV usando pandas\n",
    "        # df = pd.DataFrame()\n",
    "        df = pd.read_csv(filename, header=column_row,\n",
    "                         skiprows=None, skipfooter=0)\n",
    "        if column_row and row_ini is None:\n",
    "            return df\n",
    "        else:\n",
    "            df.columns = df.loc[column_row, :].to_list()  # la fila 2 como fila\n",
    "            df = df.loc[row_ini:, :]   # Obtener desde la fila 4 en adelante\n",
    "            return df\n",
    "\n",
    "    def merge_dataframes(self, df1: pd.DataFrame, df2: pd.DataFrame, on_columns: list):\n",
    "        # Realizar el merge de dos DataFrames\n",
    "        return pd.merge(df1, df2, on=on_columns, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "    def process(\n",
    "            self,\n",
    "            df_input,\n",
    "            columns_to_remove: list = ['RO', 'AM', 'AZ', 'MO', 'VE', 'BL', 'NA', 'CE', 'CA', 'PL']):\n",
    "        # Método principal que engloba toda la lógica\n",
    "        # df = self.download_csv()  # Descarga y carga del CSV\n",
    "        # df = self.read_csv(filename=filename_input,column_row=2,row_ini=4)\n",
    "        # print(filename_input)\n",
    "        # df = pd.read_csv(filename_input)\n",
    "\n",
    "        # self.validate_no_duplicate_columns(df)  # Validar columnas duplicadas\n",
    "        # Método principal que engloba toda la lógica\n",
    "        df = self.process_dataframe(df_input, columns_to_remove)  # Procesar el DataFrame\n",
    "        # Es importante que tenga esta columna, es la columna indice a partir de la cual procesara\n",
    "        amef_index = df.columns.get_loc('AMEF')\n",
    "        end = len(df.columns)\n",
    "        df = self.convertir_booleano_amef(df, amef_index, end)\n",
    "        # Crear DataFrame de salida\n",
    "        df_output = self.create_output_dataframe(df)\n",
    "\n",
    "        cantidad_activos = df.iloc[:, amef_index + 1:].sum().sum()\n",
    "        print(f\"Existen {cantidad_activos} activos en la hoja de datos\")\n",
    "        if len(df_output) != cantidad_activos:\n",
    "            assert False, \"La cantidad de activos no corresponde con la salida\"\n",
    "        \n",
    "        # Cargar datos desde la base de datos\n",
    "        df_db = self.load_data_from_postgres()\n",
    "        # Merge de DataFrames\n",
    "        df_result = self.merge_dataframes(df_output, df_db, ['tag', 'location_code'])  \n",
    "\n",
    "        return df_output, df_db, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinacion de dataframes\n",
    "gs1 = GoogleSheetProcessor2(url_baja_demanda)\n",
    "if descargar : gs1.download_csv(archivo_ad)\n",
    "df1 = pd.read_csv(archivo_ad,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GoogleSheetProcessor2 (url_baja_demanda)\n",
    "if descargar: gs2.download_csv(archivo_bd)\n",
    "df2 = pd.read_csv(archivo_bd,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix Dataframes\n",
    "\n",
    "Generar un mix con los 2 planes de mantto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar ambos dataframes\n",
    "df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "filename = \"input/mix_planes_script2.csv\"\n",
    "df_merged.to_csv(filename,sep=';')  # Exportar archivo mezclado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existen 12815 activos en la hoja de datos\n"
     ]
    }
   ],
   "source": [
    "df_output, df_db, df_result=gs1.process(df_merged)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para base de datos\n",
    "Funciones necesarias para base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine.result import Result\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import uuid\n",
    "\"\"\" Para pasar a la base de datos\"\"\"\n",
    "\n",
    "def format_dataframe(df:pd.DataFrame,tabla:str,usuario=usuario, password=password,host=host, database=basedatos):\n",
    "    \n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    # Leer la tabla original en un DataFrame de pandas\n",
    "    df_origen = pd.read_sql_query(f\"SELECT * FROM {tabla}\", con=engine)\n",
    "\n",
    "    # Renombrar la columna 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "\n",
    "    # Si existe la columna 'uuid' en la tabla original, crear esa columna\n",
    "    if 'uuid' in df_origen.columns:\n",
    "        df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "    if 'is_active' in df_origen.columns:\n",
    "        df['is_active'] = True        \n",
    "\n",
    "    # Identificar las columnas que están en df_origen pero no en df\n",
    "    missing_columns = [col for col in df_origen.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columnas faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None #pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir columnas comunes\n",
    "    df['id'] = df.index +1 if df.index[0] ==0 else df.index\n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()\n",
    "    # Validar que las columnas de df y df_origen sean iguales\n",
    "    columnas_df = set(df.columns)\n",
    "    columnas_df_origen = set(df_origen.columns)\n",
    "    \n",
    "    # Si las columnas no son iguales, lanzar un error\n",
    "    assert columnas_df == columnas_df_origen, f\"Las columnas no coinciden. Columnas faltantes: {columnas_df_origen - columnas_df} en df y {columnas_df - columnas_df_origen} en df_origen\"        \n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def actualizar_tabla_postgres(df: pd.DataFrame, tabla: str, columna_id: str,\n",
    "                              usuario=usuario, password=password, \n",
    "                              host=host, database=basedatos):    \n",
    "    # Reemplazar NaN por None (que en SQL es equivalente a NULL)\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "        \n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        #connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.execute(text(f\"DELETE FROM {tabla} CASCADE;\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # Insertar los nuevos datos en la tabla\n",
    "    df.to_sql(tabla, con=engine, if_exists='append', index=False)  # Solo append en tablas con relaciones    \n",
    "\n",
    "    # Obtener el valor máximo de la columna 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX({columna_id}) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    # Obtener el nombre de la secuencia asociada a la columna 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\"))\n",
    "        id_secuencia = result.scalar()\n",
    "\n",
    "    # Reiniciar el valor de la secuencia si se obtiene la secuencia asociada\n",
    "    with engine.connect() as connection:\n",
    "        if id_secuencia:\n",
    "            connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "            connection.commit()\n",
    "            print(f'Se reinició el índice {id_secuencia} en {max_id + 1}')\n",
    "\n",
    "# Ejemplo de uso:\n",
    "## actualizar_tabla_postgres(df_plan, 'plans', 'id')\n",
    "def obtener_registros( tabla,  usuario=usuario, password=password, host=host, database=basedatos,columna_ids=[]):\n",
    "    \"\"\"\n",
    "    Realiza un SELECT * en una tabla especificada de la base de datos y retorna un DataFrame con los resultados.\n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la sentencia SQL para obtener los registros\n",
    "        result = connection.execute(text(f'select * from {tabla}'))        \n",
    "        # Convertir los resultados en un DataFrame\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "        #df.index = df['index']\n",
    "        df.index = df['id']\n",
    "    return df if not columna_ids or len(columna_ids) == 0 else df[columna_ids]\n",
    "    \n",
    "def buscarIndice(df: pd.DataFrame, valor:str, columna_id='value'):\n",
    "        # Verificar si el valor está en la columna_id especificada\n",
    "        \"\"\"\n",
    "        Busca un valor en la columna especificada del DataFrame.\n",
    "        Si el valor de búsqueda es nulo o si no se encuentra, retorna el mismo valor de búsqueda.\n",
    "        \"\"\"\n",
    "        # Validar si el valor de búsqueda es nulo        \n",
    "            \n",
    "        if pd.isna(valor):\n",
    "            return None #pd.NA    \n",
    "        \n",
    "        #fkc_priority tiene el valor \"BAJA \" con espacio al final, eliminar el ultimo espacio Se añade a la funcion buscarIndice\n",
    "        valor = valor.upper().strip()\n",
    "\n",
    "        resultado = df[df[columna_id].str.upper() == valor]    \n",
    "        # Si no encuentra el valor, retornar el mismo valor\n",
    "        if resultado.empty:\n",
    "            return valor\n",
    "        else:\n",
    "            return int(resultado.index[0])\n",
    "\n",
    "def ejecutar_query(query, usuario=usuario, password=password, host=host, database=basedatos):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta SQL y devuelve el resultado en un DataFrame si la consulta devuelve filas.\n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la consulta\n",
    "        result = connection.execute(text(query))\n",
    "        connection.commit()\n",
    "        \n",
    "        # Verificar si la consulta devuelve filas\n",
    "        if result.returns_rows:\n",
    "            # Obtener los resultados en un DataFrame\n",
    "            df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "            return df\n",
    "        else:\n",
    "            # Si no devuelve filas, solo confirmar la ejecución\n",
    "            return None\n",
    "\n",
    "    return result\n",
    "def eliminar_registros(tabla,usuario=usuario, password=password, host= host, database=basedatos):\n",
    "    \"\"\"\n",
    "    Elimina todos los registros de una tabla especificada en la base de datos.    \n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la sentencia SQL para eliminar todos los registros\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.commit()  # Confirmar los cambios\n",
    "\n",
    "def __actualizar_tabla_postgres(df:pd.DataFrame , tabla:str, columna_id:str , usuario=usuario, password=password, host= host, database=basedatos):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "\n",
    "    # Usar pd.read_sql_query con una conexión\n",
    "        # Leer la tabla en un DataFrame de pandas\n",
    "    df_origen = ejecutar_query(f\"SELECT * FROM {tabla}\")\n",
    "\n",
    "    \n",
    "    # Renombrar la columna_id 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "    \n",
    "    # Si existe la columna_id uuid en la tabla original, crear esa columna_id\n",
    "    if 'uuid' in df_origen.columns:\n",
    "        df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "    \n",
    "    if 'is_active' in df_origen.columns:\n",
    "        df['is_active'] = True\n",
    "\n",
    "\n",
    "    # Identificar las columna_ids que están en df pero no en df_origen\n",
    "    missing_columns = [col for col in df_origen.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columna_ids faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None #pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir las columna_ids comunes en las tablas\n",
    "    df['id'] = df.index\n",
    "    \n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()   \n",
    "\n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        #connection.commit()\n",
    "    \n",
    "    # Insertar nuevos datos con pandas to_sql\n",
    "    df.to_sql(tabla, con= engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Obtener el valor máximo de la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX({columna_id}) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    \n",
    "    # Obtener el nombre de la secuencia asociada a la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"\"\"\n",
    "            SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\n",
    "        \"\"\"))\n",
    "        id_secuencia = result.scalar()  # Obtener el nombre de la secuencia\n",
    "    \n",
    "        \n",
    "    # Reiniciar el valor de la secuencia\n",
    "    with engine.connect() as connection:\n",
    "        # Si se tienen \n",
    "        if id_secuencia : connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "\n",
    "\n",
    "def update_plans_table(df,tabla, columna_id, usuario='user_mantenimiento', password='pass_M4ntenimient0', host= 'localhost', database='db_mantenimiento_test' ):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "\n",
    "    # Leer la tabla en un DataFrame de pandas\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabla}\", engine)\n",
    "\n",
    "    # Renombrar columna_id 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "\n",
    "    # Identificar las columna_ids que están en df pero no en df\n",
    "    missing_columns = [col for col in df.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columna_ids faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir/actualizar las columna_ids necesarias en df\n",
    "    df['id'] = df.index\n",
    "    df['is_active'] = True\n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()\n",
    "\n",
    "    # Obtener el nombre de la secuencia asociada a la columna_id 'id' en la tabla 'plans_test'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\"))\n",
    "        id_secuencia = result.scalar()  # Obtener el nombre de la secuencia\n",
    "\n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # Insertar nuevos datos con pandas to_sql\n",
    "    df.to_sql(tabla, engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Obtener el valor máximo de la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX(id) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    # Reiniciar el valor de la secuencia\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "\n",
    "\n",
    "def actualizar_fk_plan(df_base, usuario=usuario, password=password, host=host, database=basedatos):\n",
    "    \"\"\"\n",
    "    Actualiza la columna fk_plan en la tabla 'base' de PostgreSQL \n",
    "    utilizando los datos proporcionados en df_base.\n",
    "\n",
    "    Parámetros:\n",
    "    - df_base: DataFrame con las columnas 'id' y 'fk_plan' a actualizar.\n",
    "    - host: Host de la base de datos.\n",
    "    - database: Nombre de la base de datos.\n",
    "    - user: Usuario para la conexión.\n",
    "    - password: Contraseña para la conexión.\n",
    "    \"\"\"\n",
    "    # Conexión a la base de datos PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        user=usuario,\n",
    "        password=password,\n",
    "        #options=\"-c client_encoding=LATIN1\"  # Cambia 'LATIN1' por el encoding que utiliza tu base de datos si no es UTF-8\n",
    "\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Recorre cada fila del DataFrame para generar la consulta de actualización\n",
    "    for index, row in df_base.iterrows():\n",
    "        try: \n",
    "            query = f\"\"\"\n",
    "            UPDATE base\n",
    "            SET fk_plan = {row['fk_plan']}\n",
    "            WHERE id = {row['id']};\n",
    "            \"\"\"\n",
    "            cursor.execute(query)\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Error en la fila {index}:{e}\")\n",
    "    # Confirmar los cambios\n",
    "    conn.commit()\n",
    "\n",
    "    # Cerrar la conexión\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plans = obtener_registros('plans')\n",
    "df_result['fk_plan'] = df_result['plan'].apply(lambda x : buscarIndice(df_plans,x,'name'))\n",
    "df_result.to_excel('RevisarPlanEquipo.xlsx')\n",
    "# Filtrar el dataframe de datos invalidos.\n",
    "df_result\n",
    "\n",
    "obtener_registros('base')\n",
    "df_base = df_result[['id','fk_plan']]\n",
    "\n",
    "# Filtrar instancias solo numeros o float\n",
    "df_base = df_base[df_base['fk_plan'].apply(lambda x: isinstance(x, (int, float)) and not pd.isnull(x))]\n",
    "# Filtrar instancias que no encontraron id\n",
    "df_base = df_base[df_base['id'].notnull()]\n",
    "# Convertir la columna 'id' de float a entero, omitiendo los valores nulos\n",
    "df_base['id'] = df_base['id'].fillna(0).astype(int)\n",
    "df_base.to_excel(\"df_base.xlsx\")\n",
    "# Conteo de valores nulos\n",
    "df_base.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar la tabla 'base' en la base de datos con la información proporcionada \n",
    "actualizar_fk_plan(df_base)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
