{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "class GoogleSheetProcessor:\n",
    "    def __init__(self, sheet_url1: str):\n",
    "        self.sheet_url1 = sheet_url1\n",
    "        self.spreadsheet_id = self.extract_spreadsheet_id(sheet_url1)\n",
    "        self.sheet_id = self.extract_sheet_id(sheet_url1)\n",
    "        self.csv_export_url = self.construct_csv_export_url()\n",
    "\n",
    "    def extract_spreadsheet_id(self, url: str):\n",
    "        return url.split('/d/')[1].split('/')[0]\n",
    "\n",
    "    def extract_sheet_id(self, url: str):\n",
    "        return url.split('gid=')[1]\n",
    "\n",
    "    def construct_csv_export_url(self):\n",
    "        return f\"https://docs.google.com/spreadsheets/d/{self.spreadsheet_id}/export?format=csv&gid={self.sheet_id}\"\n",
    "\n",
    "    def download_csv(self, output_filename: str = 'temp_sheet.csv'):\n",
    "        # Descarga el archivo CSV y lo guarda temporalmente\n",
    "        response = requests.get(self.csv_export_url)\n",
    "        response.raise_for_status()  # Asegurarse de que la solicitud fue exitosa\n",
    "        with open(output_filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return pd.read_csv(output_filename)\n",
    "\n",
    "    def validate_no_duplicate_columns(self, df: pd.DataFrame):\n",
    "        # Validar si existen columnas duplicadas en el DataFrame\n",
    "        duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "        if not duplicate_columns.empty:\n",
    "            raise ValueError(\n",
    "                f\"Columnas duplicadas encontradas: {duplicate_columns.tolist()}\")\n",
    "\n",
    "    def convertir_booleano_amef(self, df: pd.DataFrame, ini: int, end: int):\n",
    "        \"\"\"\n",
    "        Convierte a tipo booleano las columnas en el rango dado, si no son ya booleanas.\n",
    "\n",
    "        Parámetros:\n",
    "        - df: DataFrame en el que se realizará la conversión.\n",
    "        - ini: Índice de la columna inicial.\n",
    "        - end: Índice de la columna final.\n",
    "\n",
    "        Retorna:\n",
    "        - DataFrame con las columnas convertidas a booleano.\n",
    "        \"\"\"\n",
    "        # Iterar sobre las columnas en el rango especificado\n",
    "        for col in df.columns[ini + 1:end]:\n",
    "            # Verificar si la columna no es de tipo booleano\n",
    "            if df[col].dtype != bool:\n",
    "                # Convertir la columna a booleano\n",
    "                df[col] = df[col].map(lambda x: True if str(\n",
    "                    x).upper() == 'TRUE' else False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def load_data_from_postgres(\n",
    "            self,\n",
    "            db_url: str = 'postgresql://postgres:postgres@localhost/simyo',\n",
    "            query: str = \"\"\"\n",
    "                SELECT\n",
    "                    base.\"id\",\n",
    "                    \"structure\".tag,\n",
    "                    locations.location_code,\n",
    "                    \"plans\".\"name\",\n",
    "                    base.fk_plan\n",
    "                FROM\n",
    "                    base\n",
    "                    INNER JOIN\n",
    "                    locations\n",
    "                    ON\n",
    "                        base.fk_location = locations.\"id\"\n",
    "                    INNER JOIN\n",
    "                    \"structure\"\n",
    "                    ON\n",
    "                        base.fk_structure = \"structure\".\"id\"\n",
    "                    LEFT JOIN\n",
    "                    \"plans\"\n",
    "                    ON\n",
    "                        base.fk_plan = \"plans\".\"id\"\n",
    "                \"\"\"):\n",
    "        \"\"\"\n",
    "        Conecta a la base de datos PostgreSQL, ejecuta la consulta SQL y devuelve un DataFrame.\n",
    "\n",
    "        Parámetros:\n",
    "        - db_url (str): URL de la base de datos PostgreSQL.\n",
    "        - query (str): Consulta SQL a ejecutar.\n",
    "\n",
    "        Retorna:\n",
    "        - DataFrame con los datos obtenidos de la consulta.\n",
    "        \"\"\"\n",
    "        # Crear un engine de SQLAlchemy para conectarse a la base de datos\n",
    "        engine = sqlalchemy.create_engine(db_url)\n",
    "\n",
    "        # Ejecutar la consulta y cargar los resultados en un DataFrame\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "\n",
    "        # Establecer la columna 'id' como índice del DataFrame\n",
    "        df.index = df['id'].values\n",
    "\n",
    "        return df\n",
    "\n",
    "    def process_dataframe(self, df: pd.DataFrame, columns_to_remove: list):\n",
    "\n",
    "        # Si existen columnas con nombres duplicados, arrojar un error de columnas duplicadas\n",
    "        if df.columns.duplicated().any():\n",
    "            assert False, \"Hay columnas duplicadas en el DataFrame df1\"\n",
    "        # Eliminar columnas innecesarias\n",
    "        df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "        # Eliminar filas donde 'TIPO' tenga valores 'Sistema' o 'Subsistema'\n",
    "        df = df[~df['Tipo_equipo'].isin(['Sistema', 'Subsistema'])] # \n",
    "\n",
    "        # Filtrar filas donde la columna 'Plan' no sea nula\n",
    "        df = df[df['Plan'].notna()]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_output_dataframe(self, df: pd.DataFrame):\n",
    "        # Crear un DataFrame de salida con columnas específicas\n",
    "        # Iterar sobre las filas del dataframe\n",
    "        df_salida = pd.DataFrame()\n",
    "        for index, row in df.iterrows():\n",
    "            # Buscar el índice de la columna 'AMEF'\n",
    "            try:\n",
    "                amef_index = df.columns.get_loc('AMEF')\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            # Iterar a partir de la columna siguiente a 'AMEF'\n",
    "            for col in df.columns[amef_index + 1:]:\n",
    "                # print(col)\n",
    "                if row[col] == True:  # Si el valor es True\n",
    "                    # Adicionar una nueva fila al dataframe de salida\n",
    "                    new_row = pd.DataFrame({\n",
    "                        'tag': [row['Tag']],\n",
    "                        'location_code': [col],\n",
    "                        'plan': [row['Plan']]\n",
    "                    })\n",
    "                    df_salida = pd.concat(\n",
    "                        [df_salida, new_row], ignore_index=True)\n",
    "        return df_salida\n",
    "\n",
    "    def load_data_from_db(self, query: str, db_path: str):\n",
    "        # Cargar datos desde una base de datos SQLite\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        df_db = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        return df_db\n",
    "\n",
    "    def read_csv(self, filename=\"temp_sheet.csv\", column_row=None, row_ini=None):\n",
    "        # Lee el archivo CSV usando pandas\n",
    "        # df = pd.DataFrame()\n",
    "        df = pd.read_csv(filename, header=column_row,\n",
    "                         skiprows=None, skipfooter=0)\n",
    "        if column_row and row_ini is None:\n",
    "            return df\n",
    "        else:\n",
    "            df.columns = df.loc[column_row, :].to_list()  # la fila 2 como fila\n",
    "            df = df.loc[row_ini:, :]   # Obtener desde la fila 4 en adelante\n",
    "            return df\n",
    "\n",
    "    def merge_dataframes(self, df1: pd.DataFrame, df2: pd.DataFrame, on_columns: list):\n",
    "        # Realizar el merge de dos DataFrames\n",
    "        return pd.merge(df1, df2, on=on_columns, how='left', suffixes=('_left', '_right'))\n",
    "\n",
    "    def process(\n",
    "            self,\n",
    "            df_input,\n",
    "            columns_to_remove: list = ['RO', 'AM', 'AZ', 'MO', 'VE', 'BL', 'NA', 'CE', 'CA', 'PL']):\n",
    "        # Método principal que engloba toda la lógica\n",
    "        # df = self.download_csv()  # Descarga y carga del CSV\n",
    "        # df = self.read_csv(filename=filename_input,column_row=2,row_ini=4)\n",
    "        # print(filename_input)\n",
    "        # df = pd.read_csv(filename_input)\n",
    "\n",
    "        # self.validate_no_duplicate_columns(df)  # Validar columnas duplicadas\n",
    "        # Método principal que engloba toda la lógica\n",
    "        df = self.process_dataframe(df_input, columns_to_remove)  # Procesar el DataFrame\n",
    "        # Es importante que tenga esta columna, es la columna indice a partir de la cual procesara\n",
    "        amef_index = df.columns.get_loc('AMEF')\n",
    "        end = len(df.columns)\n",
    "        df = self.convertir_booleano_amef(df, amef_index, end)\n",
    "        # Crear DataFrame de salida\n",
    "        df_output = self.create_output_dataframe(df)\n",
    "\n",
    "        cantidad_activos = df.iloc[:, amef_index + 1:].sum().sum()\n",
    "        print(f\"Existen {cantidad_activos} activos en la hoja de datos\")\n",
    "        if len(df_output) != cantidad_activos:\n",
    "            assert False, \"La cantidad de activos no corresponde con la salida\"\n",
    "        \n",
    "        # Cargar datos desde la base de datos\n",
    "        df_db = self.load_data_from_postgres()  \n",
    "        # Merge de DataFrames\n",
    "        df_result = self.merge_dataframes(df_output, df_db, ['tag', 'location_code'])  \n",
    "\n",
    "        return df_output, df_db, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "descargar = False\n",
    "url_alta_demanda =\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\"\n",
    "archivo_ad = \"input/pad_equipos.csv\"\n",
    "url_baja_demanda = \"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\"\n",
    "archivo_bd = \"input/pbd_equipos.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinacion de dataframes\n",
    "gs1 = GoogleSheetProcessor(url_baja_demanda)\n",
    "if descargar : gs1.download_csv(archivo_ad)\n",
    "df1 = pd.read_csv(archivo_ad,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GoogleSheetProcessor (url_baja_demanda)\n",
    "if descargar: gs2.download_csv(archivo_bd)\n",
    "df2 = pd.read_csv(archivo_bd,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix Dataframes\n",
    "\n",
    "Generar un mix con los 2 planes de mantto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar ambos dataframes\n",
    "df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "filename = \"input/mix_planes_script2.csv\"\n",
    "df_merged.to_csv(filename,sep=';')  # Exportar archivo mezclado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existen 12815 activos en la hoja de datos\n"
     ]
    }
   ],
   "source": [
    "df_output, df_db, df_result=gs1.process(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para base de datos\n",
    "Funciones necesarias para base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine.result import Result\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\"\"\" Para pasar a la base de datos\"\"\"\n",
    "\n",
    "def format_dataframe(df:pd.DataFrame,tabla:str,usuario='user_mantenimiento', password='pass_M4ntenimient0',host='192.168.100.56', database='db_mantenimiento_test'):\n",
    "    \n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    # Leer la tabla original en un DataFrame de pandas\n",
    "    df_origen = pd.read_sql_query(f\"SELECT * FROM {tabla}\", con=engine)\n",
    "\n",
    "    # Renombrar la columna 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "\n",
    "    # Si existe la columna 'uuid' en la tabla original, crear esa columna\n",
    "    if 'uuid' in df_origen.columns:\n",
    "        df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "    if 'is_active' in df_origen.columns:\n",
    "        df['is_active'] = True        \n",
    "\n",
    "    # Identificar las columnas que están en df_origen pero no en df\n",
    "    missing_columns = [col for col in df_origen.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columnas faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None #pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir columnas comunes\n",
    "    df['id'] = df.index +1 if df.index[0] ==0 else df.index\n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()\n",
    "    # Validar que las columnas de df y df_origen sean iguales\n",
    "    columnas_df = set(df.columns)\n",
    "    columnas_df_origen = set(df_origen.columns)\n",
    "    \n",
    "    # Si las columnas no son iguales, lanzar un error\n",
    "    assert columnas_df == columnas_df_origen, f\"Las columnas no coinciden. Columnas faltantes: {columnas_df_origen - columnas_df} en df y {columnas_df - columnas_df_origen} en df_origen\"        \n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def actualizar_tabla_postgres(df: pd.DataFrame, tabla: str, columna_id: str,\n",
    "                              usuario='user_mantenimiento', password='pass_M4ntenimient0', \n",
    "                              host='192.168.100.56', database='db_mantenimiento_test'):    \n",
    "    # Reemplazar NaN por None (que en SQL es equivalente a NULL)\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "        \n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        #connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.execute(text(f\"DELETE FROM {tabla} CASCADE;\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # Insertar los nuevos datos en la tabla\n",
    "    df.to_sql(tabla, con=engine, if_exists='append', index=False)  # Solo append en tablas con relaciones    \n",
    "\n",
    "    # Obtener el valor máximo de la columna 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX({columna_id}) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    # Obtener el nombre de la secuencia asociada a la columna 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\"))\n",
    "        id_secuencia = result.scalar()\n",
    "\n",
    "    # Reiniciar el valor de la secuencia si se obtiene la secuencia asociada\n",
    "    with engine.connect() as connection:\n",
    "        if id_secuencia:\n",
    "            connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "            connection.commit()\n",
    "            print(f'Se reinició el índice {id_secuencia} en {max_id + 1}')\n",
    "\n",
    "# Ejemplo de uso:\n",
    "## actualizar_tabla_postgres(df_plan, 'plans', 'id')\n",
    "def obtener_registros( tabla,  usuario='user_mantenimiento', password='pass_M4ntenimient0', host='192.168.100.56', database='db_mantenimiento_test',columna_ids=[]):\n",
    "    \"\"\"\n",
    "    Realiza un SELECT * en una tabla especificada de la base de datos y retorna un DataFrame con los resultados.\n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la sentencia SQL para obtener los registros\n",
    "        result = connection.execute(text(f'select * from {tabla}'))        \n",
    "        # Convertir los resultados en un DataFrame\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "        #df.index = df['index']\n",
    "        df.index = df['id']\n",
    "    return df if not columna_ids or len(columna_ids) == 0 else df[columna_ids]\n",
    "    \n",
    "def buscarIndice(df: pd.DataFrame, valor:str, columna_id='value'):\n",
    "        # Verificar si el valor está en la columna_id especificada\n",
    "        \"\"\"\n",
    "        Busca un valor en la columna especificada del DataFrame.\n",
    "        Si el valor de búsqueda es nulo o si no se encuentra, retorna el mismo valor de búsqueda.\n",
    "        \"\"\"\n",
    "        # Validar si el valor de búsqueda es nulo        \n",
    "            \n",
    "        if pd.isna(valor):\n",
    "            return None #pd.NA    \n",
    "        \n",
    "        #fkc_priority tiene el valor \"BAJA \" con espacio al final, eliminar el ultimo espacio Se añade a la funcion buscarIndice\n",
    "        valor = valor.upper().strip()\n",
    "\n",
    "        resultado = df[df[columna_id].str.upper() == valor]    \n",
    "        # Si no encuentra el valor, retornar el mismo valor\n",
    "        if resultado.empty:\n",
    "            return valor\n",
    "        else:\n",
    "            return int(resultado.index[0])\n",
    "\n",
    "def ejecutar_query(query, usuario='user_mantenimiento', password='pass_M4ntenimient0', host='192.168.100.56', database='db_mantenimiento_test'):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta SQL y devuelve el resultado en un DataFrame si la consulta devuelve filas.\n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la consulta\n",
    "        result = connection.execute(text(query))\n",
    "        connection.commit()\n",
    "        \n",
    "        # Verificar si la consulta devuelve filas\n",
    "        if result.returns_rows:\n",
    "            # Obtener los resultados en un DataFrame\n",
    "            df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "            return df\n",
    "        else:\n",
    "            # Si no devuelve filas, solo confirmar la ejecución\n",
    "            return None\n",
    "\n",
    "    return result\n",
    "def eliminar_registros(tabla,usuario='user_mantenimiento', password='pass_M4ntenimient0', host= 'localhost', database='db_mantenimiento_test'):\n",
    "    \"\"\"\n",
    "    Elimina todos los registros de una tabla especificada en la base de datos.    \n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la sentencia SQL para eliminar todos los registros\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.commit()  # Confirmar los cambios\n",
    "\n",
    "def __actualizar_tabla_postgres(df:pd.DataFrame , tabla:str, columna_id:str , usuario='user_mantenimiento', password='pass_M4ntenimient0', host= 'localhost', database='db_mantenimiento_test'):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "\n",
    "    # Usar pd.read_sql_query con una conexión\n",
    "        # Leer la tabla en un DataFrame de pandas\n",
    "    df_origen = ejecutar_query(f\"SELECT * FROM {tabla}\")\n",
    "\n",
    "    \n",
    "    # Renombrar la columna_id 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "    \n",
    "    # Si existe la columna_id uuid en la tabla original, crear esa columna_id\n",
    "    if 'uuid' in df_origen.columns:\n",
    "        df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "    \n",
    "    if 'is_active' in df_origen.columns:\n",
    "        df['is_active'] = True\n",
    "\n",
    "\n",
    "    # Identificar las columna_ids que están en df pero no en df_origen\n",
    "    missing_columns = [col for col in df_origen.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columna_ids faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None #pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir las columna_ids comunes en las tablas\n",
    "    df['id'] = df.index\n",
    "    \n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()   \n",
    "\n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        #connection.commit()\n",
    "    \n",
    "    # Insertar nuevos datos con pandas to_sql\n",
    "    df.to_sql(tabla, con= engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Obtener el valor máximo de la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX({columna_id}) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    \n",
    "    # Obtener el nombre de la secuencia asociada a la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"\"\"\n",
    "            SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\n",
    "        \"\"\"))\n",
    "        id_secuencia = result.scalar()  # Obtener el nombre de la secuencia\n",
    "    \n",
    "        \n",
    "    # Reiniciar el valor de la secuencia\n",
    "    with engine.connect() as connection:\n",
    "        # Si se tienen \n",
    "        if id_secuencia : connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "\n",
    "\n",
    "def update_plans_table(df,tabla, columna_id, usuario='user_mantenimiento', password='pass_M4ntenimient0', host= 'localhost', database='db_mantenimiento_test' ):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "\n",
    "    # Leer la tabla en un DataFrame de pandas\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabla}\", engine)\n",
    "\n",
    "    # Renombrar columna_id 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "\n",
    "    # Identificar las columna_ids que están en df pero no en df\n",
    "    missing_columns = [col for col in df.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columna_ids faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir/actualizar las columna_ids necesarias en df\n",
    "    df['id'] = df.index\n",
    "    df['is_active'] = True\n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()\n",
    "\n",
    "    # Obtener el nombre de la secuencia asociada a la columna_id 'id' en la tabla 'plans_test'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\"))\n",
    "        id_secuencia = result.scalar()  # Obtener el nombre de la secuencia\n",
    "\n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # Insertar nuevos datos con pandas to_sql\n",
    "    df.to_sql(tabla, engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Obtener el valor máximo de la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX(id) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    # Reiniciar el valor de la secuencia\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "import psycopg2\n",
    "def actualizar_fk_plan(df_base, usuario='user_mantenimiento', password='pass_M4ntenimient0', host= '192.168.100.56', database='db_mantenimiento_test'):\n",
    "    \"\"\"\n",
    "    Actualiza la columna fk_plan en la tabla 'base' de PostgreSQL \n",
    "    utilizando los datos proporcionados en df_base.\n",
    "\n",
    "    Parámetros:\n",
    "    - df_base: DataFrame con las columnas 'id' y 'fk_plan' a actualizar.\n",
    "    - host: Host de la base de datos.\n",
    "    - database: Nombre de la base de datos.\n",
    "    - user: Usuario para la conexión.\n",
    "    - password: Contraseña para la conexión.\n",
    "    \"\"\"\n",
    "    # Conexión a la base de datos PostgreSQL\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        user=usuario,\n",
    "        password=password,\n",
    "        #options=\"-c client_encoding=LATIN1\"  # Cambia 'LATIN1' por el encoding que utiliza tu base de datos si no es UTF-8\n",
    "\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Recorre cada fila del DataFrame para generar la consulta de actualización\n",
    "    for index, row in df_base.iterrows():\n",
    "        try: \n",
    "            query = f\"\"\"\n",
    "            UPDATE base\n",
    "            SET fk_plan = {row['fk_plan']}\n",
    "            WHERE id = {row['id']};\n",
    "            \"\"\"\n",
    "            cursor.execute(query)\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Error en la fila {index}:{e}\")\n",
    "    # Confirmar los cambios\n",
    "    conn.commit()\n",
    "\n",
    "    # Cerrar la conexión\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "# Definir el DataFrame df con tus datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plans = obtener_registros('plans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['fk_plan'] = df_result['plan'].apply(lambda x : buscarIndice(df_plans,x,'name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_excel('RevisarPlanEquipo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>location_code</th>\n",
       "      <th>plan</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>fk_plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC-PRI-MEPA-MEL</td>\n",
       "      <td>RO-S2-M1</td>\n",
       "      <td>MOTOR ELECTRICO PRINCIPAL</td>\n",
       "      <td>19.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACC-PRI-MEPA-MEL</td>\n",
       "      <td>RO-S1-M1</td>\n",
       "      <td>MOTOR ELECTRICO PRINCIPAL</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACC-PRI-MEPA-MEL</td>\n",
       "      <td>AM-S1-M1</td>\n",
       "      <td>MOTOR ELECTRICO PRINCIPAL</td>\n",
       "      <td>21.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACC-PRI-MEPA-MEL</td>\n",
       "      <td>AM-S2-M1</td>\n",
       "      <td>MOTOR ELECTRICO PRINCIPAL</td>\n",
       "      <td>22.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACC-PRI-MEPA-MEL</td>\n",
       "      <td>AZ-S1-M1</td>\n",
       "      <td>MOTOR ELECTRICO PRINCIPAL</td>\n",
       "      <td>25.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12840</th>\n",
       "      <td>SUM-GOL-GE</td>\n",
       "      <td>VE-S2-I1</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "      <td>19620.0</td>\n",
       "      <td>None</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12841</th>\n",
       "      <td>SUM-GOL-GE</td>\n",
       "      <td>VE-EDF-EOB</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "      <td>19621.0</td>\n",
       "      <td>None</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12842</th>\n",
       "      <td>SUM-GOL-GE</td>\n",
       "      <td>VE-EDF-EAO</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "      <td>19622.0</td>\n",
       "      <td>None</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12843</th>\n",
       "      <td>SUM-GOL-GE</td>\n",
       "      <td>VE-EDF-ELB</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "      <td>19623.0</td>\n",
       "      <td>None</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12844</th>\n",
       "      <td>SUM-GOL-GE</td>\n",
       "      <td>BL-EDF-EVI</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRUPO ELECTROGENO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12845 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tag location_code                        plan       id  \\\n",
       "0      ACC-PRI-MEPA-MEL      RO-S2-M1  MOTOR ELECTRICO PRINCIPAL      19.0   \n",
       "1      ACC-PRI-MEPA-MEL      RO-S1-M1  MOTOR ELECTRICO PRINCIPAL      20.0   \n",
       "2      ACC-PRI-MEPA-MEL      AM-S1-M1  MOTOR ELECTRICO PRINCIPAL      21.0   \n",
       "3      ACC-PRI-MEPA-MEL      AM-S2-M1  MOTOR ELECTRICO PRINCIPAL      22.0   \n",
       "4      ACC-PRI-MEPA-MEL      AZ-S1-M1  MOTOR ELECTRICO PRINCIPAL      25.0   \n",
       "...                 ...           ...                         ...      ...   \n",
       "12840        SUM-GOL-GE      VE-S2-I1           GRUPO ELECTROGENO  19620.0   \n",
       "12841        SUM-GOL-GE    VE-EDF-EOB           GRUPO ELECTROGENO  19621.0   \n",
       "12842        SUM-GOL-GE    VE-EDF-EAO           GRUPO ELECTROGENO  19622.0   \n",
       "12843        SUM-GOL-GE    VE-EDF-ELB           GRUPO ELECTROGENO  19623.0   \n",
       "12844        SUM-GOL-GE    BL-EDF-EVI           GRUPO ELECTROGENO      NaN   \n",
       "\n",
       "       name            fk_plan  \n",
       "0      None                  1  \n",
       "1      None                  1  \n",
       "2      None                  1  \n",
       "3      None                  1  \n",
       "4      None                  1  \n",
       "...     ...                ...  \n",
       "12840  None  GRUPO ELECTROGENO  \n",
       "12841  None  GRUPO ELECTROGENO  \n",
       "12842  None  GRUPO ELECTROGENO  \n",
       "12843  None  GRUPO ELECTROGENO  \n",
       "12844   NaN  GRUPO ELECTROGENO  \n",
       "\n",
       "[12845 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar el dataframe de datos invalidos.\n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fk_structure</th>\n",
       "      <th>fk_asset</th>\n",
       "      <th>fk_location</th>\n",
       "      <th>fkc_priority</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>fk_plan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>203.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>251.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>516.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>485.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20135</th>\n",
       "      <td>20135</td>\n",
       "      <td>2071</td>\n",
       "      <td>20135</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-02-28 15:36:28.622000-04:00</td>\n",
       "      <td>2024-02-28 16:57:57.244000-04:00</td>\n",
       "      <td>2024-02-28 16:57:57.244000-04:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20133</th>\n",
       "      <td>20133</td>\n",
       "      <td>2069</td>\n",
       "      <td>20133</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-02-28 15:35:20.797000-04:00</td>\n",
       "      <td>2024-02-28 16:58:06.384000-04:00</td>\n",
       "      <td>2024-02-28 16:58:06.384000-04:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20308</th>\n",
       "      <td>20308</td>\n",
       "      <td>2612</td>\n",
       "      <td>20308</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-05-21 18:36:51.019000-04:00</td>\n",
       "      <td>2024-05-21 18:36:51.019000-04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>2133.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-09-21 17:06:13.830436-04:00</td>\n",
       "      <td>2024-10-08 15:09:46.735000-04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20311</th>\n",
       "      <td>20311</td>\n",
       "      <td>2</td>\n",
       "      <td>20311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-10-09 10:50:06.778000-04:00</td>\n",
       "      <td>2024-10-09 10:50:06.778000-04:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20298 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  fk_structure  fk_asset  fk_location  fkc_priority  created_by  \\\n",
       "id                                                                            \n",
       "1          1             1         1         32.0         151.0           1   \n",
       "3          3             1         3        203.0         151.0           1   \n",
       "4          4             1         4        251.0         151.0           1   \n",
       "5          5             1         5        516.0         151.0           1   \n",
       "6          6             1         6        485.0         151.0           1   \n",
       "...      ...           ...       ...          ...           ...         ...   \n",
       "20135  20135          2071     20135       1506.0           NaN           7   \n",
       "20133  20133          2069     20133       1506.0           NaN           7   \n",
       "20308  20308          2612     20308       1335.0           NaN           7   \n",
       "126      126             7       126       2133.0         150.0           1   \n",
       "20311  20311             2     20311          NaN           NaN          62   \n",
       "\n",
       "       updated_by deleted_by                       created_at  \\\n",
       "id                                                              \n",
       "1               1       None 2023-09-21 17:06:13.830436-04:00   \n",
       "3               1       None 2023-09-21 17:06:13.830436-04:00   \n",
       "4               1       None 2023-09-21 17:06:13.830436-04:00   \n",
       "5               1       None 2023-09-21 17:06:13.830436-04:00   \n",
       "6               1       None 2023-09-21 17:06:13.830436-04:00   \n",
       "...           ...        ...                              ...   \n",
       "20135           7       None 2024-02-28 15:36:28.622000-04:00   \n",
       "20133           7       None 2024-02-28 15:35:20.797000-04:00   \n",
       "20308           7       None 2024-05-21 18:36:51.019000-04:00   \n",
       "126            62       None 2023-09-21 17:06:13.830436-04:00   \n",
       "20311          62       None 2024-10-09 10:50:06.778000-04:00   \n",
       "\n",
       "                            updated_at                       deleted_at  \\\n",
       "id                                                                        \n",
       "1     2023-09-21 17:06:13.830436-04:00                              NaT   \n",
       "3     2023-09-21 17:06:13.830436-04:00                              NaT   \n",
       "4     2023-09-21 17:06:13.830436-04:00                              NaT   \n",
       "5     2023-09-21 17:06:13.830436-04:00                              NaT   \n",
       "6     2023-09-21 17:06:13.830436-04:00                              NaT   \n",
       "...                                ...                              ...   \n",
       "20135 2024-02-28 16:57:57.244000-04:00 2024-02-28 16:57:57.244000-04:00   \n",
       "20133 2024-02-28 16:58:06.384000-04:00 2024-02-28 16:58:06.384000-04:00   \n",
       "20308 2024-05-21 18:36:51.019000-04:00                              NaT   \n",
       "126   2024-10-08 15:09:46.735000-04:00                              NaT   \n",
       "20311 2024-10-09 10:50:06.778000-04:00                              NaT   \n",
       "\n",
       "       fk_plan  \n",
       "id              \n",
       "1          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "...        ...  \n",
       "20135      NaN  \n",
       "20133      NaN  \n",
       "20308      NaN  \n",
       "126        5.0  \n",
       "20311      NaN  \n",
       "\n",
       "[20298 rows x 12 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtener_registros('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df_result[['id','fk_plan']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar instancias solo numeros o float\n",
    "df_base = df_base[df_base['fk_plan'].apply(lambda x: isinstance(x, (int, float)) and not pd.isnull(x))]\n",
    "# Filtrar instancias que no encontraron id\n",
    "df_base = df_base[df_base['id'].notnull()]\n",
    "# Convertir la columna 'id' de float a entero, omitiendo los valores nulos\n",
    "df_base['id'] = df_base['id'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     fk_plan\n",
       "False  False      10660\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conteo de valores nulos\n",
    "df_base.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_excel(\"df_base.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar la tabla 'base' en la base de datos con la información proporcionada \n",
    "actualizar_fk_plan(df_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ## Script 2\\n# https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\\nimport warnings\\nimport pandas as pd\\nimport ipywidgets as widgets\\nfrom ipywidgets import Button, Layout\\nfrom IPython.display import display\\n\\n#warnings.simplefilter(action=\\'ignore\\', category=FutureWarning)\\n\\nlad = widgets.Textarea(value=\\'https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\\',placeholder=\\'Plan Maestro LAD\\',description=\\'Lineas Alta Demanda:\\',disabled=False,layout=Layout(width=\\'70%\\',height=\"200px\"))\\nlbd = widgets.Textarea(value=\\'https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\\',placeholder=\\'Plan Maestro LBD\\',description=\\'Lineas Baja Demanda:\\',disabled=False,layout=Layout(width=\\'70%\\',height=\"200px\"))\\nhost = widgets.Text(value=\\'192.168.100.50\\',placeholder=\\'Host\\',description=\\'Host:\\',disabled=False)\\nbasedatos = widgets.Text(value=\\'simyo2\\',placeholder=\\'BaseDatos\\',description=\\'BaseDatos\\',disabled=False)\\nusuario = widgets.Text(value=\\'mantto\\',description=\\'Usuario\\')\\npassword = widgets.Password(value=\\'Sistemas0\\',description=\\'Password\\')\\nbutton1 = widgets.Button(description=\"Generar Archivo Excel\",button_style=\\'success\\',layout=Layout(width=\\'20%\\'))\\nbutton2 = widgets.Button(description=\"Cargar en Base de datos\",button_style=\\'danger\\',layout=Layout(width=\\'20%\\'))\\noutput = widgets.Output()\\nsalida = widgets.Text(value=\"output/Salida_Planes.xlsx\",description=\"Nombre:\",disabled=False)\\naccordion = widgets.Accordion(children=[ salida], titles=([\\'Archivo Salida\\']))\\naccordion1 = widgets.Accordion(children=[ usuario,password,host,basedatos], titles=(\\'Usuario\\',\\'Password\\',\\'Host\\',\\'Base de Datos\\'))\\n\\ndisplay(lad,lbd,host,usuario,password,accordion,button1, accordion1,button2,output)\\n\\ndef on_button_clicked(b):    \\n    # Combinacion de dataframes\\n    gs1 = GoogleSheetProcessor(lad.value) # (\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\")\\n    archivo = \"input/pad_planes.csv\"\\n    #gs1.download_csv(archivo)\\n    df1 = pd.read_csv(archivo,header=3,true_values=[\\'True\\',\\'TRUE\\'],false_values=[\\'False\\',\"FALSE\",\"\"])\\n\\n\\n    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\")\\n    archivo = \"input/pbd_planes.csv\"\\n    #gs2.download_csv(archivo)\\n    df2 = pd.read_csv(archivo,header=3,true_values=[\\'True\\',\\'TRUE\\'],false_values=[\\'False\\',\"FALSE\",\"\"])\\n\\n    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\\n    filename = \"input/mix_planes.csv\"\\n    df_merged.to_csv(filename,sep=\\';\\')\\n\\n    df_output, df_db, df_result=gs1.process(df_merged)\\n    df_result.to_excel(salida.value)\\n    \\n    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \\n    with output:\\n        print(f\"Se Genera archivo excel {salida.value}\")\\n\\nbutton1.on_click(on_button_clicked)\\nbutton2.on_click(lambda _: print(\"Boton 2 accionado\"))\\n#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html\\n## Script 2 '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ## Script 2\n",
    "# https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import display\n",
    "\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "lad = widgets.Textarea(value='https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678',placeholder='Plan Maestro LAD',description='Lineas Alta Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "lbd = widgets.Textarea(value='https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678',placeholder='Plan Maestro LBD',description='Lineas Baja Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "host = widgets.Text(value='192.168.100.50',placeholder='Host',description='Host:',disabled=False)\n",
    "basedatos = widgets.Text(value='simyo2',placeholder='BaseDatos',description='BaseDatos',disabled=False)\n",
    "usuario = widgets.Text(value='mantto',description='Usuario')\n",
    "password = widgets.Password(value='Sistemas0',description='Password')\n",
    "button1 = widgets.Button(description=\"Generar Archivo Excel\",button_style='success',layout=Layout(width='20%'))\n",
    "button2 = widgets.Button(description=\"Cargar en Base de datos\",button_style='danger',layout=Layout(width='20%'))\n",
    "output = widgets.Output()\n",
    "salida = widgets.Text(value=\"output/Salida_Planes.xlsx\",description=\"Nombre:\",disabled=False)\n",
    "accordion = widgets.Accordion(children=[ salida], titles=(['Archivo Salida']))\n",
    "accordion1 = widgets.Accordion(children=[ usuario,password,host,basedatos], titles=('Usuario','Password','Host','Base de Datos'))\n",
    "\n",
    "display(lad,lbd,host,usuario,password,accordion,button1, accordion1,button2,output)\n",
    "\n",
    "def on_button_clicked(b):    \n",
    "    # Combinacion de dataframes\n",
    "    gs1 = GoogleSheetProcessor(lad.value) # (\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1115106678#gid=1115106678\")\n",
    "    archivo = \"input/pad_planes.csv\"\n",
    "    #gs1.download_csv(archivo)\n",
    "    df1 = pd.read_csv(archivo,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n",
    "\n",
    "\n",
    "    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1115106678#gid=1115106678\")\n",
    "    archivo = \"input/pbd_planes.csv\"\n",
    "    #gs2.download_csv(archivo)\n",
    "    df2 = pd.read_csv(archivo,header=3,true_values=['True','TRUE'],false_values=['False',\"FALSE\",\"\"])\n",
    "\n",
    "    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "    filename = \"input/mix_planes.csv\"\n",
    "    df_merged.to_csv(filename,sep=';')\n",
    "\n",
    "    df_output, df_db, df_result=gs1.process(df_merged)\n",
    "    df_result.to_excel(salida.value)\n",
    "    \n",
    "    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \n",
    "    with output:\n",
    "        print(f\"Se Genera archivo excel {salida.value}\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(lambda _: print(\"Boton 2 accionado\"))\n",
    "#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html\n",
    "## Script 2 '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
