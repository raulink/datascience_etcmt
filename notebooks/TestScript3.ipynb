{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a40ae54f9ed472897ae1815e7654941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b4b4f277284934a70a7c4fcda76299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2867151c61e448a08bf6ff98f1d861b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Text(value='user_gom_mantenimiento', description='Usuario'), Password(description='Passwor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94db08afcc4f48218348fe8457ee7a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Generar Archivo Excel', layout=Layout(width='20%'), style=ButtonSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba5f5651cc44ba9837a41a0cd9a01cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Cargar en Base de datos', layout=Layout(width='20%'), style=ButtonS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57be848f256c47cf93986b7399e6eb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(),), titles=('',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Variables\n",
    "lad = 'https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294'\n",
    "lbd = 'https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294'\n",
    "host = '192.168.100.56' #'localhost'#'192.168.100.50'\n",
    "basedatos= 'db_mantenimiento_test' #'db_mantenimiento'\n",
    "usuario = 'user_gom_mantenimiento' #'postgres'\n",
    "password = 'M4ntenim13nto.' #''\n",
    "salida = \"Salida.xlsx\"\n",
    "# Bloque de variables\n",
    "descargar = False\n",
    "url_alta_demanda =lad\n",
    "archivo_ad = \"input/pad_actividades.csv\"\n",
    "url_baja_demanda = lbd\n",
    "archivo_bd = \"input/pbd_actividades.csv\"\n",
    "filename_actividades = \"input/mix_plan_actividades.csv\"\n",
    "\n",
    "valores = {\n",
    "    \"D\": 1,\n",
    "    \"S\": 1,\n",
    "    \"2S\": 2,\n",
    "    \"M\": 5,\n",
    "    \"MC\": 1,\n",
    "    \"2M\": 2,\n",
    "    \"T\": 3,\n",
    "    \"SE\": 6,\n",
    "    \"8M\": 8,\n",
    "    \"A\": 1,\n",
    "    \"1.5A\": 18,\n",
    "    \"2A\": 2,\n",
    "    \"3A\": 3,\n",
    "    \"4A\": 4,\n",
    "    \"5A\": 5,\n",
    "    \"6A\": 6,\n",
    "    \"8A\": 8,\n",
    "    \"10A\": 10,\n",
    "    \"1000\": 1000,\n",
    "    \"1300\": 1300,\n",
    "    \"1800\": 1800,\n",
    "    \"6000\": 6000,\n",
    "    \"22500\": 6000,\n",
    "    \"40000\": 40000,\n",
    "    \"55000\": 55000,\n",
    "    \"55000C\": 55000}\n",
    "regimen = {\n",
    "    \"D\": 'dia(s)',\n",
    "    \"S\": 'semana(s)',\n",
    "    \"2S\": 'semana(s)',\n",
    "    \"M\": 'semana(s)',\n",
    "    \"MC\": 'mes(es)',\n",
    "    \"2M\": 'mes(es)',\n",
    "    \"T\": 'mes(es)',\n",
    "    \"SE\": 'mes(es)',\n",
    "    \"8M\": 'mes(es)',\n",
    "    \"A\": 'año(s)',\n",
    "    \"1.5A\": 'mes(es)',\n",
    "    \"2A\": 'año(s)',\n",
    "    \"3A\": 'año(s)',\n",
    "    \"4A\": 'año(s)',\n",
    "    \"5A\": 'año(s)',\n",
    "    \"6A\": 'año(s)',\n",
    "    \"8A\": 'año(s)',\n",
    "    \"10A\": 'año(s)',\n",
    "    \"1000\": 'horas',\n",
    "    \"1300\": 'horas',\n",
    "    \"1800\": 'horas',\n",
    "    \"6000\": 'horas',\n",
    "    \"22500\": 'horas',\n",
    "    \"40000\": 'horas',\n",
    "    \"55000\": 'horas',\n",
    "    \"55000C\": 'ciclos'\n",
    "}\n",
    "\n",
    "wlad = widgets.Textarea(value=lad,placeholder='Plan Maestro LAD',description='Lineas Alta Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "wlbd = widgets.Textarea(value=lbd,placeholder='Plan Maestro LBD',description='Lineas Baja Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "whost = widgets.Text(value=host,placeholder='Host',description='Host:',disabled=False)\n",
    "wbasedatos = widgets.Text(value=basedatos,placeholder='BaseDatos',description='BaseDatos',disabled=False)\n",
    "wusuario = widgets.Text(value=usuario,description='Usuario')\n",
    "wpassword = widgets.Password(value=password,description='Password')\n",
    "wbutton1 = widgets.Button(description=\"Generar Archivo Excel\",button_style='success',layout=Layout(width='20%'))\n",
    "wbutton2 = widgets.Button(description=\"Cargar en Base de datos\",button_style='danger',layout=Layout(width='20%'))\n",
    "woutput = widgets.Output()\n",
    "wsalida = widgets.Text(value=salida,description=\"Nombre:\",disabled=False)\n",
    "\n",
    "waccordion = widgets.Accordion(children=[ wusuario,wpassword,whost,wbasedatos], titles=('Usuario','Password','Host','Base de Datos'))\n",
    "wsalida = widgets.Accordion(children=[ woutput])\n",
    "\n",
    "display(wlad,wlbd,waccordion,wbutton1,wbutton2,wsalida)\n",
    "\n",
    "def on_button_clicked(b):                \n",
    "    with woutput:\n",
    "        print(\"Ejecucion Script Fase 1\")\n",
    "\n",
    "def on_button_clicked_2(b):                \n",
    "    with woutput:\n",
    "        print(\"Ejecucion Script Fase 2\")\n",
    "\n",
    "wbutton1.on_click(on_button_clicked)\n",
    "wbutton2.on_click(on_button_clicked_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script de migracion de datos\n",
    "\n",
    "Este programa está diseñado para procesar datos de, en el caso de los planes de mantenimiento, se tienen 2 planes de mantenimiento (Lineas de Alta Demanda LAD y Lineas de Baja Demanda LBD) descargándolos, transformándolos y guardándolos en un archivo Excel. La clase principal, GoogleSheetProcessor, maneja todo el flujo de trabajo, desde la obtención de datos hasta su procesamiento y almacenamiento. A continuación se describe el funcionamiento detallado del programa.\n",
    "\n",
    "## Funcionalidades Principales\n",
    "1. Inicialización (__init__)\n",
    "La clase se inicializa con la URL de una hoja de cálculo de Google Sheets. Durante la inicialización, se extraen los identificadores del archivo y de la hoja específica, y se construye la URL para exportar la hoja en formato CSV.\n",
    "\n",
    "### Atributos:\n",
    "\n",
    "sheet_url: URL de la hoja de cálculo de Google Sheets.\n",
    "spreadsheet_id: ID único de la hoja de cálculo.\n",
    "sheet_id: ID único de la hoja dentro de la hoja de cálculo.\n",
    "csv_export_url: URL para exportar la hoja en formato CSV.\n",
    "\n",
    "### Diccionarios predefinidos:\n",
    "\n",
    "valores: Diccionario que asocia códigos con valores numéricos. Este diccionario de valores es dependiendo las columnas de la hoja de calculo, especifico a las frecuencias \n",
    "regimen: Diccionario que asocia códigos con sus unidades de medida correspondientes.\n",
    "\n",
    "\n",
    "1. Extracción de Identificadores\n",
    "extract_spreadsheet_id(url): Extrae el ID de la hoja de cálculo desde la URL.\n",
    "extract_sheet_id(url): Extrae el ID de la hoja específica desde la URL.\n",
    "2. Construcción de la URL de Exportación\n",
    "construct_csv_export_url(): Construye la URL que permite descargar la hoja de cálculo en formato CSV.\n",
    "3. Descarga de la Hoja en CSV\n",
    "download_csv(output_filename='temp_sheet.csv'): Descarga la hoja de cálculo en formato CSV y la guarda con un nombre de archivo especificado (por defecto, temp_sheet.csv).\n",
    "4. Procesamiento de Datos\n",
    "process_data(filename=\"temp_sheet.csv\", valores=\"\", regimen=\"\"):\n",
    "Carga el archivo CSV y realiza una serie de transformaciones y filtrados en los datos, como la conversión de valores, la asignación de unidades, y la reestructuración del DataFrame.\n",
    "Comprueba que las claves de los diccionarios valores y regimen coinciden, lanzando un AssertionError si no es así.\n",
    "Filtra los datos para excluir planes y mantener solo las columnas relevantes.\n",
    "Realiza transformaciones en el DataFrame para preparar la información que se almacenará en Excel.\n",
    "Retorna los DataFrames df_plan, df_action, df_speciality y filtered_data.\n",
    "5. Guardar Resultados en Excel\n",
    "save_to_excel(output_path=\"Salida.xlsx\", filename=\"mix_plan.csv\", valores=\"\", regimen=\"\"):\n",
    "Llama al método process_data para obtener los DataFrames procesados.\n",
    "Guarda los DataFrames resultantes en un archivo Excel con hojas separadas para acciones, planes, especialidades y actividades filtradas.\n",
    "6. Funciones Auxiliares\n",
    "get_unique(df: pd.DataFrame, column: str): Genera un DataFrame con valores únicos de una columna específica, ajustando los índices.\n",
    "buscarIndice(df: pd.DataFrame, valor, columna='value'): Busca el índice de un valor específico en un DataFrame y lo retorna como un entero.\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Inicio] --> B[Inicializa GoogleSheetProcessor con lad.value]\n",
    "    B --> C[Lee CSV desde input/pad.csv]\n",
    "    C --> D[Inicializa GoogleSheetProcessor con lbd.value]\n",
    "    D --> E[Lee CSV desde input/pbd.csv]\n",
    "    E --> F[Concatena los DataFrames df1 y df2]\n",
    "    F --> G[Guarda el DataFrame combinado indicado en el campo salida]    \n",
    "    G --> H[Guarda el Dataframe directamente en la base de datos indicada]\n",
    "\n",
    "```\n",
    "\n",
    "Descripción del Flujograma\n",
    "* Inicio: El proceso comienza con la inicialización del primer GoogleSheetProcessor con la URL contenida en lad.value.\n",
    "* Lectura del primer CSV: Se lee el archivo CSV asociado al primer DataFrame desde la ruta input/pad.csv.\n",
    "* Inicialización del segundo GoogleSheetProcessor: Se inicializa el segundo objeto GoogleSheetProcessor con la URL contenida en lbd.value.\n",
    "* Lectura del segundo CSV: Se lee el archivo CSV asociado al segundo DataFrame desde la ruta input/pbd.csv.\n",
    "* Concatenación de DataFrames: Los dos DataFrames (df1 y df2) se combinan en uno solo mediante pd.concat.\n",
    "* Guardar el DataFrame combinado: El DataFrame combinado se guarda en un archivo CSV en la ruta input/mix_plan.csv.\n",
    "* Procesamiento y Almacenamiento de hoja de calculo procesada: Se puede almacenar en archivo excel o directamente en la base de datos, \n",
    "\n",
    "\n",
    "### Pantalla 1\n",
    "Al presionar el boton de _Generar Archivo Excel_ se realiza la generación del archivo excel en la carpeta output, colocando el nombre del archivo excel que se encuetnra en el campo de salida.\n",
    "\n",
    "![Pantalla 1](assets/pantalla1.png \"Pantalla 1\")\n",
    "\n",
    "### Pantalla 2\n",
    "\n",
    "En este apartado se colocan los datos de conexion de la base de datos. Al presionar el botón de _Cargar en Base de datos_ se procede a conectar y a volcar el dataframe en la base de datos indicada en los datos de usuario, password, host y base de datos de destino.\n",
    "\n",
    "![Pantalla 2](assets/pantalla2.png \"Pantalla 2\")\n",
    "\n",
    "\n",
    "\n",
    "> Nota. Exportar directamente en la base de datos aun no es posible, se requiere complementar el codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "class GoogleSheetProcessor1:\n",
    "    def __init__(self, sheet_url:str):\n",
    "        self.sheet_url = sheet_url\n",
    "        self.spreadsheet_id = self.extract_spreadsheet_id(sheet_url)\n",
    "        self.sheet_id = self.extract_sheet_id(sheet_url)\n",
    "        self.csv_export_url = self.construct_csv_export_url()\n",
    "\n",
    "        # Diccionarios originales\n",
    "        self.valores = {\n",
    "            \"D\": 1, \"S\": 1, \"M\": 5, \"MC\": 1, \"2M\": 2, \"T\": 3, \"4M\": 4, \"SE\": 6,\n",
    "            \"8M\": 8, \"A\": 1, \"1.5A\": 18, \"2A\": 2, \"3A\": 3, \"4A\": 4, \"5A\": 5,\n",
    "            \"6A\": 6, \"8A\": 8, \"10A\": 10, \"1000\": 1000, \"6000\": 6000, \"22500\": 22500,\n",
    "            \"40000\": 40000, \"55000\": 55000\n",
    "        }\n",
    "\n",
    "        self.regimen = {\n",
    "            \"D\": 'dia', \"S\": 'semana', \"M\": 'semana', \"MC\": 'mes', \"2M\": 'mes', \"T\": 'mes',\n",
    "            \"4M\": 'mes', \"SE\": 'mes', \"8M\": 'mes', \"A\": 'año', \"1.5A\": 'mes', \"2A\": 'año',\n",
    "            \"3A\": 'año', \"4A\": 'año', \"5A\": 'año', \"6A\": 'año', \"8A\": 'año', \"10A\": 'año',\n",
    "            \"1000\": 'horas', \"6000\": 'horas', \"22500\": 'horas', \"40000\": 'horas', \"55000\": 'horas'\n",
    "        }\n",
    "\n",
    "    def extract_spreadsheet_id(self, url):\n",
    "        return url.split('/d/')[1].split('/')[0]\n",
    "\n",
    "    def extract_sheet_id(self, url):\n",
    "        return url.split('gid=')[1]\n",
    "\n",
    "    def construct_csv_export_url(self):\n",
    "        return f\"https://docs.google.com/spreadsheets/d/{self.spreadsheet_id}/export?format=csv&gid={self.sheet_id}\"\n",
    "\n",
    "    def download_csv(self, output_filename='temp_sheet.csv'):\n",
    "        # Descarga el archivo CSV y lo guarda temporalmente\n",
    "        response = requests.get(self.csv_export_url)\n",
    "        response.raise_for_status()  # Asegurarse de que la solicitud fue exitosa\n",
    "        with open(output_filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return output_filename\n",
    "    def get_unique(self, df: pd.DataFrame, column: str):\n",
    "        \"\"\"\n",
    "        Obtiene un DataFrame con valores únicos de la columna 'Column', con índices ajustados.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: Un DataFrame con valores únicos de la columna 'Column' y un índice ajustado.\n",
    "        \"\"\"\n",
    "        df[column] = df[column].str.strip()\n",
    "        df = df[df[column].notnull()]\n",
    "        df_unique = pd.DataFrame(df[column].unique(), columns=['value'])\n",
    "        df_unique.index = df_unique.index + 1\n",
    "        return df_unique\n",
    "\n",
    "\n",
    "    def buscarIndice(self, df: pd.DataFrame, valor:str, columna_id='value'):\n",
    "        # Verificar si el valor está en la columna_id especificada\n",
    "        \"\"\"\n",
    "        Busca un valor en la columna especificada del DataFrame.\n",
    "        Si el valor de búsqueda es nulo o si no se encuentra, retorna el mismo valor de búsqueda.\n",
    "        \"\"\"\n",
    "        # Validar si el valor de búsqueda es nulo        \n",
    "            \n",
    "        if pd.isna(valor):\n",
    "            return None #pd.NA    \n",
    "        \n",
    "        #fkc_priority tiene el valor \"BAJA \" con espacio al final, eliminar el ultimo espacio Se añade a la funcion buscarIndice\n",
    "        valor = valor.upper().strip()\n",
    "\n",
    "        resultado = df[df[columna_id].str.upper() == valor]    \n",
    "        # Si no encuentra el valor, retornar el mismo valor\n",
    "        if resultado.empty:\n",
    "            return valor\n",
    "        else:\n",
    "            return int(resultado.index[0])\n",
    "\n",
    "\n",
    "    def read_csv(self, filename=\"temp_sheet.csv\"):\n",
    "        # Lee el archivo CSV usando pandas\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.df.columns = self.df.loc[2, :].to_list()  # la fila 2 como fila\n",
    "        self.df = self.df.loc[4:, :]   # Obtener desde la fila 4 en adelante\n",
    "        return self.df\n",
    "    \n",
    "    def process_data_with_validation(self, df: pd.DataFrame, valores: dict):\n",
    "        # Iterar sobre las claves del diccionario valores\n",
    "        for col in valores.keys():\n",
    "            # Verificar si la columna existe en el DataFrame\n",
    "            if col in df.columns:\n",
    "                # Comprobar si la columna no es booleana\n",
    "                if not pd.api.types.is_bool_dtype(df[col]):\n",
    "                    # Si no es booleana, intentamos convertirla\n",
    "                    df[col] = df[col].apply(lambda x: True if str(x).upper() == 'TRUE' else False)\n",
    "                    # df[list(valores.keys())] = df[valores.keys()].applymap(lambda x: True if x == 'TRUE' else False)\n",
    "            else:\n",
    "                print(f\"La columna '{col}' no se encuentra en el DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    def process_data(self,filename = \"temp_sheet.csv\",valores=\"\", regimen=\"\"):        \n",
    "        df = pd.DataFrame()\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        if valores == \"\":valores = self.valores    \n",
    "        if regimen == \"\":regimen = self.regimen\n",
    "        \n",
    "        if valores.keys() != regimen.keys():\n",
    "            raise AssertionError(f\"Las claves no coinciden: {valores.keys()} != {regimen.keys()}\")\n",
    "\n",
    "        # Realiza el procesamiento necesario\n",
    "        # Este es un lugar para incluir toda la lógica de procesamiento\n",
    "        \n",
    "        # Suponiendo que el procesamiento produce 'filtered_data' y otros DataFrames\n",
    "        df_plan = pd.DataFrame()  # Placeholder\n",
    "        df_action = pd.DataFrame()  # Placeholder\n",
    "        df_speciality = pd.DataFrame()  # Placeholder\n",
    "        filtered_data = pd.DataFrame()  # Placeholder        \n",
    "        #print(valores)\n",
    "        ## convertir a booleano\n",
    "        # df[list(valores.keys())] = df[valores.keys()].applymap(lambda x: True if x == 'TRUE' else False)\n",
    "        ## convertir a booleano\n",
    "        df = self.process_data_with_validation(df,valores)\n",
    "        #print(df.dtypes)\n",
    "\n",
    "        # Quitar planes\n",
    "        df = df[df['Tipo_plan']!= 'Plan']   # Se cambio de Tipo a Tipo_plan el 5-9-24\n",
    "\n",
    "        # Obtener la unidades\n",
    "        parametros = regimen\n",
    "        df['unidad'] = df.apply(lambda row: next((parametros[key] for key in parametros.keys() if key in row and row[key] == True), None), axis=1)\n",
    "        # Obtener los valores\n",
    "        parametros = valores\n",
    "        df['valor'] = df.apply(lambda row: next((parametros[key] for key in parametros.keys() if key in row and row[key] == True), None), axis=1)\n",
    "        # Filtrar las columnas necesarias solamente\n",
    "        #print(\"Valores unicos en unidades: \")\n",
    "        #print(df['unidad'].unique())        \n",
    "        # Mantener solo las columnas necesarias\n",
    "        columns = ['Plan','Accion','Trabajo','Actividad','Tipo_plan','Parada','Relevancia','Especialidad','valor','unidad']\n",
    "        df = df[columns]\n",
    "        # Crear la nueva columna fk_activity que tendra relaciones con las actividades padre\n",
    "        df['fk_activity']= None\n",
    "        df['fkc_regime']= None\n",
    "\n",
    "        # renombrar los nombres de las columnas\n",
    "        nuevos_nombres = {\n",
    "            'Plan': 'fk_plan',\n",
    "            'Accion': 'fk_action',\n",
    "            'Actividad': 'name',\n",
    "            'Tipo_plan': 'fkc_activity_type',\n",
    "            'Relevancia': 'fkc_priority',\n",
    "            'Especialidad': 'fk_specialty',\n",
    "            'valor': 'time_interval_value',\n",
    "            'unidad': 'fk_periodicity_unit',\n",
    "            'Parada': 'stoppage',\n",
    "        }\n",
    "        df.rename(columns=nuevos_nombres, inplace=True)\n",
    "                # Mantener las columnas del excel en el orden indicado\n",
    "        columnas_excel = ['fk_activity','fk_plan','fk_action','name','fkc_activity_type','fkc_priority','fk_specialty','fkc_regime','stoppage','time_interval_value','fk_periodicity_unit'] \n",
    "\n",
    "        df = df[columnas_excel]\n",
    "        df_plan = self.get_unique(df,\"fk_plan\")\n",
    "        df_action = self.get_unique(df,\"fk_action\")\n",
    "        df_speciality = self.get_unique(df,\"fk_specialty\")\n",
    "        df_activity_type = self.get_unique(df,\"fkc_activity_type\")\n",
    "        df_regime = self.get_unique(df,\"fkc_regime\")\n",
    "\n",
    "        # Filter the data\n",
    "        #df = df_raw.copy(deep=True)\n",
    "        filtered_data = df[(df['fkc_activity_type'] == 'Actividad') | (df['fkc_activity_type'] == 'Tarea')]\n",
    "        \n",
    "        # Add fk_activity column\n",
    "        filtered_data['fk_activity'] = None\n",
    "\n",
    "        # Buscar fk_activity para las Tareas que provienen de una Actividad\n",
    "        parent_index = None\n",
    "        for i, row in filtered_data.iterrows():\n",
    "            if row['fkc_activity_type'] == 'Actividad':\n",
    "                parent_index = i\n",
    "            elif row['fkc_activity_type'] == 'Tarea':\n",
    "                filtered_data.at[i, 'fk_activity'] = parent_index\n",
    "\n",
    "        # Obtener los ids de la relacion con los otros dataframes\n",
    "        filtered_data['fk_plan']= filtered_data['fk_plan'].apply(lambda x: self.buscarIndice(df_plan,x))\n",
    "        filtered_data['fk_action']= filtered_data['fk_action'].apply(lambda x: self.buscarIndice(df_action,x)) \n",
    "        filtered_data['fk_specialty']= filtered_data['fk_specialty'].apply(lambda x: self.buscarIndice(df_speciality,x)) \n",
    "        valores_lecturas=['horas','ciclos']\n",
    "        # Discriminar si las lecturas son horas o ciclos colocar FECHAS O LECTURAS\n",
    "        filtered_data['fkc_regime'] = filtered_data['fk_periodicity_unit'].apply(lambda x: 'LECTURAS' if x in valores_lecturas else 'FECHAS')\n",
    "        # Filtrar y aplicar los cambios correspondientes, mover los valores a las columnas de uso\n",
    "        filtered_data.loc[filtered_data['fk_periodicity_unit'].isin(valores_lecturas), 'usage_interval_value'] = filtered_data['time_interval_value']\n",
    "        filtered_data.loc[filtered_data['fk_periodicity_unit'].isin(valores_lecturas), 'fk_usage_unit'] = filtered_data['fk_periodicity_unit']\n",
    "\n",
    "        # Colocar los valores en las columnas timer_interva_value y fk_periodicity_unit en nulo\n",
    "        filtered_data.loc[filtered_data['fk_periodicity_unit'].isin(valores_lecturas), 'time_interval_value'] = None #pd.NA\n",
    "        filtered_data.loc[filtered_data['fk_periodicity_unit'].isin(valores_lecturas), 'fk_periodicity_unit'] = None #pd.NA\n",
    "       \n",
    "        return df_plan, df_action, df_speciality, filtered_data    \n",
    "\n",
    "\n",
    "    def save_to_excel(self, output_path=\"Salida.xlsx\",filename=\"mix_plan.csv\",valores=\"\",regimen=\"\"):\n",
    "        df_plan, df_action, df_speciality, filtered_data = self.process_data(filename=filename,valores=valores,regimen=regimen)  \n",
    "        with pd.ExcelWriter(output_path) as writer:\n",
    "            df_action.to_excel(writer, sheet_name='actions')\n",
    "            df_plan.to_excel(writer, sheet_name='plans')\n",
    "            df_speciality.to_excel(writer, sheet_name='specialties')\n",
    "            filtered_data.to_excel(writer, sheet_name='activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinacion de dataframes\n",
    "gs1 = GoogleSheetProcessor1(url_alta_demanda)\n",
    "if descargar : gs1.download_csv(archivo_ad)\n",
    "df1 = gs1.read_csv(archivo_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GoogleSheetProcessor1 (url_baja_demanda)\n",
    "if descargar: gs2.download_csv(archivo_bd)\n",
    "df2 = gs2.read_csv(archivo_bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([           'id',           'Cod',          'Plan',        'Accion',\n",
       "           'Actividad',     'Tipo_plan',        'Parada',    'Relevancia',\n",
       "        'Especialidad',             'D',             'S',            '2S',\n",
       "                   'M',            'MC',            '2M',             'T',\n",
       "                  'SE',            '8M',             'A',          '1.5A',\n",
       "                  '2A',            '3A',            '4A',            '5A',\n",
       "                  '6A',            '8A',           '10A',          '1000',\n",
       "                '1300',          '1800',          '6000',         '22500',\n",
       "               '40000',         '55000',        '55000C',  'Verificacion',\n",
       "             'Trabajo', 'Observaciones',             nan,           False],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df1.columns[:-2] == df2.columns[:-2]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la igualdad de las columnas, menos las 2 ultimas columnas\n",
    "if (~(df1.columns[:-2] == df2.columns[:-2]).all()) :\n",
    "    print(\"No son iguales las columnas, verificar la igualdad de columnas\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el merge de ambos planes en un solo dataframe\n",
    "df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "df_merged.to_csv(filename_actividades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plan, df_action, df_speciality, df_activities = gs1.process_data(filename=filename_actividades,valores=valores,regimen=regimen)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fk_activity              object\n",
       "fk_plan                   int64\n",
       "fk_action                 int64\n",
       "name                     object\n",
       "fkc_activity_type        object\n",
       "fkc_priority             object\n",
       "fk_specialty              int64\n",
       "fkc_regime               object\n",
       "stoppage                 object\n",
       "time_interval_value     float64\n",
       "fk_periodicity_unit      object\n",
       "usage_interval_value    float64\n",
       "fk_usage_unit            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_activities.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones principales (Para Base de Datos)\n",
    "1. **format_dataframe**:\n",
    "Descripción: Formatea un DataFrame antes de insertarlo en una base de datos, asegurándose de que tenga todas las columnas requeridas y ajustando algunas de sus propiedades (como agregar UUIDs, establecer columnas de seguimiento como created_at, updated_at, etc.).\n",
    "Uso: Asegura que las columnas entre el DataFrame y la tabla de la base de datos sean consistentes.\n",
    "2. **actualizar_tabla_postgres:**\n",
    "Descripción: Elimina los registros de una tabla PostgreSQL, inserta nuevos datos desde un DataFrame, y reinicia la secuencia de la columna id para evitar conflictos.\n",
    "Uso: Se utiliza para actualizar completamente una tabla en PostgreSQL con nuevos datos, manteniendo la consistencia de la columna id.\n",
    "3. **obtener_registros:**\n",
    "Descripción: Ejecuta una consulta SELECT * en una tabla PostgreSQL y devuelve los resultados en un DataFrame. Puede filtrar por columnas específicas si se le proporcionan.\n",
    "Uso: Sirve para obtener los registros de una tabla en formato DataFrame.\n",
    "4. **buscarIndice:**\n",
    "Descripción: Busca un valor en una columna específica de un DataFrame y devuelve el índice del primer resultado encontrado. Si no se encuentra el valor, devuelve el valor de búsqueda original.\n",
    "Uso: Para encontrar la posición de un valor en un DataFrame.\n",
    "5. **ejecutar_query:**\n",
    "Descripción: Ejecuta una consulta SQL (que puede o no devolver filas) y devuelve el resultado en un DataFrame si aplica.\n",
    "Uso: Ejecuta cualquier consulta SQL genérica, devolviendo resultados si es necesario.\n",
    "6. **eliminar_registros:**\n",
    "Descripción: Elimina todos los registros de una tabla PostgreSQL.\n",
    "Uso: Se utiliza para limpiar una tabla antes de insertar nuevos datos.\n",
    "7. **update_plans_table:**\n",
    "Descripción: Elimina registros de una tabla PostgreSQL, inserta nuevos datos desde un DataFrame y reinicia la secuencia de la columna id. Se enfoca en tablas relacionadas con planes.\n",
    "Uso: Función similar a actualizar_tabla_postgres, diseñada específicamente para actualizar tablas de planes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine.result import Result\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\"\"\" Para pasar a la base de datos\"\"\"\n",
    "\n",
    "\n",
    "def format_dataframe(df:pd.DataFrame,tabla:str,\n",
    "                     usuario=usuario, password=password,host=host, database=basedatos):\n",
    "#def format_dataframe(df:pd.DataFrame,tabla:str,usuario='user_mantenimiento', password='pass_M4ntenimient0',host='192.168.100.56', database='db_mantenimiento_test'):\n",
    "    \n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    # Leer la tabla original en un DataFrame de pandas\n",
    "    df_origen = pd.read_sql_query(f\"SELECT * FROM {tabla}\", con=engine)\n",
    "\n",
    "    # Renombrar la columna 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "\n",
    "    # Si existe la columna 'uuid' en la tabla original, crear esa columna\n",
    "    if 'uuid' in df_origen.columns:\n",
    "        df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "\n",
    "    if 'is_active' in df_origen.columns:\n",
    "        df['is_active'] = True        \n",
    "\n",
    "    # Identificar las columnas que están en df_origen pero no en df\n",
    "    missing_columns = [col for col in df_origen.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columnas faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None #pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir columnas comunes\n",
    "    df['id'] = df.index +1 if df.index[0] ==0 else df.index\n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()\n",
    "    # Validar que las columnas de df y df_origen sean iguales\n",
    "    columnas_df = set(df.columns)\n",
    "    columnas_df_origen = set(df_origen.columns)\n",
    "    \n",
    "    # Si las columnas no son iguales, lanzar un error\n",
    "    assert columnas_df == columnas_df_origen, f\"Las columnas no coinciden. Columnas faltantes: {columnas_df_origen - columnas_df} en df y {columnas_df - columnas_df_origen} en df_origen\"        \n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def actualizar_tabla_postgres(df: pd.DataFrame, tabla: str, columna_id: str,\n",
    "                              usuario=usuario, password=password,host=host, database=basedatos):    \n",
    "    # Reemplazar NaN por None (que en SQL es equivalente a NULL)\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "        \n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        #connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.execute(text(f\"DELETE FROM {tabla} CASCADE;\"))\n",
    "        connection.commit()\n",
    "\n",
    "    # Insertar los nuevos datos en la tabla\n",
    "    df.to_sql(tabla, con=engine, if_exists='append', index=False)  # Solo append en tablas con relaciones    \n",
    "\n",
    "    # Obtener el valor máximo de la columna 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX({columna_id}) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    # Obtener el nombre de la secuencia asociada a la columna 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\"))\n",
    "        id_secuencia = result.scalar()\n",
    "\n",
    "    # Reiniciar el valor de la secuencia si se obtiene la secuencia asociada\n",
    "    with engine.connect() as connection:\n",
    "        if id_secuencia:\n",
    "            connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "            connection.commit()\n",
    "            print(f'Se reinició el índice {id_secuencia} en {max_id + 1}')\n",
    "\n",
    "# Ejemplo de uso:\n",
    "## actualizar_tabla_postgres(df_plan, 'plans', 'id')\n",
    "def obtener_registros( tabla,  usuario=usuario, password=password,host=host, database=basedatos,columna_ids=[]):\n",
    "    \"\"\"\n",
    "    Realiza un SELECT * en una tabla especificada de la base de datos y retorna un DataFrame con los resultados.\n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la sentencia SQL para obtener los registros\n",
    "        result = connection.execute(text(f'select * from {tabla}'))        \n",
    "        # Convertir los resultados en un DataFrame\n",
    "        df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "        #df.index = df['index']\n",
    "        df.index = df['id']\n",
    "    return df if not columna_ids or len(columna_ids) == 0 else df[columna_ids]\n",
    "    \n",
    "def buscarIndice(df: pd.DataFrame, valor_busqueda:str, columna_busqueda='name'):\n",
    "    \"\"\"\n",
    "    Busca un valor en la columna especificada del DataFrame.\n",
    "    Si el valor de búsqueda es nulo o si no se encuentra, retorna el mismo valor de búsqueda.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Validar si el valor de búsqueda es nulo\n",
    "    if pd.isna(valor_busqueda):\n",
    "        return None #pd.NA    \n",
    "    # Verificar si el valor está en la columna_id especificada\n",
    "    resultado = df[df[columna_busqueda].str.contains(valor_busqueda, case=False, na=False)]    \n",
    "    # Si no encuentra el valor, retornar el mismo valor\n",
    "    if resultado.empty:\n",
    "        return valor_busqueda\n",
    "    else:\n",
    "        return int(resultado.index[0])\n",
    "\n",
    "def ejecutar_query(query, usuario=usuario, password=password,host=host, database=basedatos):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta SQL y devuelve el resultado en un DataFrame si la consulta devuelve filas.\n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la consulta\n",
    "        result = connection.execute(text(query))\n",
    "        connection.commit()\n",
    "        \n",
    "        # Verificar si la consulta devuelve filas\n",
    "        if result.returns_rows:\n",
    "            # Obtener los resultados en un DataFrame\n",
    "            df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "            return df\n",
    "        else:\n",
    "            # Si no devuelve filas, solo confirmar la ejecución\n",
    "            return None\n",
    "\n",
    "    return result\n",
    "def eliminar_registros(tabla,usuario=usuario, password=password,host=host, database=basedatos):\n",
    "    \"\"\"\n",
    "    Elimina todos los registros de una tabla especificada en la base de datos.    \n",
    "    \"\"\"\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        # Ejecutar la sentencia SQL para eliminar todos los registros\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        connection.commit()  # Confirmar los cambios\n",
    "\n",
    "def __actualizar_tabla_postgres(df:pd.DataFrame , tabla:str, columna_id:str , usuario=usuario, password=password, host= host, database=basedatos):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "\n",
    "    # Usar pd.read_sql_query con una conexión\n",
    "        # Leer la tabla en un DataFrame de pandas\n",
    "    df_origen = ejecutar_query(f\"SELECT * FROM {tabla}\")\n",
    "\n",
    "    \n",
    "    # Renombrar la columna_id 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "    \n",
    "    # Si existe la columna_id uuid en la tabla original, crear esa columna_id\n",
    "    if 'uuid' in df_origen.columns:\n",
    "        df['uuid'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "    \n",
    "    if 'is_active' in df_origen.columns:\n",
    "        df['is_active'] = True\n",
    "\n",
    "\n",
    "    # Identificar las columna_ids que están en df pero no en df_origen\n",
    "    missing_columns = [col for col in df_origen.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columna_ids faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None #pd.NA  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir las columna_ids comunes en las tablas\n",
    "    df['id'] = df.index\n",
    "    \n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()   \n",
    "\n",
    "    # Eliminar todos los registros de la tabla\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "        #connection.commit()\n",
    "    \n",
    "    # Insertar nuevos datos con pandas to_sql\n",
    "    df.to_sql(tabla, con= engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Obtener el valor máximo de la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX({columna_id}) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    \n",
    "    # Obtener el nombre de la secuencia asociada a la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"\"\"\n",
    "            SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\n",
    "        \"\"\"))\n",
    "        id_secuencia = result.scalar()  # Obtener el nombre de la secuencia\n",
    "    \n",
    "        \n",
    "    # Reiniciar el valor de la secuencia\n",
    "    with engine.connect() as connection:\n",
    "        # Si se tienen \n",
    "        if id_secuencia : connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "\n",
    "#usuario='user_mantenimiento', password='pass_M4ntenimient0',host='192.168.100.56', database='db_mantenimiento_test'\n",
    "def update_plans_table(df, tabla, columna_id, usuario=usuario, password=password,host=host, database=basedatos ):\n",
    "    # Crear el engine de SQLAlchemy\n",
    "    engine = create_engine(f'postgresql://{usuario}:{password}@{host}/{database}')\n",
    "\n",
    "    # Leer la tabla en un DataFrame de pandas\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabla}\", engine)\n",
    "\n",
    "    # Renombrar columna_id 'value' a 'name' si existe\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'name'})\n",
    "\n",
    "    # Identificar las columna_ids que están en df pero no en df\n",
    "    missing_columns = [col for col in df.columns if col not in df.columns]\n",
    "\n",
    "    # Añadir las columna_ids faltantes a df con valores NaN\n",
    "    for col in missing_columns:\n",
    "        df[col] = None  # O usa otro valor predeterminado si es necesario\n",
    "\n",
    "    # Añadir/actualizar las columna_ids necesarias en df\n",
    "    df['id'] = df.index\n",
    "    df['is_active'] = True\n",
    "    df['created_by'] = 1\n",
    "    df['updated_by'] = 1\n",
    "    df['created_at'] = pd.Timestamp.now()\n",
    "    df['updated_at'] = pd.Timestamp.now()\n",
    "\n",
    "    # Obtener el nombre de la secuencia asociada a la columna_id 'id' en la tabla 'plans_test'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT pg_get_serial_sequence('{tabla}', '{columna_id}');\"))\n",
    "        id_secuencia = result.scalar()  # Obtener el nombre de la secuencia\n",
    "\n",
    "    # Eliminar todos los registros de la tabla TODO: ANALIZAR LA ELIMINACION DE LOS DATOS DE LA TABLA\n",
    "    #with engine.connect() as connection:\n",
    "    #    connection.execute(text(f\"DELETE FROM {tabla};\"))\n",
    "    #    connection.commit()\n",
    "\n",
    "    # Insertar nuevos datos con pandas to_sql\n",
    "    df.to_sql(tabla, engine, if_exists='replace', index=False)\n",
    "\n",
    "    # Obtener el valor máximo de la columna_id 'id'\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT MAX(id) FROM {tabla};\"))\n",
    "        max_id = result.scalar() or 0  # Si no hay registros, usar 0\n",
    "\n",
    "    # Reiniciar el valor de la secuencia\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(f\"ALTER SEQUENCE {id_secuencia} RESTART WITH {max_id + 1};\"))\n",
    "\n",
    "# Ejemplo de uso\n",
    "# Definir el DataFrame df con tus datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT FASE 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fk_base</th>\n",
       "      <th>fk_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88631</th>\n",
       "      <td>494</td>\n",
       "      <td>2887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88632</th>\n",
       "      <td>19842</td>\n",
       "      <td>2887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88633</th>\n",
       "      <td>19998</td>\n",
       "      <td>2887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88634</th>\n",
       "      <td>20011</td>\n",
       "      <td>2887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88635</th>\n",
       "      <td>20029</td>\n",
       "      <td>2887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88636 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fk_base  fk_activity\n",
       "0            8            1\n",
       "1            9            1\n",
       "2           10            1\n",
       "3           17            1\n",
       "4           19            1\n",
       "...        ...          ...\n",
       "88631      494         2887\n",
       "88632    19842         2887\n",
       "88633    19998         2887\n",
       "88634    20011         2887\n",
       "88635    20029         2887\n",
       "\n",
       "[88636 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"\"\"\n",
    "SELECT\t\n",
    "    b.id AS fk_base,\n",
    "--p.id AS id_plan, \n",
    "    a.id AS fk_activity\n",
    "FROM\n",
    "    base AS b LEFT JOIN\tplans AS p\tON b.fk_plan = p.id\n",
    "    LEFT JOIN\tactivities AS a ON p.id = a.fk_plan\n",
    "WHERE\n",
    "    b.fk_plan IS NOT NULL\n",
    "ORDER BY\n",
    "    b.fk_plan ASC,\n",
    "a.id ASC,\n",
    "b.id ASC\n",
    "\"\"\"\n",
    "df_base_activities =  ejecutar_query(query)\n",
    "df_base_activities\n",
    "#obtener_registros('base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_df_base_activities = format_dataframe(df_base_activities,'base_activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminar_registros('reschedule_history')\n",
    "eliminar_registros('checks')\n",
    "eliminar_registros('base_activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar registros con truncate de la tabla base_activities\n",
    "#ejecutar_query('TRUNCATE base_activities CASCADE;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se requiere que las actividades, sean inicializadas, si la actividad es por fecha, se requiere que se inicialicen en una fecha determinada, esta fecha debera obtenerse posteriormente de una hoja de calculo donde los responsables deberan registrar la fecha en la que se ejecuto por ultima vez, para que realice el calculo de la proxima intervencion\n",
    "# En el caso de start_date, colocar como referencia la fecha de inicio de operacion de la linea TODO: Se requiere que se tome en cuenta en hoja de calculo las fechas de inicio de operast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activities = obtener_registros(\"activities\")\n",
    "df_base_activities = format_df_base_activities.copy(deep=True)\n",
    "\n",
    "# Crear el diccionario de mapeo\n",
    "enum_mapping = {\n",
    "    1: 'días',\n",
    "    2: 'semanas',\n",
    "    3: 'meses',\n",
    "    4: 'años'\n",
    "}\n",
    "\n",
    "# Mapear la columna fk_periodicity_unit con el diccionario\n",
    "df_activities['fk_periodicity_unit'] = df_activities['fk_periodicity_unit'].map(enum_mapping)\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Crear la variable fecha_inicio con la fecha de hoy\n",
    "fecha_inicio = datetime.today()\n",
    "\n",
    "# Agregar la fecha de inicio (fecha_inicio) a la columna start_date de df_activities\n",
    "df_base_activities['start_date'] = fecha_inicio\n",
    "\n",
    "# Restablecer índices para evitar conflictos\n",
    "df_base_activities_reset = df_base_activities.reset_index(drop=True)\n",
    "df_activities_reset = df_activities.reset_index(drop=True)\n",
    "\n",
    "# Renombrar temporalmente la columna 'id' en df_activities si existe conflicto\n",
    "df_activities_reset.rename(columns={'id': 'activity_id'}, inplace=True)\n",
    "\n",
    "# Realizar la fusión con las columnas adecuadas\n",
    "df_base_activities_merge = df_base_activities_reset.merge(\n",
    "    df_activities_reset[['activity_id', 'time_interval_value', 'fk_periodicity_unit']],\n",
    "    left_on='fk_activity',\n",
    "    right_on='activity_id',\n",
    "    how='left'\n",
    ")\n",
    "# Redefinir la función calculate_next_date\n",
    "def calculate_next_date(row):\n",
    "    \n",
    "    if row['fk_periodicity_unit'] == 'días':\n",
    "        return row['start_date'] + timedelta(days=row['time_interval_value'])\n",
    "    elif row['fk_periodicity_unit'] == 'semanas':\n",
    "        return row['start_date'] + timedelta(weeks=row['time_interval_value'])\n",
    "    elif row['fk_periodicity_unit'] == 'meses':\n",
    "        return row['start_date'] + relativedelta(months=row['time_interval_value'])\n",
    "    elif row['fk_periodicity_unit'] == 'años':\n",
    "        return row['start_date'] + relativedelta(years=row['time_interval_value'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Recalcular las columnas last_date y next_date\n",
    "df_base_activities_merge['last_date'] = df_base_activities_merge['start_date']\n",
    "df_base_activities_merge['next_date'] = df_base_activities_merge.apply(calculate_next_date, axis=1)\n",
    "df_base_activities_merge = [format_df_base_activities.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.InsufficientPrivilege) must be owner of sequence base_activities_id_seq\n\n[SQL: ALTER SEQUENCE public.base_activities_id_seq RESTART WITH 88637;]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInsufficientPrivilege\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInsufficientPrivilege\u001b[0m: must be owner of sequence base_activities_id_seq\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mactualizar_tabla_postgres\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_df_base_activities\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase_activities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 80\u001b[0m, in \u001b[0;36mactualizar_tabla_postgres\u001b[0;34m(df, tabla, columna_id, usuario, password, host, database)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m id_secuencia:\n\u001b[0;32m---> 80\u001b[0m         \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mALTER SEQUENCE \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mid_secuencia\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m RESTART WITH \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmax_id\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m         connection\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSe reinició el índice \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_secuencia\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_id\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1639\u001b[0m )\n\u001b[0;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1655\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         ret,\n\u001b[1;32m   1660\u001b[0m     )\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2357\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
      "File \u001b[0;32m~/proyectos/datascience_etcmt/notebooks/venv/lib/python3.8/site-packages/sqlalchemy/engine/default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.errors.InsufficientPrivilege) must be owner of sequence base_activities_id_seq\n\n[SQL: ALTER SEQUENCE public.base_activities_id_seq RESTART WITH 88637;]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "actualizar_tabla_postgres(format_df_base_activities,'base_activities','id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasos\n",
    "1. Eliminar registros de activities\n",
    "2. Eliminar de tabla base que este relacionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Eliminar datos tabla actividades\n",
    "eliminar_registros(tabla='activities')\n",
    "# Eliminar registros de la tabla base que tenga items relacionados\n",
    "query = 'delete from base where fk_plan is not null '\n",
    "ejecutar_query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOTOR ELECTRICO PRINCIPAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REFRIGERACION DE MOTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       value\n",
       "1  MOTOR ELECTRICO PRINCIPAL\n",
       "2     REFRIGERACION DE MOTOR"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plan.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install SQLAlchemy psycopg2-binary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.actions_id_seq en 16\n"
     ]
    }
   ],
   "source": [
    "# Tabla actions, darle formato y actualizar en BBDD\n",
    "df_action =format_dataframe(df_action,'actions')\n",
    "actualizar_tabla_postgres(df_action,'actions','id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla Periodicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>deleted_by</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dia(s)</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>semana(s)</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mes(es)</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>año(s)</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>lunes</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-17 08:55:19.768000-04:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>martes</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-17 08:55:19.768000-04:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>miercoles</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-17 08:55:19.768000-04:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>jueves</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-17 08:55:19.768000-04:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>viernes</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-17 08:55:19.768000-04:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>sábado</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-17 08:55:19.768000-04:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>domingo</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30 12:05:19.768000-04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-12-17 08:55:19.768000-04:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       name                       created_at  created_by  \\\n",
       "id                                                               \n",
       "1    1     dia(s) 2022-05-30 12:05:19.768000-04:00           1   \n",
       "2    2  semana(s) 2022-05-30 12:05:19.768000-04:00           1   \n",
       "3    3    mes(es) 2022-05-30 12:05:19.768000-04:00           1   \n",
       "4    4     año(s) 2022-05-30 12:05:19.768000-04:00           1   \n",
       "5    5      lunes 2022-05-30 12:05:19.768000-04:00           1   \n",
       "6    6     martes 2022-05-30 12:05:19.768000-04:00           1   \n",
       "7    7  miercoles 2022-05-30 12:05:19.768000-04:00           1   \n",
       "8    8     jueves 2022-05-30 12:05:19.768000-04:00           1   \n",
       "9    9    viernes 2022-05-30 12:05:19.768000-04:00           1   \n",
       "10  10     sábado 2022-05-30 12:05:19.768000-04:00           1   \n",
       "11  11    domingo 2022-05-30 12:05:19.768000-04:00           1   \n",
       "\n",
       "                         updated_at  updated_by  \\\n",
       "id                                                \n",
       "1  2022-05-30 12:05:19.768000-04:00           1   \n",
       "2  2022-05-30 12:05:19.768000-04:00           1   \n",
       "3  2022-05-30 12:05:19.768000-04:00           1   \n",
       "4  2022-05-30 12:05:19.768000-04:00           1   \n",
       "5  2022-05-30 12:05:19.768000-04:00           1   \n",
       "6  2022-05-30 12:05:19.768000-04:00           1   \n",
       "7  2022-05-30 12:05:19.768000-04:00           1   \n",
       "8  2022-05-30 12:05:19.768000-04:00           1   \n",
       "9  2022-05-30 12:05:19.768000-04:00           1   \n",
       "10 2022-05-30 12:05:19.768000-04:00           1   \n",
       "11 2022-05-30 12:05:19.768000-04:00           1   \n",
       "\n",
       "                         deleted_at  deleted_by  \n",
       "id                                               \n",
       "1                               NaT         NaN  \n",
       "2                               NaT         NaN  \n",
       "3                               NaT         NaN  \n",
       "4                               NaT         NaN  \n",
       "5  2024-12-17 08:55:19.768000-04:00         1.0  \n",
       "6  2024-12-17 08:55:19.768000-04:00         1.0  \n",
       "7  2024-12-17 08:55:19.768000-04:00         1.0  \n",
       "8  2024-12-17 08:55:19.768000-04:00         1.0  \n",
       "9  2024-12-17 08:55:19.768000-04:00         1.0  \n",
       "10 2024-12-17 08:55:19.768000-04:00         1.0  \n",
       "11 2024-12-17 08:55:19.768000-04:00         1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_periodicities = obtener_registros(tabla='periodicities')\n",
    "# Se cambio la periodicidad\n",
    "df_periodicities = obtener_registros(tabla='periodicity_unit')\n",
    "df_periodicities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specialties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.specialties_id_seq en 9\n"
     ]
    }
   ],
   "source": [
    "df_speciality = format_dataframe(df_speciality,'specialties')\n",
    "df_speciality['description'] = df_speciality['name'] # no se crea automaticamente\n",
    "actualizar_tabla_postgres(df=df_speciality,tabla='specialties',columna_id='id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.plans_id_seq en 279\n"
     ]
    }
   ],
   "source": [
    "# Tabla actions, darle formato y actualizar en BBDD\n",
    "df_plan = format_dataframe(df_plan,'plans')\n",
    "actualizar_tabla_postgres(df_plan,'plans','id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.usage_units_id_seq en 3\n"
     ]
    }
   ],
   "source": [
    "df_usage_units = pd.DataFrame(df_activities['fk_usage_unit'].dropna().unique(),columns=['value'])\n",
    "df_usage_units = format_dataframe(df_usage_units,'usage_units')\n",
    "df_usage_units['unit']=df_usage_units['name']           #TODO: ???\n",
    "df_usage_units['description']=df_usage_units['name']    #TODO: ???\n",
    "actualizar_tabla_postgres(df_usage_units,'usage_units',columna_id='id')\n",
    "df_usage_units.index = df_usage_units.id    # Se coloca el id correspondientea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>unit</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horas</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-21 11:46:45.455170</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-21 11:46:45.455403</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>horas</td>\n",
       "      <td>horas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ciclos</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-01-21 11:46:45.455170</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-21 11:46:45.455403</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ciclos</td>\n",
       "      <td>ciclos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  id                 created_at  created_by  \\\n",
       "id                                                      \n",
       "1    horas   1 2025-01-21 11:46:45.455170           1   \n",
       "2   ciclos   2 2025-01-21 11:46:45.455170           1   \n",
       "\n",
       "                   updated_at  updated_by deleted_at deleted_by    unit  \\\n",
       "id                                                                        \n",
       "1  2025-01-21 11:46:45.455403           1       None       None   horas   \n",
       "2  2025-01-21 11:46:45.455403           1       None       None  ciclos   \n",
       "\n",
       "   description  \n",
       "id              \n",
       "1        horas  \n",
       "2       ciclos  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_usage_units"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fk_classifiers_type</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>grup_1</th>\n",
       "      <th>notEnabled</th>\n",
       "      <th>is_active</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>ACORDE A LA DISPONIBILIDAD</td>\n",
       "      <td>ACORDE A LA DISPONIBILIDAD</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-05-30 12:05:18.891000-04:00</td>\n",
       "      <td>2022-05-30 12:05:18.891000-04:00</td>\n",
       "      <td>2022-07-18 10:05:18.891000-04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>ELECTRICO</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-30 12:05:18.891000-04:00</td>\n",
       "      <td>2022-05-30 12:05:18.891000-04:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  fk_classifiers_type                        name  \\\n",
       "id                                                        \n",
       "5    5                    3  ACORDE A LA DISPONIBILIDAD   \n",
       "17  17                    5                   ELECTRICO   \n",
       "\n",
       "                   description  grup_1 notEnabled  is_active  created_by  \\\n",
       "id                                                                         \n",
       "5   ACORDE A LA DISPONIBILIDAD       1       None      False           1   \n",
       "17                   ELECTRICO       1       None       True           1   \n",
       "\n",
       "    updated_by  deleted_by                       created_at  \\\n",
       "id                                                            \n",
       "5          1.0         1.0 2022-05-30 12:05:18.891000-04:00   \n",
       "17         1.0         NaN 2022-05-30 12:05:18.891000-04:00   \n",
       "\n",
       "                         updated_at                       deleted_at  \n",
       "id                                                                    \n",
       "5  2022-05-30 12:05:18.891000-04:00 2022-07-18 10:05:18.891000-04:00  \n",
       "17 2022-05-30 12:05:18.891000-04:00                              NaT  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener registros de la tabla classifiers\n",
    "df_classifiers = obtener_registros(tabla='classifiers')\n",
    "df_classifiers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dar formato a tabla\n",
    "df_activities = format_dataframe(df_activities,'activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer copia local\n",
    "df_activities_raw = df_activities.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fk_activity</th>\n",
       "      <th>fk_plan</th>\n",
       "      <th>fk_action</th>\n",
       "      <th>name</th>\n",
       "      <th>fkc_activity_type</th>\n",
       "      <th>fkc_priority</th>\n",
       "      <th>fk_specialty</th>\n",
       "      <th>fkc_regime</th>\n",
       "      <th>stoppage</th>\n",
       "      <th>time_interval_value</th>\n",
       "      <th>...</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>earliest_reschedule_days</th>\n",
       "      <th>latest_reschedule_days</th>\n",
       "      <th>earliest_reschedule_usage</th>\n",
       "      <th>latest_reschedule_usage</th>\n",
       "      <th>skippable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verificar la ausencia de ruidos y vibraciones ...</td>\n",
       "      <td>Actividad</td>\n",
       "      <td>MEDIA</td>\n",
       "      <td>1</td>\n",
       "      <td>FECHAS</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-21 11:47:06.243646</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verificación de marcas de tornillería del moto...</td>\n",
       "      <td>Actividad</td>\n",
       "      <td>MEDIA</td>\n",
       "      <td>1</td>\n",
       "      <td>FECHAS</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-21 11:47:06.243646</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fk_activity  fk_plan  fk_action  \\\n",
       "1        None        1          1   \n",
       "2        None        1          1   \n",
       "\n",
       "                                                name fkc_activity_type  \\\n",
       "1  Verificar la ausencia de ruidos y vibraciones ...         Actividad   \n",
       "2  Verificación de marcas de tornillería del moto...         Actividad   \n",
       "\n",
       "  fkc_priority  fk_specialty fkc_regime stoppage  time_interval_value  ...  \\\n",
       "1        MEDIA             1     FECHAS    False                  1.0  ...   \n",
       "2        MEDIA             1     FECHAS    False                  1.0  ...   \n",
       "\n",
       "  created_by                 updated_at updated_by deleted_at  deleted_by  \\\n",
       "1          1 2025-01-21 11:47:06.243646          1       None        None   \n",
       "2          1 2025-01-21 11:47:06.243646          1       None        None   \n",
       "\n",
       "   earliest_reschedule_days latest_reschedule_days  earliest_reschedule_usage  \\\n",
       "1                      None                   None                       None   \n",
       "2                      None                   None                       None   \n",
       "\n",
       "  latest_reschedule_usage  skippable  \n",
       "1                    None       None  \n",
       "2                    None       None  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_activities.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fk_activity</th>\n",
       "      <th>fk_plan</th>\n",
       "      <th>fk_action</th>\n",
       "      <th>name</th>\n",
       "      <th>fkc_activity_type</th>\n",
       "      <th>fkc_priority</th>\n",
       "      <th>fk_specialty</th>\n",
       "      <th>fkc_regime</th>\n",
       "      <th>stoppage</th>\n",
       "      <th>time_interval_value</th>\n",
       "      <th>...</th>\n",
       "      <th>created_by</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>deleted_at</th>\n",
       "      <th>deleted_by</th>\n",
       "      <th>earliest_reschedule_days</th>\n",
       "      <th>latest_reschedule_days</th>\n",
       "      <th>earliest_reschedule_usage</th>\n",
       "      <th>latest_reschedule_usage</th>\n",
       "      <th>skippable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verificar la ausencia de ruidos y vibraciones ...</td>\n",
       "      <td>166</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-21 11:47:06.243646</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verificación de marcas de tornillería del moto...</td>\n",
       "      <td>166</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-01-21 11:47:06.243646</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fk_activity  fk_plan  fk_action  \\\n",
       "1        None        1          1   \n",
       "2        None        1          1   \n",
       "\n",
       "                                                name  fkc_activity_type  \\\n",
       "1  Verificar la ausencia de ruidos y vibraciones ...                166   \n",
       "2  Verificación de marcas de tornillería del moto...                166   \n",
       "\n",
       "   fkc_priority  fk_specialty  fkc_regime stoppage  time_interval_value  ...  \\\n",
       "1             8             1         163    False                  1.0  ...   \n",
       "2             8             1         163    False                  1.0  ...   \n",
       "\n",
       "  created_by                 updated_at updated_by deleted_at  deleted_by  \\\n",
       "1          1 2025-01-21 11:47:06.243646          1       None        None   \n",
       "2          1 2025-01-21 11:47:06.243646          1       None        None   \n",
       "\n",
       "   earliest_reschedule_days latest_reschedule_days  earliest_reschedule_usage  \\\n",
       "1                      None                   None                       None   \n",
       "2                      None                   None                       None   \n",
       "\n",
       "  latest_reschedule_usage  skippable  \n",
       "1                    None       None  \n",
       "2                    None       None  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir en sus indices todas las columnas que tengan que ver con classifiers\n",
    "df_activities['fkc_activity_type'] =df_activities['fkc_activity_type'].apply(lambda x: gs1.buscarIndice(valor=str(x),df=df_classifiers,columna_id='name')) \n",
    "df_activities['fkc_priority'] = df_activities['fkc_priority'].apply(lambda x: gs1.buscarIndice(df=df_classifiers,valor=str(x),columna_id='name'))\n",
    "df_activities['fkc_regime'] = df_activities['fkc_regime'].apply(lambda x: gs1.buscarIndice(df=df_classifiers,valor=str(x),columna_id='name'))\n",
    "\n",
    "#Obtener periodiciadad unit\n",
    "df_activities['fk_periodicity_unit'] = df_activities['fk_periodicity_unit'].apply(lambda x: gs1.buscarIndice(valor=str(x),df=df_periodicities,columna_id='name'))\n",
    "# obtener usage_unit\n",
    "df_activities['fk_usage_unit'] = df_activities['fk_usage_unit'].apply(lambda x: gs1.buscarIndice(valor=str(x),df=df_usage_units,columna_id='name'))\n",
    "\n",
    "# en la columna fk_periodicity_unit tienen valores 'NONE', necesito que nos valores 'NONE' se conviertan en valores vacios\n",
    "df_activities['fk_periodicity_unit'] = df_activities['fk_periodicity_unit'].replace('NONE', None)\n",
    "\n",
    "# en la columna fk_usage_unit tiene valores \"NAN\", reemplazar valores NAN con valores vacios o None\n",
    "df_activities['fk_usage_unit'] = df_activities['fk_usage_unit'].replace('NAN', None)\n",
    "\n",
    "df_activities.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activities.to_excel(\"activities_antes_bd.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se reinició el índice public.activities_id_seq en 2881\n"
     ]
    }
   ],
   "source": [
    "actualizar_tabla_postgres(df_activities,'activities',columna_id='id')\n",
    "\n",
    "#InvalidTextRepresentation: la sintaxis de entrada no es válida para tipo integer: «nan»\n",
    "#LINE 1: ...l motor.', 166, 8, 1, 163, false, 1.0, '1', NULL, 'nan', 'd3...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completar unidades medida y de uso\n",
    "\n",
    "De df_activities de la columna fk_periodicity_unit, si el valor de la columna es ['horas','ciclos'] mover el contenido de la columna time_interval_value a la columna usage_interval_value en la columna time_interval_value dejar con valor nulo, y mover el valor de la columna fk_peridicity_unit  a la columna fk_usage_unit y en la columna fk_periodicity_unit dejar en nulo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sqlalchemy==1.4.23 psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalación\n",
    "Se colocaron todos los paquetes que se utilizan en el proyecto en el archivo paquetes.txt\n",
    "En caso que no funcione utilizar:\n",
    "\n",
    "<code> pip install SQLAlchemy psycopg2-binary </code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install SQLAlchemy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar a archivo excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)      \n",
    "######################    \n",
    "\n",
    "#####################\n",
    "#with pd.ExcelWriter(\"output/\"+salida.value) as writer:\n",
    "#   df_action.to_excel(writer, sheet_name='actions')\n",
    "#    df_plan.to_excel(writer, sheet_name='plans')\n",
    "#    df_speciality.to_excel(writer, sheet_name='specialties')\n",
    "#    df_activities.to_excel(writer, sheet_name='activities')\n",
    "\n",
    "# gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\\nimport warnings\\nimport pandas as pd\\nimport ipywidgets as widgets\\nfrom ipywidgets import Button, Layout\\nfrom IPython.display import display\\n\\n#warnings.simplefilter(action=\\'ignore\\', category=FutureWarning)\\n\\nvalores = {\\n    \"D\": 1,\\n    \"S\": 1,\\n    \"2S\": 2,\\n    \"M\": 5,\\n    \"MC\": 1,\\n    \"2M\": 2,\\n    \"T\": 3,\\n    \"SE\": 6,\\n    \"8M\": 8,\\n    \"A\": 1,\\n    \"1.5A\": 18,\\n    \"2A\": 2,\\n    \"3A\": 3,\\n    \"4A\": 4,\\n    \"5A\": 5,\\n    \"6A\": 6,\\n    \"8A\": 8,\\n    \"10A\": 10,\\n    \"1000\": 1000,\\n    \"1300\": 1300,\\n    \"1800\": 1800,\\n    \"6000\": 6000,\\n    \"22500\": 6000,\\n    \"40000\": 40000,\\n    \"55000\": 55000,\\n    \"55000C\": 55000\\n}\\n\\nregimen = {\\n    \"D\": \\'dia\\',\\n    \"S\": \\'semana\\',\\n    \"2S\": \\'semana\\',\\n    \"M\": \\'semana\\',\\n    \"MC\": \\'mes\\',\\n    \"2M\": \\'mes\\',\\n    \"T\": \\'mes\\',\\n    \"SE\": \\'mes\\',\\n    \"8M\": \\'mes\\',\\n    \"A\": \\'Año\\',\\n    \"1.5A\": \\'mes\\',\\n    \"2A\": \\'Año\\',\\n    \"3A\": \\'Año\\',\\n    \"4A\": \\'Año\\',\\n    \"5A\": \\'Año\\',\\n    \"6A\": \\'Año\\',\\n    \"8A\": \\'Año\\',\\n    \"10A\": \\'Año\\',\\n    \"1000\": \\'horas\\',\\n    \"1300\": \\'horas\\',\\n    \"1800\": \\'horas\\',\\n    \"6000\": \\'horas\\',\\n    \"22500\": \\'horas\\',\\n    \"40000\": \\'horas\\',\\n    \"55000\": \\'horas\\',\\n    \"55000C\": \\'ciclos\\'\\n}\\n\\nlad = widgets.Textarea(value=\\'https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294\\',placeholder=\\'Plan Maestro LAD\\',description=\\'Lineas Alta Demanda:\\',disabled=False,layout=Layout(width=\\'70%\\',height=\"200px\"))\\nlbd = widgets.Textarea(value=\\'https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294\\',placeholder=\\'Plan Maestro LBD\\',description=\\'Lineas Baja Demanda:\\',disabled=False,layout=Layout(width=\\'70%\\',height=\"200px\"))\\nhost = widgets.Text(value=\\'192.168.100.50\\',placeholder=\\'Host\\',description=\\'Host:\\',disabled=False)\\nbasedatos = widgets.Text(value=\\'simyo2\\',placeholder=\\'BaseDatos\\',description=\\'BaseDatos\\',disabled=False)\\nusuario = widgets.Text(value=\\'mantto\\',description=\\'Usuario\\')\\npassword = widgets.Password(value=\\'Sistemas0\\',description=\\'Password\\')\\nbutton1 = widgets.Button(description=\"Generar Archivo Excel\",button_style=\\'success\\',layout=Layout(width=\\'20%\\'))\\nbutton2 = widgets.Button(description=\"Cargar en Base de datos\",button_style=\\'danger\\',layout=Layout(width=\\'20%\\'))\\noutput = widgets.Output()\\nsalida = widgets.Text(value=\"Salida.xlsx\",description=\"Nombre:\",disabled=False)\\naccordion = widgets.Accordion(children=[ salida], titles=([\\'Archivo Salida\\']))\\naccordion1 = widgets.Accordion(children=[ usuario,password,host,basedatos], titles=(\\'Usuario\\',\\'Password\\',\\'Host\\',\\'Base de Datos\\'))\\n\\ndisplay(lad,lbd,host,usuario,password,accordion,button1, accordion1,button2,output)\\n\\ndef on_button_clicked(b):    \\n    # Combinacion de dataframes\\n    gs1 = GoogleSheetProcessor(lad.value) #(\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294\")\\n    archivo = \"input/pad.csv\"\\n    #gs.download_csv(archivo)\\n    df1 = gs1.read_csv(archivo)\\n\\n    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294\")\\n    archivo = \"input/pbd.csv\"\\n    #gs.download_csv(archivo)\\n    df2 = gs2.read_csv(archivo)\\n    # Realizar el merge de ambos planes en un solo dataframe\\n    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\\n\\n    filename = \"input/mix_plan.csv\"\\n    df_merged.to_csv(filename)\\n    \\n    #df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)      \\n######################    \\n\\n#####################\\n\\n    df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)  \\n    with pd.ExcelWriter(\"output/\"+salida.value) as writer:\\n        df_action.to_excel(writer, sheet_name=\\'actions\\')\\n        df_plan.to_excel(writer, sheet_name=\\'plans\\')\\n        df_speciality.to_excel(writer, sheet_name=\\'specialties\\')\\n        filtered_data.to_excel(writer, sheet_name=\\'activities\\')\\n    \\n    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \\n    with output:\\n        print(\"Se Genera archivo excel Salida.xlsx\")\\n\\nbutton1.on_click(on_button_clicked)\\nbutton2.on_click(lambda _: print(\"Boton 2 accionado\"))\\n#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html '"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import display\n",
    "\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "valores = {\n",
    "    \"D\": 1,\n",
    "    \"S\": 1,\n",
    "    \"2S\": 2,\n",
    "    \"M\": 5,\n",
    "    \"MC\": 1,\n",
    "    \"2M\": 2,\n",
    "    \"T\": 3,\n",
    "    \"SE\": 6,\n",
    "    \"8M\": 8,\n",
    "    \"A\": 1,\n",
    "    \"1.5A\": 18,\n",
    "    \"2A\": 2,\n",
    "    \"3A\": 3,\n",
    "    \"4A\": 4,\n",
    "    \"5A\": 5,\n",
    "    \"6A\": 6,\n",
    "    \"8A\": 8,\n",
    "    \"10A\": 10,\n",
    "    \"1000\": 1000,\n",
    "    \"1300\": 1300,\n",
    "    \"1800\": 1800,\n",
    "    \"6000\": 6000,\n",
    "    \"22500\": 6000,\n",
    "    \"40000\": 40000,\n",
    "    \"55000\": 55000,\n",
    "    \"55000C\": 55000\n",
    "}\n",
    "\n",
    "regimen = {\n",
    "    \"D\": 'dia',\n",
    "    \"S\": 'semana',\n",
    "    \"2S\": 'semana',\n",
    "    \"M\": 'semana',\n",
    "    \"MC\": 'mes',\n",
    "    \"2M\": 'mes',\n",
    "    \"T\": 'mes',\n",
    "    \"SE\": 'mes',\n",
    "    \"8M\": 'mes',\n",
    "    \"A\": 'Año',\n",
    "    \"1.5A\": 'mes',\n",
    "    \"2A\": 'Año',\n",
    "    \"3A\": 'Año',\n",
    "    \"4A\": 'Año',\n",
    "    \"5A\": 'Año',\n",
    "    \"6A\": 'Año',\n",
    "    \"8A\": 'Año',\n",
    "    \"10A\": 'Año',\n",
    "    \"1000\": 'horas',\n",
    "    \"1300\": 'horas',\n",
    "    \"1800\": 'horas',\n",
    "    \"6000\": 'horas',\n",
    "    \"22500\": 'horas',\n",
    "    \"40000\": 'horas',\n",
    "    \"55000\": 'horas',\n",
    "    \"55000C\": 'ciclos'\n",
    "}\n",
    "\n",
    "lad = widgets.Textarea(value='https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294',placeholder='Plan Maestro LAD',description='Lineas Alta Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "lbd = widgets.Textarea(value='https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294',placeholder='Plan Maestro LBD',description='Lineas Baja Demanda:',disabled=False,layout=Layout(width='70%',height=\"200px\"))\n",
    "host = widgets.Text(value='192.168.100.50',placeholder='Host',description='Host:',disabled=False)\n",
    "basedatos = widgets.Text(value='simyo2',placeholder='BaseDatos',description='BaseDatos',disabled=False)\n",
    "usuario = widgets.Text(value='mantto',description='Usuario')\n",
    "password = widgets.Password(value='Sistemas0',description='Password')\n",
    "button1 = widgets.Button(description=\"Generar Archivo Excel\",button_style='success',layout=Layout(width='20%'))\n",
    "button2 = widgets.Button(description=\"Cargar en Base de datos\",button_style='danger',layout=Layout(width='20%'))\n",
    "output = widgets.Output()\n",
    "salida = widgets.Text(value=\"Salida.xlsx\",description=\"Nombre:\",disabled=False)\n",
    "accordion = widgets.Accordion(children=[ salida], titles=(['Archivo Salida']))\n",
    "accordion1 = widgets.Accordion(children=[ usuario,password,host,basedatos], titles=('Usuario','Password','Host','Base de Datos'))\n",
    "\n",
    "display(lad,lbd,host,usuario,password,accordion,button1, accordion1,button2,output)\n",
    "\n",
    "def on_button_clicked(b):    \n",
    "    # Combinacion de dataframes\n",
    "    gs1 = GoogleSheetProcessor(lad.value) #(\"https://docs.google.com/spreadsheets/d/1oUHkuKpHtuhMirNW6SvAQ4A0ns5PZs71iZ_WFXZHNn8/edit?gid=1199302294\")\n",
    "    archivo = \"input/pad.csv\"\n",
    "    #gs.download_csv(archivo)\n",
    "    df1 = gs1.read_csv(archivo)\n",
    "\n",
    "    gs2 = GoogleSheetProcessor (lbd.value) #(\"https://docs.google.com/spreadsheets/d/1yOaSeqRBr1FW6tvFMi_Y-s4011cKBoyiWU5dTMlujrU/edit?gid=1199302294\")\n",
    "    archivo = \"input/pbd.csv\"\n",
    "    #gs.download_csv(archivo)\n",
    "    df2 = gs2.read_csv(archivo)\n",
    "    # Realizar el merge de ambos planes en un solo dataframe\n",
    "    df_merged = pd.concat([df1,df2],ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    filename = \"input/mix_plan.csv\"\n",
    "    df_merged.to_csv(filename)\n",
    "    \n",
    "    #df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)      \n",
    "######################    \n",
    "\n",
    "#####################\n",
    "\n",
    "    df_plan, df_action, df_speciality, filtered_data = gs1.process_data(filename=filename,valores=valores,regimen=regimen)  \n",
    "    with pd.ExcelWriter(\"output/\"+salida.value) as writer:\n",
    "        df_action.to_excel(writer, sheet_name='actions')\n",
    "        df_plan.to_excel(writer, sheet_name='plans')\n",
    "        df_speciality.to_excel(writer, sheet_name='specialties')\n",
    "        filtered_data.to_excel(writer, sheet_name='activities')\n",
    "    \n",
    "    # gs1.save_to_excel(output_path=salida.value,valores=valores,regimen=regimen,filename=\"mix_plan.csv\")        \n",
    "    with output:\n",
    "        print(\"Se Genera archivo excel Salida.xlsx\")\n",
    "\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(lambda _: print(\"Boton 2 accionado\"))\n",
    "#https://ipywidgets.readthedocs.io/en/7.6.3/examples/Widget%20Styling.html '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las columnas y sus tipos de datos de la columna activities\n",
    "#query = \"\"\"\n",
    "#SELECT column_name\n",
    "#FROM information_schema.columns\n",
    "#WHERE table_name = 'activities' order by ordinal_position asc;\n",
    "#\"\"\"\n",
    "#df_columnas_activities = ejecutar_query(query)\n",
    "#df_columnas_activities['column_name']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
